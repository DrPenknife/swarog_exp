{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "690ba15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9fea8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "! id=\"12vbx8UMl4KpoSPM4ZHqqggjtKrn35odG\"; \\\n",
    "conf=$(wget --quiet --save-cookies /tmp/cookies.txt \\\n",
    "--keep-session-cookies --no-check-certificate \\\n",
    "'https://docs.google.com/uc?export=download&id='$id -O- | \\\n",
    "sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p'); \\\n",
    "wget --load-cookies /tmp/cookies.txt \\\n",
    "\"https://docs.google.com/uc?export=download&confirm=$conf&id=$id\" -O qprop.csv && \\\n",
    "rm -rf /tmp/cookies.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3c12c2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels\n",
      " 0    45534\n",
      "1     5736\n",
      "Name: label, dtype: int64\n",
      "shape  \n",
      " (51270, 14)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 4191.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shapes X (2002,) y (2002,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "\n",
    "data = pd.read_csv(\"raw/qprop.csv\",sep=\"\\t\")\n",
    "print(\"labels\\n\",data[\"label\"].value_counts())\n",
    "print(\"shape  \\n\",data.shape)\n",
    "\n",
    "bootstrap_size = 2000\n",
    "\n",
    "if bootstrap_size != 0:\n",
    "    bootstrap_factor = bootstrap_size / data.shape[0]\n",
    "    bootstrap = np.random.uniform(size=data.shape[0]) < bootstrap_factor\n",
    "    data = data.iloc[bootstrap]\n",
    "\n",
    "X, y = data[\"text\"].values, data[\"label\"].values\n",
    "\n",
    "rskf = RepeatedStratifiedKFold(n_splits=2, n_repeats=5, random_state=1410)\n",
    "foldids = []\n",
    "for fold_idx, (train, test) in tqdm(enumerate(rskf.split(X, y)), total=rskf.get_n_splits()):\n",
    "    foldids.append((fold_idx,train,test))\n",
    "    \n",
    "print(\"shapes X\",X.shape,\"y\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd21fdc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['text', 'event_location', 'average_tone', 'article_URL',\n",
       "       'MBFC_factuality_label', 'article_URL2', 'MBFC_factuality_label2',\n",
       "       'URL_to_MBFC_page', 'source_name', 'MBFC_notes_about_source',\n",
       "       'MBFC_bias_label', 'source_URL', 'published_utc', 'label'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9cc7892d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "msn.com                        210\n",
       "The News International         103\n",
       "washingtonpost.com              62\n",
       "timesofindia.indiatimes.com     61\n",
       "Chicago Tribune                 53\n",
       "                              ... \n",
       "texastribune.org                 1\n",
       "Utah Public Radio (UPR)          1\n",
       "St. Louis Post-Dispatch          1\n",
       "kansas.com                       1\n",
       "National Review                  1\n",
       "Name: source_name, Length: 135, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"source_name\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "08651559",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "transformers.logging.set_verbosity_error()\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModel\n",
    "from transformers import TFDistilBertModel, DistilBertTokenizerFast\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from scipy.sparse import csr_matrix\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(\"using device:\", device)\n",
    "\n",
    "if \"disilbert_model\" not in locals():\n",
    "    disilbert_tokenizer =  AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "    disilbert_model = AutoModel.from_pretrained(\"distilbert-base-uncased\")\n",
    "    handle = disilbert_model.to(device)\n",
    "\n",
    "\n",
    "class BERTEmbeddings(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.tokenizer =  disilbert_tokenizer\n",
    "        self.model = disilbert_tokenizer\n",
    "        self.max_length = 256\n",
    "        self.model_name = disilbert_model\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        pass\n",
    "    \n",
    "    def encode(self, txt):\n",
    "        return self.tokenizer(txt, max_length=self.max_length, \n",
    "                              truncation=True, padding=True, return_tensors=\"pt\")\n",
    "\n",
    "    def transform(self, X=None):\n",
    "        dataloader = DataLoader(X, batch_size=16, shuffle=False)\n",
    "        allembeds = []\n",
    "        for batch in tqdm(dataloader):\n",
    "            batchenc = disilbert_tokenizer(batch, max_length=256, truncation=True, padding=True, return_tensors=\"pt\")\n",
    "            input_ids = batchenc['input_ids'].to(device)\n",
    "            attention_mask = batchenc['attention_mask'].to(device)\n",
    "            batchout = disilbert_model(input_ids, attention_mask=attention_mask, output_hidden_states=True)\n",
    "            embeds = [vec[0].cpu().detach().numpy() for vec in batchout[1][-1]]\n",
    "            allembeds.extend(embeds)\n",
    "        return csr_matrix(allembeds)\n",
    "\n",
    "\n",
    "class BertHead(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.head = LogisticRegression(class_weight='auto', max_iter=10000)\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.head.fit(X, y)\n",
    "\n",
    "\n",
    "    def transform(self, X=None):\n",
    "        pass\n",
    "    \n",
    "    def predict(self, X=None):    \n",
    "        return self.head.predict(X)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "940fa452",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:03<00:00, 31.75it/s]\n"
     ]
    }
   ],
   "source": [
    "bert = BERTEmbeddings()\n",
    "X_dstil_numpy = bert.transform(X).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9e4087a3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " BAC= 0.7476174334140435\n",
      " BAC= 0.7133849878934625\n",
      " BAC= 0.7368571428571429\n",
      " BAC= 0.7617094430992736\n",
      " BAC= 0.7133849878934625\n",
      " BAC= 0.7362857142857142\n",
      " BAC= 0.7258595641646489\n",
      " BAC= 0.7162421307506053\n",
      " BAC= 0.7351428571428571\n",
      " BAC= 0.7393801452784503\n",
      "----------\n",
      "AVG. BAC= 0.7325864406779661 +/- 0.014860929092860893\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "arr = []\n",
    "\n",
    "for fold,j in enumerate(foldids):\n",
    "    train = foldids[fold][1]\n",
    "    test = foldids[fold][2]\n",
    "    xin, yin = X_dstil_numpy[train], np.array(y[train])\n",
    "    cls = BertHead()\n",
    "    \n",
    "    cls.fit(xin, yin)\n",
    "    y_pred = cls.predict(X_dstil_numpy[test])\n",
    "\n",
    "    bac = balanced_accuracy_score(y[test], y_pred)\n",
    "    arr.append(bac)\n",
    "\n",
    "    print(\" BAC=\", bac)\n",
    "\n",
    "print(10*\"-\")\n",
    "print(\"AVG. BAC=\",np.mean(arr),\"+/-\",np.std(arr))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b77d67b",
   "metadata": {},
   "source": [
    "# Testy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c3d1ebf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fold = 1\n",
    "train = foldids[fold][1]\n",
    "test = foldids[fold][2]\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
