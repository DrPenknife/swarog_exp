{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79cd8f90",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2845/3486400938.py:57: DtypeWarning: Columns (2,4,5,8,9,10,11,12,13,15,21) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv(\"raw/grafn.csv\",sep=\",\")\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "DATA = {\n",
    "    \"X\" : [],\n",
    "    \"category\" : [],\n",
    "    \"y\" : []\n",
    "}\n",
    "\n",
    "X=DATA[\"X\"]\n",
    "category=DATA[\"category\"]\n",
    "y=DATA[\"y\"]\n",
    "\n",
    "\n",
    "with open('covid_fake_news_BERTEmbeddings.pickle', 'rb') as handle:\n",
    "    dst = pickle.load(handle)\n",
    "    X.extend(dst)\n",
    "    category.extend(np.repeat(0,len(dst)))\n",
    "    data = pd.read_csv(\"raw/covid_fake_news.csv\",sep=\"\\t\")\n",
    "    y.extend(data[\"label\"].values)\n",
    "    \n",
    "with open('mmcovid_en_BERTEmbeddings.pickle', 'rb') as handle:\n",
    "    dst = pickle.load(handle)\n",
    "    X.extend(dst)\n",
    "    category.extend(np.repeat(1,len(dst)))\n",
    "    data = pd.read_csv(\"raw/mmcovid_en.csv\",sep=\",\")\n",
    "    y.extend(data[\"label\"].values)\n",
    "    \n",
    "\n",
    "with open('pubhealth_BERTEmbeddings.pickle', 'rb') as handle:\n",
    "    dst = pickle.load(handle)\n",
    "    X.extend(dst)\n",
    "    category.extend(np.repeat(2,len(dst)))\n",
    "    data = pd.read_csv(\"raw/pubhealth.csv\",sep=\",\")\n",
    "    y.extend(data[\"label\"].values)\n",
    "\n",
    "    \n",
    "with open('qprop_BERTEmbeddings.pickle', 'rb') as handle:\n",
    "    dst = pickle.load(handle)\n",
    "    X.extend(dst)\n",
    "    category.extend(np.repeat(3,len(dst)))\n",
    "    data = pd.read_csv(\"raw/qprop.csv\",sep=\"\\t\")\n",
    "    y.extend(data[\"label\"].values)\n",
    "    \n",
    "with open('isot_BERTEmbeddings.pickle', 'rb') as handle:\n",
    "    dst = pickle.load(handle)\n",
    "    X.extend(dst)\n",
    "    category.extend(np.repeat(4,len(dst)))\n",
    "    data = pd.read_csv(\"raw/isot.csv\",sep=\",\")\n",
    "    y.extend(data[\"label\"].values)\n",
    "    \n",
    "with open('grafn_BERTEmbeddings.pickle', 'rb') as handle:\n",
    "    dst = pickle.load(handle)\n",
    "    X.extend(dst)\n",
    "    category.extend(np.repeat(5,len(dst)))\n",
    "    data = pd.read_csv(\"raw/grafn.csv\",sep=\",\")\n",
    "    y.extend(data[\"label\"].values)\n",
    "    \n",
    "    \n",
    "DATA[\"X\"]=np.array(X)\n",
    "DATA[\"category\"]=np.array(category)\n",
    "DATA[\"y\"]=np.array(y)\n",
    "DATA[\"folds\"] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "794f2c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, f1_score, precision_score, recall_score, roc_auc_score\n",
    "from imblearn.metrics import geometric_mean_score\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def experiment(foldids, X, y, cls = LogisticRegression(max_iter=10000), fit=True):\n",
    "\n",
    "    scores = {\n",
    "        'Accuracy': {'func': accuracy_score},\n",
    "        'Balanced Accuracy': {'func': balanced_accuracy_score},\n",
    "        'F1': {'func': f1_score},\n",
    "        'Precision': {'func': precision_score},\n",
    "        'Recall': {'func': recall_score},\n",
    "        'G-mean': {'func': geometric_mean_score}\n",
    "    }\n",
    "\n",
    "    for score_name, score_dict in scores.items():\n",
    "        scores[score_name][\"list\"] = []\n",
    "        scores[score_name][\"lab\"] = []\n",
    "\n",
    "    for fold,j in enumerate(foldids):\n",
    "        train = foldids[fold][1]\n",
    "        test = foldids[fold][2]\n",
    "        xin, yin = X[train], np.array(y[train])\n",
    "        \n",
    "        pca = PCA(n_components=128)\n",
    "        pca.fit(xin)\n",
    "        \n",
    "        \n",
    "        if fit == True:\n",
    "            cls.fit(pca.transform(xin), yin)\n",
    "        y_pred = cls.predict(pca.transform(X[test]))\n",
    "        for score_name, score_dict in scores.items():\n",
    "            if score_name in [\"F1\",\"Precision\",\"Recall\"]:\n",
    "                scorvaln = score_dict['func'](y[test], y_pred, average=None)\n",
    "                score_dict['lab'].append(scorvaln)\n",
    "                scorval = score_dict['func'](y[test], y_pred, average=\"weighted\")\n",
    "                score_dict['list'].append(scorval)\n",
    "                #print(score_name, scorval, scorvaln)  \n",
    "            else:\n",
    "                scorval=score_dict['func'](y[test], y_pred)\n",
    "                score_dict['list'].append(scorval)\n",
    "                #print(score_name, scorval)\n",
    "        #print(\" \")\n",
    "\n",
    "    #clear_output()\n",
    "    for score_name, score_dict in scores.items():\n",
    "        score_dict['avg'] = np.mean(score_dict['list'])\n",
    "        score_dict['std'] = np.std(score_dict['list'])\n",
    " \n",
    "    # Print stats\n",
    "    numlabels = scores[\"F1\"][\"lab\"][0].shape[0]\n",
    "    scores[\"F1\"][\"lab\"][0].shape[0] \n",
    "    head = \"| %-20s | %-10s |\" +  numlabels * \" %-10s |\" \n",
    "    headv = [\"Score\", \"Average\"]\n",
    "    headv.extend([\"Kat_\"+str(i+1) for i in range(numlabels)])\n",
    "    row=head % tuple(headv)\n",
    "    print(\"+\"*len(row))\n",
    "    print(row)\n",
    "    print(\"+\"*len(row))\n",
    "    for score_name, score_dict in sorted(scores.items()) :\n",
    "        headv = [score_name, np.mean(score_dict['list'])*100, np.std(score_dict['list'])*100]\n",
    "        for i in range(numlabels):\n",
    "            if score_name in [\"F1\",\"Precision\",\"Recall\"]:\n",
    "                head = \"| %-20s | %4.1f ± %3.1f |\" + numlabels* \" %4.1f ± %3.1f |\"\n",
    "                vals = [v[i] for v in scores[score_name][\"lab\"]]\n",
    "                headv.append(np.mean(vals)*100)\n",
    "                headv.append(np.std(vals)*100)\n",
    "            else:\n",
    "                head = \"| %-20s | %4.1f ± %3.1f |\" + numlabels * \" %-10s |\" \n",
    "                headv.append(\"-\")\n",
    "        print(head % tuple(headv))\n",
    "    print(\"+\"*len(row))\n",
    "    return cls, scores, pca"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "808eb41d",
   "metadata": {},
   "source": [
    "<hr style=\"border: 5px dashed red\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "802f574d",
   "metadata": {},
   "source": [
    "# Single Task Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f5479333",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TASK 0\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "| Score                | Average    | Kat_1      | Kat_2      |\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "| Accuracy             | 96.9 ± 0.1 | -          | -          |\n",
      "| Balanced Accuracy    | 77.2 ± 1.3 | -          | -          |\n",
      "| F1                   | 96.7 ± 0.2 | 98.4 ± 0.1 | 65.0 ± 1.8 |\n",
      "| G-mean               | 74.0 ± 1.7 | -          | -          |\n",
      "| Precision            | 96.7 ± 0.2 | 97.6 ± 0.1 | 79.2 ± 3.0 |\n",
      "| Recall               | 96.9 ± 0.1 | 99.2 ± 0.2 | 55.2 ± 2.6 |\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "TASK 1\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "| Score                | Average    | Kat_1      | Kat_2      |\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "| Accuracy             | 92.2 ± 0.3 | -          | -          |\n",
      "| Balanced Accuracy    | 87.6 ± 0.8 | -          | -          |\n",
      "| F1                   | 92.0 ± 0.4 | 94.8 ± 0.2 | 84.6 ± 0.9 |\n",
      "| G-mean               | 87.0 ± 0.9 | -          | -          |\n",
      "| Precision            | 92.3 ± 0.3 | 91.9 ± 0.6 | 93.2 ± 0.9 |\n",
      "| Recall               | 92.2 ± 0.3 | 97.8 ± 0.4 | 77.5 ± 1.9 |\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "TASK 2\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "| Score                | Average    | Kat_1      | Kat_2      |\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "| Accuracy             | 80.3 ± 0.5 | -          | -          |\n",
      "| Balanced Accuracy    | 78.8 ± 0.6 | -          | -          |\n",
      "| F1                   | 80.2 ± 0.5 | 73.5 ± 0.7 | 84.3 ± 0.5 |\n",
      "| G-mean               | 78.6 ± 0.6 | -          | -          |\n",
      "| Precision            | 80.2 ± 0.5 | 73.9 ± 0.9 | 84.0 ± 0.4 |\n",
      "| Recall               | 80.3 ± 0.5 | 73.1 ± 0.8 | 84.6 ± 0.7 |\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "TASK 3\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "| Score                | Average    | Kat_1      | Kat_2      |\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "| Accuracy             | 93.1 ± 0.1 | -          | -          |\n",
      "| Balanced Accuracy    | 76.8 ± 0.4 | -          | -          |\n",
      "| F1                   | 92.6 ± 0.1 | 96.2 ± 0.1 | 64.4 ± 0.5 |\n",
      "| G-mean               | 73.9 ± 0.6 | -          | -          |\n",
      "| Precision            | 92.5 ± 0.1 | 94.6 ± 0.1 | 76.0 ± 1.1 |\n",
      "| Recall               | 93.1 ± 0.1 | 97.8 ± 0.2 | 55.8 ± 1.0 |\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "TASK 4\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "| Score                | Average    | Kat_1      | Kat_2      |\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "| Accuracy             | 99.2 ± 0.1 | -          | -          |\n",
      "| Balanced Accuracy    | 99.2 ± 0.1 | -          | -          |\n",
      "| F1                   | 99.2 ± 0.1 | 99.2 ± 0.1 | 99.3 ± 0.1 |\n",
      "| G-mean               | 99.2 ± 0.1 | -          | -          |\n",
      "| Precision            | 99.2 ± 0.1 | 99.1 ± 0.1 | 99.4 ± 0.1 |\n",
      "| Recall               | 99.2 ± 0.1 | 99.3 ± 0.1 | 99.2 ± 0.1 |\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "TASK 5\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "| Score                | Average    | Kat_1      | Kat_2      |\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "| Accuracy             | 88.8 ± 0.1 | -          | -          |\n",
      "| Balanced Accuracy    | 79.9 ± 0.3 | -          | -          |\n",
      "| F1                   | 88.5 ± 0.1 | 93.1 ± 0.1 | 70.2 ± 0.4 |\n",
      "| G-mean               | 78.4 ± 0.3 | -          | -          |\n",
      "| Precision            | 88.4 ± 0.1 | 91.3 ± 0.1 | 76.8 ± 0.5 |\n",
      "| Recall               | 88.8 ± 0.1 | 95.0 ± 0.1 | 64.7 ± 0.5 |\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "DATA[\"folds\"] = []\n",
    "rskf = RepeatedStratifiedKFold(n_splits=2, n_repeats=5, random_state=1410)\n",
    "\n",
    "stl=[]\n",
    "\n",
    "for t in range(np.max(DATA[\"category\"]+1)):\n",
    "    print(\"TASK\",t)\n",
    "    X = DATA[\"X\"][DATA[\"category\"] == t]\n",
    "    y = DATA[\"y\"][DATA[\"category\"] == t]\n",
    "\n",
    "    foldids = []\n",
    "    for fold_idx, (train, test) in enumerate(rskf.split(X, y)):\n",
    "        foldids.append((fold_idx,train,test))\n",
    "\n",
    "    #print(\"shapes X\",X.shape,\"y\", y.shape)\n",
    "    DATA[\"folds\"].append(foldids)\n",
    "    model1, scores1, pca = experiment(foldids, X, y, \n",
    "                                 LogisticRegression(max_iter=10000))\n",
    "    stl.append((model1,pca,scores1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4173836e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STL- 0\n",
      "STL- 1\n",
      "STL- 2\n",
      "STL- 3\n",
      "STL- 4\n",
      "STL- 5\n",
      "50.1 ± 0.43 &\n",
      "68.9 ± 0.42 &\n",
      "41.3 ± 0.52 &\n",
      "77.3 ± 0.21 &\n",
      "89.4 ± 0.15 &\n",
      "74.1 ± 0.11 &\n",
      "---\n",
      "66.86956697284273 16.370773622340355\n"
     ]
    }
   ],
   "source": [
    "T = np.max(DATA[\"category\"])+1\n",
    "d = 128\n",
    "\n",
    "stl_bacs = [[] for b in range(T)]\n",
    "\n",
    "ft = 0\n",
    "\n",
    "for ft in range(6):\n",
    "    print(\"STL-\",ft)\n",
    "    for _foldid in range(10):\n",
    "        #print(\"fold\",_foldid)\n",
    "\n",
    "        ##### Test\n",
    "        for task in range(T):\n",
    "            X = DATA[\"X\"][DATA[\"category\"] == task]\n",
    "            y = DATA[\"y\"][DATA[\"category\"] == task]\n",
    "            foldids = DATA[\"folds\"][task]\n",
    "\n",
    "            train = foldids[_foldid][1]\n",
    "            test = foldids[_foldid][2]    \n",
    "\n",
    "            X=stl[ft][1].transform(X[test])\n",
    "\n",
    "            #print(np.unique(domain_pred, return_counts=True))\n",
    "            #print(\"task\",task, pred_task_id)\n",
    "\n",
    "            pred=stl[ft][0].predict(X)\n",
    "            bac = balanced_accuracy_score(y[test], pred)\n",
    "            #print(task,bac)\n",
    "            stl_bacs[task].append(bac)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "379ab0b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50.8 ± 13.78 &\n",
      "56.9 ± 15.20 &\n",
      "48.1 ± 14.90 &\n",
      "57.0 ± 17.17 &\n",
      "58.7 ± 23.76 &\n",
      "54.7 ± 14.58 &\n",
      "---\n",
      "54.36844556864055 17.319565221417843\n"
     ]
    }
   ],
   "source": [
    "for t in range(T):\n",
    "    print(\"%3.1f ± %3.2f &\" % (np.mean(stl_bacs[t])*100, 100*np.std(stl_bacs[t])) )\n",
    "\n",
    "print(\"---\")\n",
    "print(np.mean(np.array(stl_bacs).flatten())*100, np.std(np.array(stl_bacs).flatten())*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98cbdf68",
   "metadata": {},
   "source": [
    "# Batch Multi Task Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "98df1a72",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 10/10 [00:00<00:00, 169.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shapes X (186477, 768) y (186477,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "| Score                | Average    | Kat_1      | Kat_2      |\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "| Accuracy             | 84.5 ± 0.1 | -          | -          |\n",
      "| Balanced Accuracy    | 77.7 ± 0.1 | -          | -          |\n",
      "| F1                   | 84.0 ± 0.1 | 89.7 ± 0.1 | 68.9 ± 0.2 |\n",
      "| G-mean               | 76.3 ± 0.2 | -          | -          |\n",
      "| Precision            | 84.0 ± 0.1 | 86.9 ± 0.1 | 76.3 ± 0.3 |\n",
      "| Recall               | 84.5 ± 0.1 | 92.7 ± 0.1 | 62.8 ± 0.3 |\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n"
     ]
    }
   ],
   "source": [
    "X = DATA[\"X\"]\n",
    "y = DATA[\"y\"]\n",
    "\n",
    "rskf = RepeatedStratifiedKFold(n_splits=2, n_repeats=5, random_state=1410)\n",
    "foldids = []\n",
    "for fold_idx, (train, test) in tqdm(enumerate(rskf.split(X, y)), total=rskf.get_n_splits()):\n",
    "    foldids.append((fold_idx,train,test))\n",
    "    \n",
    "print(\"shapes X\",X.shape,\"y\", y.shape)\n",
    "\n",
    "model3, scores3, model3_pca = experiment(foldids, X, y, \n",
    "                             LogisticRegression(max_iter=10000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4afa71b2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0\n",
      "0 0.49759623242889833\n",
      "1 0.6827648219050935\n",
      "2 0.42324744822202087\n",
      "3 0.7740426345626505\n",
      "4 0.8954930213517331\n",
      "5 0.7415292180821338\n",
      "fold 1\n",
      "0 0.5046861090339351\n",
      "1 0.6956143404107205\n",
      "2 0.40334829229467034\n",
      "3 0.7721165139737413\n",
      "4 0.8929018452055881\n",
      "5 0.7409854492895602\n",
      "fold 2\n",
      "0 0.507643429225237\n",
      "1 0.6899727346559925\n",
      "2 0.4081338054532713\n",
      "3 0.7723664995930211\n",
      "4 0.893690589254943\n",
      "5 0.7411778912232476\n",
      "fold 3\n",
      "0 0.4946861599035512\n",
      "1 0.6884064276598213\n",
      "2 0.4184691154516677\n",
      "3 0.7737926489433709\n",
      "4 0.8947044891947944\n",
      "5 0.7413364206470661\n",
      "fold 4\n",
      "0 0.495481570774763\n",
      "1 0.6918581041884209\n",
      "2 0.41274118119158965\n",
      "3 0.7720576816661714\n",
      "4 0.8970492567177326\n",
      "5 0.741581899741727\n",
      "fold 5\n",
      "0 0.5068012676708329\n",
      "1 0.6865210581273931\n",
      "2 0.41386047258601155\n",
      "3 0.7741014668702204\n",
      "4 0.8913456106829852\n",
      "5 0.7409325319905253\n",
      "fold 6\n",
      "0 0.499711915658712\n",
      "1 0.682822833275322\n",
      "2 0.41168017323402994\n",
      "3 0.7746342426910564\n",
      "4 0.8953652639205092\n",
      "5 0.7428369103898261\n",
      "fold 7\n",
      "0 0.5025897721549896\n",
      "1 0.6955563290404919\n",
      "2 0.41492204371127694\n",
      "3 0.7715249058453355\n",
      "4 0.8930296135190464\n",
      "5 0.7396775557674798\n",
      "fold 8\n",
      "0 0.4995944344557045\n",
      "1 0.6888270100939784\n",
      "2 0.41105443764979843\n",
      "3 0.7689936234140546\n",
      "4 0.8939050216163156\n",
      "5 0.7430873144134483\n",
      "fold 9\n",
      "0 0.5027072809681505\n",
      "1 0.6895521522218355\n",
      "2 0.4155465121681706\n",
      "3 0.7771655251223373\n",
      "4 0.8944899551922049\n",
      "5 0.7394271170064561\n"
     ]
    }
   ],
   "source": [
    "T = np.max(DATA[\"category\"])+1\n",
    "d = 128\n",
    "\n",
    "_bacs = [[] for b in range(T)]\n",
    "\n",
    "\n",
    "for _foldid in range(10):\n",
    "    print(\"fold\",_foldid)\n",
    "\n",
    "    ##### Test\n",
    "    for task in range(T):\n",
    "        X = DATA[\"X\"][DATA[\"category\"] == task]\n",
    "        y = DATA[\"y\"][DATA[\"category\"] == task]\n",
    "        foldids = DATA[\"folds\"][task]\n",
    "        \n",
    "        train = foldids[_foldid][1]\n",
    "        test = foldids[_foldid][2]    \n",
    "        \n",
    "        X=model3_pca.transform(X[test])\n",
    "\n",
    "        #print(np.unique(domain_pred, return_counts=True))\n",
    "        #print(\"task\",task, pred_task_id)\n",
    "\n",
    "        pred=model3.predict(X)\n",
    "        bac = balanced_accuracy_score(y[test], pred)\n",
    "        print(task,bac)\n",
    "        _bacs[task].append(bac)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b35d890d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50.1 ± 0.43 &\n",
      "68.9 ± 0.42 &\n",
      "41.3 ± 0.52 &\n",
      "77.3 ± 0.21 &\n",
      "89.4 ± 0.15 &\n",
      "74.1 ± 0.11 &\n",
      "---\n",
      "66.86956697284273 16.370773622340355\n"
     ]
    }
   ],
   "source": [
    "for t in range(T):\n",
    "    print(\"%3.1f ± %3.2f &\" % (np.mean(_bacs[t])*100, 100*np.std(_bacs[t])) )\n",
    "\n",
    "print(\"---\")\n",
    "print(np.mean(np.array(_bacs).flatten())*100, np.std(np.array(_bacs).flatten())*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1942b16",
   "metadata": {},
   "source": [
    "<hr style=\"border: 5px dashed red\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "066c1796",
   "metadata": {},
   "source": [
    "# Domain Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c8936f91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shapes X (186477, 768) y (186477,)\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "| Score                | Average    | Kat_1      | Kat_2      | Kat_3      | Kat_4      | Kat_5      | Kat_6      |\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "| Accuracy             | 71.3 ± 0.2 | -          | -          | -          | -          | -          | -          |\n",
      "| Balanced Accuracy    | 80.0 ± 0.2 | -          | -          | -          | -          | -          | -          |\n",
      "| F1                   | 71.2 ± 0.2 | 94.7 ± 0.2 | 77.2 ± 0.4 | 64.0 ± 0.2 | 64.0 ± 0.2 | 76.4 ± 0.3 | 70.4 ± 0.2 |\n",
      "| G-mean               | 78.9 ± 0.2 | -          | -          | -          | -          | -          | -          |\n",
      "| Precision            | 72.3 ± 0.2 | 92.2 ± 0.3 | 67.5 ± 0.5 | 51.1 ± 0.3 | 65.8 ± 0.3 | 72.8 ± 0.5 | 78.4 ± 0.4 |\n",
      "| Recall               | 71.3 ± 0.2 | 97.4 ± 0.2 | 90.1 ± 0.8 | 85.6 ± 0.3 | 62.3 ± 0.2 | 80.5 ± 0.6 | 63.9 ± 0.3 |\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n"
     ]
    }
   ],
   "source": [
    "X = DATA[\"X\"]\n",
    "y = DATA[\"y\"]\n",
    "category = DATA[\"category\"]\n",
    "\n",
    "rskf = RepeatedStratifiedKFold(n_splits=2, n_repeats=5, random_state=1410)\n",
    "foldids = []\n",
    "for fold_idx, (train, test) in enumerate(rskf.split(X, y)):\n",
    "    foldids.append((fold_idx,train,test))\n",
    "    \n",
    "print(\"shapes X\",X.shape,\"y\", category.shape)\n",
    "\n",
    "domain_model, domain_scores, domain_pca = experiment(foldids, X, \n",
    "                                         category, LogisticRegression(max_iter=10000, class_weight='balanced'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c5419e",
   "metadata": {},
   "source": [
    "<hr style=\"border: 5px dashed red\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c15dfd22",
   "metadata": {},
   "source": [
    "# ParamMultitaskShare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bee7b30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class SparseNet(nn.Module):\n",
    "\n",
    "    def __init__(self, K:int=32, M:int=128, R_lr:float=0.1, lmda:float=5e-3, device=None):\n",
    "        super(SparseNet, self).__init__()\n",
    "        self.K = K\n",
    "        self.M = M\n",
    "        self.R_lr = R_lr\n",
    "        self.lmda = lmda\n",
    "        # synaptic weights\n",
    "        self.device = torch.device(\"cpu\") if device is None else device\n",
    "        self.U = nn.Linear(self.K, self.M, bias=False).to(self.device)\n",
    "        # responses\n",
    "        self.R = None\n",
    "        self.normalize_weights()\n",
    "\n",
    "    def ista_(self, img_batch):\n",
    "        # create R\n",
    "        self.R = torch.zeros((img_batch.shape[0], self.K), requires_grad=True, device=self.device)\n",
    "        converged = False\n",
    "        # update R\n",
    "        optim = torch.optim.SGD([{'params': self.R, \"lr\": self.R_lr}])\n",
    "        # train\n",
    "        while not converged:\n",
    "            old_R = self.R.clone().detach()\n",
    "            # pred\n",
    "            pred = self.U(self.R)\n",
    "            # loss\n",
    "            loss = ((img_batch - pred) ** 2).sum()\n",
    "            loss.backward()\n",
    "            # update R in place\n",
    "            optim.step()\n",
    "            # zero grad\n",
    "            self.zero_grad()\n",
    "            # prox\n",
    "            self.R.data = SparseNet.soft_thresholding_(self.R, self.lmda)\n",
    "            # convergence\n",
    "            converged = torch.norm(self.R - old_R) / torch.norm(old_R) < 0.01\n",
    "\n",
    "    @staticmethod\n",
    "    def soft_thresholding_(x, alpha):\n",
    "        with torch.no_grad():\n",
    "            rtn = F.relu(x - alpha) - F.relu(-x - alpha)\n",
    "        return rtn.data\n",
    "\n",
    "    def zero_grad(self):\n",
    "        self.R.grad.zero_()\n",
    "        self.U.zero_grad()\n",
    "\n",
    "    def normalize_weights(self):\n",
    "        with torch.no_grad():\n",
    "            self.U.weight.data = F.normalize(self.U.weight.data, dim=0)\n",
    "\n",
    "    def forward(self, img_batch):\n",
    "        # first fit\n",
    "        self.ista_(img_batch)\n",
    "        # now predict again\n",
    "        pred = self.U(self.R)\n",
    "        return pred, self.R\n",
    "\n",
    "\n",
    "from math import log\n",
    "import numpy as np\n",
    "from scipy.special import logsumexp\n",
    "from scipy.linalg import sqrtm, inv, norm\n",
    "from sklearn.linear_model import LinearRegression, Ridge, LogisticRegression, Lasso\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, explained_variance_score\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "class ParamMultitaskShare(object):\n",
    "    def __init__(self):\n",
    "        self.net = SparseNet()\n",
    "        self.base_learner = LogisticRegression\n",
    "        self.codes = []\n",
    "\n",
    "    def fit(self, X, y, task_id):\n",
    "        single_task_model = self.base_learner(max_iter=10000, class_weight='balanced')\n",
    "        single_task_model.fit(X,y)\n",
    "        theta_t = torch.tensor(single_task_model.coef_)\n",
    "        optim = torch.optim.SGD([{'params': self.net.U.weight, \"lr\": 1e-2}])\n",
    "        \n",
    "        running_loss = 0\n",
    "        code = None\n",
    "        for c in range(50):\n",
    "            pred, code = self.net.forward(theta_t)\n",
    "            loss = ((theta_t - pred) ** 2).sum()\n",
    "            running_loss += loss.item()\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "            self.net.zero_grad()\n",
    "            self.net.normalize_weights()\n",
    "            #print('Loss', running_loss / (c+1))\n",
    "        \n",
    "        self.codes.append(code.clone().detach().numpy()[0])\n",
    "#        tpred = self.predict(X,task_id)\n",
    "#         print()\n",
    "#         print(\"PMS-BAC:\", balanced_accuracy_score(y,tpred))\n",
    "#         print(\"T-BAC:\", balanced_accuracy_score(y,single_task_model.predict(X)))\n",
    "\n",
    "    def predict(self, X, task_id):\n",
    "        code = self.codes[task_id]\n",
    "        theta_t = self.net.U(torch.tensor(code)).detach().numpy()\n",
    "        sign = 1. / (1.0 + np.exp(-X.dot(theta_t)))\n",
    "        pred = [1 if p > 0.5 else 0 for p in sign]\n",
    "        return np.array(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a8c9fb9",
   "metadata": {},
   "source": [
    "\n",
    "# Param Share Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f029b62",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0\n",
      "0 0.7794857388035306\n",
      "1 0.8677195730363152\n",
      "2 0.77578837383621\n",
      "3 0.7648214916142482\n",
      "4 0.9863031020955114\n",
      "5 0.7883114984367685\n",
      "fold 1\n",
      "0 0.7713654931046235\n",
      "1 0.8522885485555168\n",
      "2 0.7911154274263112\n",
      "3 0.7765563201381726\n",
      "4 0.9869026880063785\n",
      "5 0.7903763432628574\n",
      "fold 2\n",
      "0 0.7750204315135665\n",
      "1 0.8394825385775613\n",
      "2 0.7787028647719616\n",
      "3 0.7714799258928865\n",
      "4 0.985105087844648\n",
      "5 0.788729402347113\n",
      "fold 3\n",
      "0 0.7561081691516474\n",
      "1 0.8481407355841746\n",
      "2 0.7895485747069316\n",
      "3 0.7601865119687106\n",
      "4 0.9853186782821945\n",
      "5 0.7905926588854593\n",
      "fold 4\n",
      "0 0.7614518633540373\n",
      "1 0.8576981088293305\n",
      "2 0.7598928560311808\n",
      "3 0.7621657677108448\n",
      "4 0.9847894525399199\n",
      "5 0.7912634234016523\n",
      "fold 5\n",
      "0 0.7830482091351656\n",
      "1 0.861236802413273\n",
      "2 0.7936239068645572\n",
      "3 0.7713701178373675\n",
      "4 0.985969820636784\n",
      "5 0.7877845738327256\n",
      "fold 6\n",
      "0 0.7538727933965348\n",
      "1 0.8612658080983873\n",
      "2 0.8040812463562554\n",
      "3 0.7647859762891788\n",
      "4 0.9841629901341229\n",
      "5 0.7854533824706611\n",
      "fold 7\n",
      "0 0.7692009909401214\n",
      "1 0.8606566887109874\n",
      "2 0.7787265590752716\n",
      "3 0.7693678207814916\n",
      "4 0.9877544767627668\n",
      "5 0.7902120265298987\n",
      "fold 8\n",
      "0 0.7824809986923831\n",
      "1 0.8328692423715048\n",
      "2 0.7842331121638186\n",
      "3 0.7680693749835747\n",
      "4 0.9810818820936514\n",
      "5 0.7884955670679212\n",
      "fold 9\n",
      "0 0.767487702270311\n",
      "1 0.8661967745678153\n",
      "2 0.781852941592377\n",
      "3 0.7783758717794768\n",
      "4 0.9831948934671485\n",
      "5 0.7870340974108747\n"
     ]
    }
   ],
   "source": [
    "T = np.max(DATA[\"category\"])+1\n",
    "d = 128\n",
    "\n",
    "bacs = [[] for b in range(T)]\n",
    "\n",
    "\n",
    "for _foldid in range(10):\n",
    "    print(\"fold\",_foldid)\n",
    "    ella = ParamMultitaskShare()\n",
    "\n",
    "    ### Train\n",
    "    for task in range(T):\n",
    "        #print(\"TASK\", task)\n",
    "        X = DATA[\"X\"][DATA[\"category\"] == task]\n",
    "        y = DATA[\"y\"][DATA[\"category\"] == task]\n",
    "        foldids = DATA[\"folds\"][task]\n",
    "       \n",
    "        train = foldids[_foldid][1]\n",
    "        test = foldids[_foldid][2]\n",
    "        \n",
    "        pca = PCA(n_components=d)\n",
    "        pca.fit_transform(X[train])\n",
    "        X=pca.transform(X[train])\n",
    "\n",
    "\n",
    "        ella.fit(X, y[train], task)\n",
    "        \n",
    "    ##### Test\n",
    "    for task in range(T):\n",
    "        X = DATA[\"X\"][DATA[\"category\"] == task]\n",
    "        y = DATA[\"y\"][DATA[\"category\"] == task]\n",
    "        foldids = DATA[\"folds\"][task]\n",
    "        \n",
    "        train = foldids[_foldid][1]\n",
    "        test = foldids[_foldid][2]    \n",
    "        \n",
    "        domain_pred=domain_model.predict(domain_pca.transform(X[test]))\n",
    "        pred_task_id = np.argmax(np.unique(domain_pred, return_counts=True)[1])\n",
    "        \n",
    "        pca = PCA(n_components=d)\n",
    "        pca.fit_transform(X[train])\n",
    "        \n",
    "        X=pca.transform(X[test])\n",
    "\n",
    "        #print(np.unique(domain_pred, return_counts=True))\n",
    "        #print(\"task\",task, pred_task_id)\n",
    "\n",
    "        pred=ella.predict(X, pred_task_id)\n",
    "        bac = balanced_accuracy_score(y[test], pred)\n",
    "        print(task,bac)\n",
    "        bacs[task].append(bac)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f771bd3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77.0 ± 1.0 &\n",
      "85.5 ± 1.1 &\n",
      "78.4 ± 1.1 &\n",
      "76.9 ± 0.6 &\n",
      "98.5 ± 0.2 &\n",
      "78.9 ± 0.2 &\n",
      "---\n",
      "82.51776383072779 7.756120196367812\n"
     ]
    }
   ],
   "source": [
    "for t in range(T):\n",
    "    print(\"%3.1f ± %3.1f &\" % (np.mean(bacs[t])*100, 100*np.std(bacs[t])) )\n",
    "\n",
    "print(\"---\")\n",
    "print(np.mean(np.array(bacs).flatten())*100, np.std(np.array(bacs).flatten())*100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
