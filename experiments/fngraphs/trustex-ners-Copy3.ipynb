{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25c253dd-4f4d-4d21-95ad-b13158f36ac0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b8c529a-ae5c-4661-8a68-f4e3bb333b80",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "rskf = RepeatedStratifiedKFold(n_splits=10, n_repeats=1, random_state=1410)\n",
    "\n",
    "class DatasetLoader:\n",
    "    def get(self, name):\n",
    "        print(f\"loading {name}\")\n",
    "        if name == \"fnkdd\":\n",
    "            data = pd.read_csv(\"/home/rkozik/Desktop/swarog_exp_disk/datasets/fakenewskdd/train.csv\",sep=\"\\t\")\n",
    "            data.head()\n",
    "            body = data[\"text\"].values\n",
    "            labels = 1-data[\"label\"].values\n",
    "            total_number_of_claims = data.shape[0]\n",
    "            print(\"total_number_of_claims=\",total_number_of_claims)\n",
    "            print(\"labels fake=\",sum(labels),\"real=\", len(labels)-sum(labels))\n",
    "        \n",
    "        if name == \"mmcovid\":\n",
    "            data = pd.read_csv(\"/media/rkozik/02FF-A831/data/swarog/datasets/mmcovid/news_collection.csv\",sep=\"\\t\")\n",
    "            data[\"label\"] = [ 1 if v ==\"fake\" else 0 for v in data[\"label\"]]\n",
    "            data[\"text\"] = [ str(v) for v in data[\"text\"]]\n",
    "            data = data[data[\"lang\"] == \"en\"]\n",
    "\n",
    "            body = data[\"text\"].values\n",
    "            labels = data[\"label\"].values\n",
    "            total_number_of_claims = data.shape[0]\n",
    "            print(\"total_number_of_claims=\",total_number_of_claims)\n",
    "            print(\"labels fake=\",sum(labels),\"real=\", len(labels)-sum(labels))\n",
    "        \n",
    "        if name == \"liar\":\n",
    "            data = pd.read_csv(\"/media/rkozik/02FF-A831/data/swarog/datasets/liar.csv\", sep=\"\\t\",encoding=\"utf-8\")\n",
    "            def mpx(x):\n",
    "                if x in [0,2]:\n",
    "                    return 0\n",
    "                elif x in [4,5]:\n",
    "                    return 1\n",
    "                else:\n",
    "                    return -1\n",
    "            data[\"text\"] = data[\"statement\"]\n",
    "            data[\"label\"] = [mpx(x) for x in data[\"label\"]]\n",
    "            data=data[ data[\"label\"] != -1] \n",
    "            body = data[\"text\"].values\n",
    "            labels = data[\"label\"].values\n",
    "            total_number_of_claims = data.shape[0]\n",
    "            print(\"total_number_of_claims=\",total_number_of_claims)\n",
    "            print(\"labels fake=\",sum(labels),\"real=\", len(labels)-sum(labels))\n",
    "\n",
    "        if name == \"covidfn\":\n",
    "            data = pd.read_csv(\"covid_fake_news.csv\", sep=\",\")\n",
    "            body = data[\"headlines\"].values\n",
    "            labels = 1 - data[\"outcome\"].values\n",
    "            total_number_of_claims = data.shape[0]\n",
    "            print(\"total_number_of_claims=\",total_number_of_claims)\n",
    "            print(\"labels fake=\",sum(labels),\"real=\", len(labels)-sum(labels))\n",
    "        \n",
    "        return body, labels, total_number_of_claims"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ec5cb3-4b6a-42d7-85ee-b5af2327ed5b",
   "metadata": {},
   "source": [
    "# Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4d1d03d0-9868-4c57-8677-c8ccb6f2a455",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, f1_score, precision_score, recall_score, roc_auc_score\n",
    "from imblearn.metrics import geometric_mean_score\n",
    "from IPython.display import clear_output\n",
    "\n",
    "\n",
    "\n",
    "class Metrics:\n",
    "    def __init__(self):\n",
    "        self.scores = {\n",
    "            'Accuracy': {'func': accuracy_score},\n",
    "            'Balanced Accuracy': {'func': balanced_accuracy_score},\n",
    "            'F1': {'func': f1_score},\n",
    "            'Precision': {'func': precision_score},\n",
    "            'Recall': {'func': recall_score},\n",
    "            'G-mean': {'func': geometric_mean_score}\n",
    "        }\n",
    "        \n",
    "        for score_name, score_dict in self.scores.items():\n",
    "            score_dict[\"list\"] = []\n",
    "            score_dict[\"lab\"] = []\n",
    "\n",
    "    def update(self, actual, prediction):\n",
    "        for score_name, score_dict in self.scores.items():\n",
    "            if score_name in [\"F1\",\"Precision\",\"Recall\",\"G-mean\"]:\n",
    "                scorvaln = score_dict['func'](actual, prediction, average=None)\n",
    "                score_dict['lab'].append(scorvaln)\n",
    "                scorval = score_dict['func'](actual, prediction, average=\"weighted\")\n",
    "                score_dict['list'].append(scorval)\n",
    "                #print(score_name, scorval, scorvaln)  \n",
    "            else:\n",
    "                scorval=score_dict['func'](actual, prediction)\n",
    "                score_dict['list'].append(scorval)\n",
    "                \n",
    "    def print_table(self, labels=None):\n",
    "        # Print stats\n",
    "        scores = self.scores\n",
    "        numlabels = scores[\"F1\"][\"lab\"][0].shape[0]\n",
    "        scores[\"F1\"][\"lab\"][0].shape[0] \n",
    "        head = \"  %-20s  %-10s  \" +  numlabels * \" %-10s  \" \n",
    "        headv = [\"Score\", \"Average\"]\n",
    "        if labels:\n",
    "            headv.extend([labels[i] for i in range(numlabels)])\n",
    "        else:\n",
    "            headv.extend([\"Lab:\"+str(i+1) for i in range(numlabels)])\n",
    "        row=head % tuple(headv)\n",
    "        # table header\n",
    "        print(\"―\"*len(row))\n",
    "        print(row)\n",
    "        print(\"―\"*len(row))\n",
    "        # table rows\n",
    "        for score_name, score_dict in sorted(scores.items()) :\n",
    "            headv = [score_name, np.mean(score_dict['list'])*100, np.std(score_dict['list'])*100]\n",
    "            for i in range(numlabels):\n",
    "                if score_name in [\"F1\",\"Precision\",\"Recall\", \"G-mean\"]:\n",
    "                    head = \"  %-20s  %4.1f ± %4.1f  \" + numlabels* \"%4.1f ± %4.1f  \"\n",
    "                    vals = [v[i] for v in scores[score_name][\"lab\"]]\n",
    "                    headv.append(np.mean(vals)*100)\n",
    "                    headv.append(np.std(vals)*100)\n",
    "                else:\n",
    "                    head = \"  %-20s  %4.1f ± %4.1f  \" + numlabels * \"%-11s  \" \n",
    "                    headv.append(\"-\")\n",
    "            print(head % tuple(headv))\n",
    "        print(\"―\"*len(row))\n",
    "\n",
    "\n",
    "def get_graph_node_stats(vec, nearestDocIDs, y_train, bodyTrainTFIDF):   \n",
    "    vecdense = vec.toarray()[0]\n",
    "    docids = nearestDocIDs\n",
    "    trlabels = np.array(y_train)\n",
    "    labsum = trlabels[docids].sum()\n",
    "    \n",
    "    ivec = []\n",
    "    labmask = []\n",
    "    for hitdocid in docids:\n",
    "        value=bodyTrainTFIDF[hitdocid].toarray()[0]\n",
    "        intersection = (vecdense>0)*(value>0)\n",
    "        ivec.append(intersection.sum())\n",
    "        labmask.append(trlabels[hitdocid])\n",
    "        \n",
    "    masked_ivec =  np.array(ivec)*np.array(labmask)   \n",
    "    masked_ivec_neg =  np.array(ivec)*(-1*(np.array(labmask)-1)) \n",
    "    ivec = np.array(ivec)\n",
    "    masked_ivec = np.array(masked_ivec)\n",
    "    masked_ivec_neg = np.array(masked_ivec_neg)\n",
    "    \n",
    "    newvec = [labsum, (vecdense>0).sum(),ivec.max(), ivec.max(), masked_ivec.max(), masked_ivec.min(), masked_ivec_neg.max(), masked_ivec_neg.min()]\n",
    "    return newvec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d842a6fe-2dea-45f6-91c0-f98d14065865",
   "metadata": {},
   "source": [
    "# Swarog Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "551840b1-0372-4cf3-be75-520adda5ac2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import bentoml\n",
    "from bentoml.io import NumpyNdarray\n",
    "from bentoml.io import JSON\n",
    "from annoy import AnnoyIndex\n",
    "import re\n",
    "\n",
    "import transformers\n",
    "transformers.logging.set_verbosity_error()\n",
    "from torch.utils.data import DataLoader \n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModel\n",
    "from transformers import TFDistilBertModel, DistilBertTokenizerFast\n",
    "import torch\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk import word_tokenize          \n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import pickle5 as pickle\n",
    "import sqlite3\n",
    "from tqdm import tqdm\n",
    " \n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(\"using device:\", device)\n",
    "\n",
    "if \"disilbert_model\" not in locals():\n",
    "    disilbert_tokenizer =  AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "    disilbert_model = AutoModel.from_pretrained(\"distilbert-base-uncased\")\n",
    "    handle = disilbert_model.to(device)\n",
    "\n",
    "class SwarogModel:\n",
    "    def __init__(self):\n",
    "        self.tokenizer =  disilbert_tokenizer\n",
    "        self.model = disilbert_tokenizer\n",
    "        self.max_length = 256\n",
    "        self.model_name = disilbert_model\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        pass\n",
    "    \n",
    "    def encode(self, txt):\n",
    "        return self.tokenizer(txt, max_length=self.max_length, \n",
    "                              truncation=True, padding=True, return_tensors=\"pt\")\n",
    "\n",
    "    def transform(self, X=None):\n",
    "        dataloader = DataLoader(X, batch_size=4, shuffle=False)\n",
    "        allembeds = []\n",
    "        for batch in tqdm(dataloader):\n",
    "            batchenc = disilbert_tokenizer(batch, max_length=256, \n",
    "                                           truncation=True, padding=True, return_tensors=\"pt\")\n",
    "            input_ids = batchenc['input_ids'].to(device)\n",
    "            attention_mask = batchenc['attention_mask'].to(device)\n",
    "            batchout = disilbert_model(input_ids, attention_mask=attention_mask, \n",
    "                                       output_hidden_states=True)\n",
    "            embeds = [vec[0].cpu().detach().numpy() for vec in batchout[1][-1]]\n",
    "            allembeds.extend(embeds)\n",
    "        return np.array(allembeds)\n",
    "    \n",
    "    def train(self, body, labels):\n",
    "        embeddings = self.transform(body)\n",
    "        self.cls = LogisticRegression(max_iter=1000)\n",
    "        self.cls.fit(embeddings, labels)\n",
    "        self.train_prob = self.cls.predict_proba(embeddings)\n",
    "        \n",
    "    def predict(self, body):\n",
    "        embeddings = self.transform(body)\n",
    "        self.test_prob = self.cls.predict_proba(embeddings)\n",
    "        return  self.cls.predict(embeddings) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c49565d-f7a3-4ebf-ba03-7bb29d13a3d8",
   "metadata": {},
   "source": [
    "# Graph Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "958f52d6-f007-4eb4-bec6-ec915a22bd0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/rkozik/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/rkozik/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "from nltk import word_tokenize          \n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Download stopwords list\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "stop_words = set(stopwords.words('english')) \n",
    "\n",
    "# Interface lemma tokenizer from nltk with sklearn\n",
    "class LemmaTokenizer:\n",
    "    ignore_tokens = [',', '.', ';', ':', '\"', '``', \"''\", '`', \"'\"]\n",
    "    def __init__(self):\n",
    "        self.wnl = WordNetLemmatizer()\n",
    "    def __call__(self, doc):\n",
    "        return [self.wnl.lemmatize(t) for t in word_tokenize(doc) if t not in self.ignore_tokens]\n",
    "    \n",
    "\n",
    "class TrustexModel:\n",
    "    def __init__(self):\n",
    "        # Lemmatize the stop words\n",
    "        self.tokenizer=LemmaTokenizer()\n",
    "        self.token_stop = self.tokenizer(' '.join(stop_words))\n",
    "        \n",
    "    def tfidf(self,body):\n",
    "        self.tfidf_vectorizer = TfidfVectorizer(stop_words=self.token_stop)\n",
    "        self.tfidf_vectorizer.fit(body)\n",
    "        self.vocabulary_tfidf_words = self.tfidf_vectorizer.get_feature_names_out()\n",
    "        self.bodyTrainTFIDF = self.tfidf_vectorizer.transform(body)\n",
    "        \n",
    "    def create_graph(self, body, labels):\n",
    "        self.nn = NearestNeighbors(n_neighbors=10)\n",
    "        self.nn.fit(self.bodyTrainTFIDF)\n",
    "        knn_d,knn_idx = self.nn.kneighbors(self.bodyTrainTFIDF)\n",
    "        self.graph_knn = []\n",
    "        self.train_labels = labels\n",
    "        from tqdm import tqdm\n",
    "        for id, topIDs in tqdm(enumerate(knn_idx), total=knn_idx.shape[0]):\n",
    "            vec = self.bodyTrainTFIDF[id]\n",
    "            newvec = get_graph_node_stats(vec, topIDs[1:], labels, self.bodyTrainTFIDF)\n",
    "            self.graph_knn.append(newvec)\n",
    "        print(\"avg. nodes sim.=\",np.mean([x[2]/x[1] for x in self.graph_knn]))\n",
    "\n",
    "    def graph_transform_test_data(self, body):\n",
    "        self.bodyTestTFIDF = self.tfidf_vectorizer.transform(body) \n",
    "        knn_test_d,knn_test_idx = self.nn.kneighbors(self.bodyTestTFIDF)\n",
    "        self.graph_test_knn = []\n",
    "        for id, topIDs in tqdm(enumerate(knn_test_idx), total=knn_test_idx.shape[0]):\n",
    "            vec = self.bodyTestTFIDF[id]\n",
    "            newvec = get_graph_node_stats(vec, topIDs[1:], self.train_labels, self.bodyTrainTFIDF)\n",
    "            self.graph_test_knn.append(newvec)        \n",
    "              \n",
    "    def train(self, body, labels):\n",
    "        print(\"Building similarity graph\")\n",
    "        self.tfidf(body)\n",
    "        self.create_graph(body, labels)\n",
    "          \n",
    "        self.cls = LogisticRegression(max_iter=10000)\n",
    "        self.cls.fit(self.graph_knn, labels)\n",
    "\n",
    "    def predict(self, body):\n",
    "        self.graph_transform_test_data(body)\n",
    "        y_pred = self.cls.predict(self.graph_test_knn)\n",
    "        return y_pred\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6336c157",
   "metadata": {},
   "source": [
    "# FTS Semantics 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d72c2ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import traceback\n",
    "from rank_bm25 import BM25Okapi\n",
    "import multiprocessing as mp\n",
    "import functools\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import traceback\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from subject_verb_object_extract import findSVOs, nlp\n",
    "import os\n",
    "import spacy\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "sp = spacy.load('en_core_web_sm')\n",
    "\n",
    "\n",
    "def call_it2(instance, name, arg):\n",
    "    \"indirect caller for instance methods and multiprocessing\"\n",
    "    return getattr(instance, name)(arg)\n",
    "\n",
    "\n",
    "class FTSSemantic2:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def tokenize_single(self, e):\n",
    "        docid, txt = e\n",
    "        tokens = nlp(txt)\n",
    "        svos = findSVOs(tokens)\n",
    "        proc_text = []\n",
    "        all_lemas = []\n",
    "        for xsvo in svos:\n",
    "            svo = xsvo\n",
    "#             if len(svo) < 3 and len(svo) > 1:\n",
    "#                 svos = [svo[0],svo[1],\"\"]\n",
    "            if len(svo) == 3:\n",
    "                line = \" \".join(svo)\n",
    "                sentence = sp(line)\n",
    "                lemas =  [word.lemma_ for word in sentence]\n",
    "                all_lemas.extend(lemas)\n",
    "#                 proc_text.append((docid,lemas))\n",
    "        return [(docid, all_lemas)]\n",
    "\n",
    "\n",
    "    def tokenize(self, body,batch=32): \n",
    "        print(\"Extracting SVO Triples\")\n",
    "        tokenized_corpus = []\n",
    "        tokenized_corpus_i = []\n",
    "        \n",
    "        with mp.Pool(processes=mp.cpu_count()) as pool:\n",
    "            func_call_it = functools.partial(call_it2, self, 'tokenize_single')\n",
    "            vectors = list(tqdm(pool.imap_unordered(func_call_it, enumerate(body),chunksize=batch), total=len(body)))\n",
    "        \n",
    "        \n",
    "        for e in vectors:\n",
    "            for docid, lema in e:\n",
    "                tokenized_corpus.append(lema)\n",
    "                tokenized_corpus_i.append(docid)\n",
    "                    \n",
    "        return tokenized_corpus, tokenized_corpus_i\n",
    "    \n",
    "    def transform_single(self, lema):\n",
    "        doc_scores = self.bm25.get_scores(lema)\n",
    "        topN = np.argsort(doc_scores)[::-1][:10]\n",
    "        sc = doc_scores[topN]\n",
    "        lab = np.array([self.training_labels[i] for i in topN])\n",
    "        sc2 = [-v if lab[i]==1 else v for i,v in enumerate(sc)]\n",
    "        v = [\n",
    "                len(lema), np.sum(lab),\n",
    "                np.mean(sc),np.max(sc),np.min(sc),\n",
    "                np.mean(sc2),np.sum(sc2),np.max(sc2),np.min(sc2),\n",
    "        ]\n",
    "        return v\n",
    "    \n",
    "    def transform(self, body, batch=32):\n",
    "        vectors = []\n",
    "        \n",
    "        with mp.Pool(processes=mp.cpu_count()) as pool:\n",
    "            func_call_it = functools.partial(call_it2, self, 'transform_single')\n",
    "            vectors = list(tqdm(pool.imap_unordered(func_call_it, body, chunksize=batch), total=len(body)))\n",
    "        \n",
    "        return vectors\n",
    "        \n",
    "    def train(self, body, labels):    \n",
    "        tokenized_corpus, tokenized_corpus_i = self.tokenize(body)\n",
    "        self.bm25 = BM25Okapi(tokenized_corpus)\n",
    "        self.training_labels = labels[list(tokenized_corpus_i)]\n",
    "        self.trainX = self.transform(tokenized_corpus)\n",
    "        y = labels[list(tokenized_corpus_i)]\n",
    "        self.cls = LogisticRegression(max_iter=10000)\n",
    "        self.cls.fit(self.trainX, y)\n",
    "            \n",
    "    def predict(self, body, labels):\n",
    "        tokenized_corpus, tokenized_corpus_i = self.tokenize(body)\n",
    "        self.testX = self.transform(tokenized_corpus)\n",
    "        preds = self.cls.predict(self.testX)\n",
    "        \n",
    "        mp={}\n",
    "        for i,e in enumerate(tokenized_corpus_i):\n",
    "            if e not in mp:\n",
    "                mp[e]=[]\n",
    "            mp[e].append(preds[i])\n",
    "        \n",
    "        ypred=[]\n",
    "        for id,row in enumerate(body):\n",
    "            if id not in mp:\n",
    "                ypred.append(0)\n",
    "            else:\n",
    "                ypred.append(1 if np.mean(mp[e]) > 0.5 else 0)\n",
    "        \n",
    "        return ypred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a1b7a8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "9443e2df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting SVO Triples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 9180/9180 [00:22<00:00, 407.84it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 9180/9180 [00:26<00:00, 350.34it/s]\n"
     ]
    }
   ],
   "source": [
    "fts2 = FTSSemantic2()\n",
    "fts2.train(body[train],labels[train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "03b01618",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting SVO Triples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 1021/1021 [00:04<00:00, 213.13it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 1021/1021 [00:04<00:00, 212.88it/s]\n"
     ]
    }
   ],
   "source": [
    "ypred = fts2.predict(body[test],labels[test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "dffdeaa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――\n",
      "  Score                 Average      Lab:1        Lab:2       \n",
      "――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――\n",
      "  Accuracy              95.3 ±  0.0  -            -            \n",
      "  Balanced Accuracy     50.0 ±  0.0  -            -            \n",
      "  F1                    93.0 ±  0.0   0.0 ±  0.0  97.6 ±  0.0  \n",
      "  G-mean                21.2 ±  0.0   0.0 ±  0.0   0.0 ±  0.0  \n",
      "  Precision             90.8 ±  0.0   0.0 ±  0.0  95.3 ±  0.0  \n",
      "  Recall                95.3 ±  0.0   0.0 ±  0.0  100.0 ±  0.0  \n",
      "――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/rkozik/02FF-A831/repos/swarog_exp/env.hator/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/media/rkozik/02FF-A831/repos/swarog_exp/env.hator/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "met = Metrics()\n",
    "met.update(labels[test], ypred)\n",
    "met.print_table()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b992a48-181f-4b67-a320-939543e855ff",
   "metadata": {},
   "source": [
    "\n",
    "# Infrence "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "id": "5526269d-b19e-46e7-803f-8eada642f486",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "class Inference:\n",
    "    def train(self,graph, content, semantics, labels):\n",
    "        newX=[]\n",
    "        for i,vec in enumerate(content):\n",
    "            v2 = np.append(content[i], graph[i]) \n",
    "            if semantics:\n",
    "                v2 = np.append(v2, semantics[i])\n",
    "            newX.append(v2)\n",
    "            \n",
    "        self.inf = RandomForestClassifier(max_depth=12)\n",
    "        self.inf.fit(newX, labels)\n",
    "        \n",
    "    def predict(self, graph, content, semantics):\n",
    "        newTest=[]\n",
    "        for i,vec in enumerate(content):\n",
    "            v2 = np.append(content[i], graph[i]) \n",
    "            if semantics:\n",
    "                v2 = np.append(v2, semantics[i])\n",
    "            newTest.append(v2)\n",
    "    \n",
    "        return self.inf.predict(newTest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4baccae2-b3bd-4e07-a8cd-e55fe8801382",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "827802d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading covidfn\n",
      "total_number_of_claims= 10201\n",
      "labels fake= 9727 real= 474\n"
     ]
    }
   ],
   "source": [
    "loader = DatasetLoader()\n",
    "body, labels, total_number_of_claims = loader.get(\"covidfn\")\n",
    "X=range(0,total_number_of_claims)\n",
    "train, test = list(rskf.split(X, labels))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "id": "315f84fb-918d-4814-9e04-3601b4f3fe01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading covidfn\n",
      "total_number_of_claims= 10201\n",
      "labels fake= 9727 real= 474\n",
      "fold-0\n",
      "Building index\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 9180/9180 [01:24<00:00, 108.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating trainX\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 9180/9180 [02:08<00:00, 71.63it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1021/1021 [00:13<00:00, 78.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building similarity graph\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 9180/9180 [00:08<00:00, 1052.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg. nodes sim.= 0.6016417403761986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 1021/1021 [00:00<00:00, 1050.97it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 2295/2295 [00:12<00:00, 185.58it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 256/256 [00:01<00:00, 183.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Semantic:\n",
      "――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――\n",
      "  Score                 Average      Lab:1        Lab:2       \n",
      "――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――\n",
      "  Accuracy              95.5 ±  0.0  -            -            \n",
      "  Balanced Accuracy     61.0 ±  0.0  -            -            \n",
      "  F1                    94.6 ±  0.0  32.4 ±  0.0  97.7 ±  0.0  \n",
      "  G-mean                50.3 ±  0.0  47.6 ±  0.0  47.6 ±  0.0  \n",
      "  Precision             94.4 ±  0.0  55.0 ±  0.0  96.3 ±  0.0  \n",
      "  Recall                95.5 ±  0.0  22.9 ±  0.0  99.1 ±  0.0  \n",
      "――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――\n",
      "Symbolic:\n",
      "――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――\n",
      "  Score                 Average      Lab:1        Lab:2       \n",
      "――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――\n",
      "  Accuracy              97.4 ±  0.0  -            -            \n",
      "  Balanced Accuracy     75.8 ±  0.0  -            -            \n",
      "  F1                    97.0 ±  0.0  64.9 ±  0.0  98.6 ±  0.0  \n",
      "  G-mean                72.7 ±  0.0  72.0 ±  0.0  72.0 ±  0.0  \n",
      "  Precision             97.1 ±  0.0  86.2 ±  0.0  97.7 ±  0.0  \n",
      "  Recall                97.4 ±  0.0  52.1 ±  0.0  99.6 ±  0.0  \n",
      "――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――\n",
      "Deep:\n",
      "――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――\n",
      "  Score                 Average      Lab:1        Lab:2       \n",
      "――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――\n",
      "  Accuracy              98.2 ±  0.0  -            -            \n",
      "  Balanced Accuracy     85.2 ±  0.0  -            -            \n",
      "  F1                    98.1 ±  0.0  79.1 ±  0.0  99.1 ±  0.0  \n",
      "  G-mean                84.2 ±  0.0  84.0 ±  0.0  84.0 ±  0.0  \n",
      "  Precision             98.1 ±  0.0  89.5 ±  0.0  98.6 ±  0.0  \n",
      "  Recall                98.2 ±  0.0  70.8 ±  0.0  99.6 ±  0.0  \n",
      "――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――\n",
      "Symb+Deep:\n",
      "――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――\n",
      "  Score                 Average      Lab:1        Lab:2       \n",
      "――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――\n",
      "  Accuracy              98.4 ±  0.0  -            -            \n",
      "  Balanced Accuracy     91.3 ±  0.0  -            -            \n",
      "  F1                    98.4 ±  0.0  83.3 ±  0.0  99.2 ±  0.0  \n",
      "  G-mean                91.0 ±  0.0  90.9 ±  0.0  90.9 ±  0.0  \n",
      "  Precision             98.4 ±  0.0  83.3 ±  0.0  99.2 ±  0.0  \n",
      "  Recall                98.4 ±  0.0  83.3 ±  0.0  99.2 ±  0.0  \n",
      "――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――\n",
      "ALL:\n",
      "――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――\n",
      "  Score                 Average      Lab:1        Lab:2       \n",
      "――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――\n",
      "  Accuracy              98.1 ±  0.0  -            -            \n",
      "  Balanced Accuracy     86.2 ±  0.0  -            -            \n",
      "  F1                    98.1 ±  0.0  78.7 ±  0.0  99.0 ±  0.0  \n",
      "  G-mean                85.3 ±  0.0  85.1 ±  0.0  85.1 ±  0.0  \n",
      "  Precision             98.0 ±  0.0  85.4 ±  0.0  98.7 ±  0.0  \n",
      "  Recall                98.1 ±  0.0  72.9 ±  0.0  99.4 ±  0.0  \n",
      "――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――\n"
     ]
    }
   ],
   "source": [
    "loader = DatasetLoader()\n",
    "\n",
    "for dataset in [\"fnkdd\"]:\n",
    "    body, labels, total_number_of_claims = loader.get(dataset)\n",
    "    X=range(0,total_number_of_claims)\n",
    "    \n",
    "    trustex_quality = Metrics()\n",
    "    swarog_quality = Metrics()\n",
    "    semantics_quality = Metrics()\n",
    "    inf3_quality = Metrics()\n",
    "    inf2_quality = Metrics()\n",
    "    \n",
    "\n",
    "    for fold_idx, (train, test) in enumerate(rskf.split(X, labels)):\n",
    "        print(f\"fold-{fold_idx}\")    \n",
    "        \n",
    "        swarog = SwarogModel()\n",
    "        trustex = TrustexModel()\n",
    "        inference2 = Inference()\n",
    "        inference3 = Inference()\n",
    "        semantics = FTSSemantic()\n",
    "        \n",
    "        semantics.train(body[train],labels[train])\n",
    "        ypred = semantics.predict(body[test])\n",
    "        semantics_quality.update(labels[test], ypred)\n",
    "    \n",
    "        trustex.train(body[train],labels[train])\n",
    "        ypred = trustex.predict(body[test])\n",
    "        trustex_quality.update(labels[test], ypred)\n",
    "        \n",
    "        swarog.train(body[train],labels[train])\n",
    "        ypred = swarog.predict(body[test])\n",
    "        swarog_quality.update(labels[test], ypred)\n",
    "\n",
    "        inference2.train(trustex.graph_knn, swarog.train_prob, None, labels[train])\n",
    "        newpred = inference2.predict(trustex.graph_test_knn, swarog.test_prob, None)\n",
    "        inf2_quality.update(labels[test], newpred)\n",
    "\n",
    "        \n",
    "        inference3.train(trustex.graph_knn, swarog.train_prob, semantics.trainX, labels[train])\n",
    "        newpred = inference3.predict(trustex.graph_test_knn, swarog.test_prob, semantics.testX)\n",
    "        inf3_quality.update(labels[test], newpred)\n",
    "\n",
    "        break\n",
    "\n",
    "print(\"Semantic:\")\n",
    "semantics_quality.print_table()\n",
    "print(\"Symbolic:\")\n",
    "trustex_quality.print_table()\n",
    "print(\"Deep:\")\n",
    "swarog_quality.print_table()\n",
    "\n",
    "print(\"Symb+Deep:\")\n",
    "inf2_quality.print_table()\n",
    "\n",
    "print(\"ALL:\")\n",
    "inf3_quality.print_table()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d0a15b3-d116-4d04-af2f-d87dcf77ed2d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env.hator",
   "language": "python",
   "name": "env.hator"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "375.498px",
    "width": "241.499px"
   },
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "788px",
    "left": "10px",
    "top": "150px",
    "width": "158.95px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
