{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4aefad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d503a6af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "--2022-08-25 13:36:58--  https://docs.google.com/uc?export=download&confirm=t&id=1U6g7mfAuDL19deR6uUqI1T1taqpKH8rd\n",
      "Resolving docs.google.com (docs.google.com)... 142.250.203.206, 2a00:1450:401b:80d::200e\n",
      "Connecting to docs.google.com (docs.google.com)|142.250.203.206|:443... connected.\n",
      "HTTP request sent, awaiting response... 303 See Other\n",
      "Location: https://doc-10-34-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/igh3u93c4cgt2cgt0eg42if0s01mv4md/1661427375000/05536367513713019519/*/1U6g7mfAuDL19deR6uUqI1T1taqpKH8rd?e=download&uuid=6f9c9276-6a84-496f-8bcd-7408eb581dd2 [following]\n",
      "Warning: wildcards not supported in HTTP.\n",
      "--2022-08-25 13:36:59--  https://doc-10-34-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/igh3u93c4cgt2cgt0eg42if0s01mv4md/1661427375000/05536367513713019519/*/1U6g7mfAuDL19deR6uUqI1T1taqpKH8rd?e=download&uuid=6f9c9276-6a84-496f-8bcd-7408eb581dd2\n",
      "Resolving doc-10-34-docs.googleusercontent.com (doc-10-34-docs.googleusercontent.com)... 142.250.75.1, 2a00:1450:401b:80d::2001\n",
      "Connecting to doc-10-34-docs.googleusercontent.com (doc-10-34-docs.googleusercontent.com)|142.250.75.1|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 116675973 (111M) [text/csv]\n",
      "Saving to: ‘isot.csv’\n",
      "\n",
      "isot.csv            100%[===================>] 111,27M  3,94MB/s    in 29s     \n",
      "\n",
      "2022-08-25 13:37:28 (3,89 MB/s) - ‘isot.csv’ saved [116675973/116675973]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!id=\"1kATR41mQR97Cb5xDfpuEXywWZfcITz-y\"; conf=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id='$id -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p'); wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$conf&id=$id\" -O grafn.csv && rm -rf /tmp/cookies.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95f17440",
   "metadata": {},
   "outputs": [],
   "source": [
    "ndata = data[[\"text\",\"label\"]]\n",
    "ndata.to_csv(\"raw/grafn_lite.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f796758",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4055/349775969.py:6: DtypeWarning: Columns (3,5,6,9,10,11,12,13,14,16,22) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv(\"../../raw/grafn.csv\",sep=\",\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels\n",
      " 0    50931\n",
      "1    12999\n",
      "Name: label, dtype: int64\n",
      "shape  \n",
      " (63930, 24)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 10/10 [00:00<00:00, 503.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shapes X (63930,) y (63930,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "\n",
    "data = pd.read_csv(\"../../raw/grafn.csv\",sep=\",\")\n",
    "print(\"labels\\n\",data[\"label\"].value_counts())\n",
    "print(\"shape  \\n\",data.shape)\n",
    "\n",
    "bootstrap_size = 0\n",
    "\n",
    "if bootstrap_size != 0:\n",
    "    bootstrap_factor = bootstrap_size / data.shape[0]\n",
    "    bootstrap = np.random.uniform(size=data.shape[0]) < bootstrap_factor\n",
    "    data = data.iloc[bootstrap]\n",
    "\n",
    "X, y = data[\"text\"].astype(str).values, data[\"label\"].values\n",
    "\n",
    "rskf = RepeatedStratifiedKFold(n_splits=2, n_repeats=5, random_state=1410)\n",
    "foldids = []\n",
    "for fold_idx, (train, test) in tqdm(enumerate(rskf.split(X, y)), total=rskf.get_n_splits()):\n",
    "    foldids.append((fold_idx,train,test))\n",
    "    \n",
    "print(\"shapes X\",X.shape,\"y\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2c31e30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "transformers.logging.set_verbosity_error()\n",
    "from torch.utils.data import DataLoader \n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModel\n",
    "from transformers import TFDistilBertModel, DistilBertTokenizerFast\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from scipy.sparse import csr_matrix\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(\"using device:\", device)\n",
    "\n",
    "if \"disilbert_model\" not in locals():\n",
    "    disilbert_tokenizer =  AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "    disilbert_model = AutoModel.from_pretrained(\"distilbert-base-uncased\")\n",
    "    handle = disilbert_model.to(device)\n",
    "\n",
    "\n",
    "class BERTEmbeddings(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.tokenizer =  disilbert_tokenizer\n",
    "        self.model = disilbert_tokenizer\n",
    "        self.max_length = 256\n",
    "        self.model_name = disilbert_model\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        pass\n",
    "    \n",
    "    def encode(self, txt):\n",
    "        return self.tokenizer(txt, max_length=self.max_length, \n",
    "                              truncation=True, padding=True, return_tensors=\"pt\")\n",
    "\n",
    "    def transform(self, X=None):\n",
    "        dataloader = DataLoader(X, batch_size=4, shuffle=False)\n",
    "        allembeds = []\n",
    "        for batch in tqdm(dataloader):\n",
    "            batchenc = disilbert_tokenizer(batch, max_length=256, truncation=True, padding=True, return_tensors=\"pt\")\n",
    "            input_ids = batchenc['input_ids'].to(device)\n",
    "            attention_mask = batchenc['attention_mask'].to(device)\n",
    "            batchout = disilbert_model(input_ids, attention_mask=attention_mask, output_hidden_states=True)\n",
    "            embeds = [vec[0].cpu().detach().numpy() for vec in batchout[1][-1]]\n",
    "            allembeds.extend(embeds)\n",
    "        return csr_matrix(allembeds)\n",
    "\n",
    "\n",
    "class BertHead(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.head = LogisticRegression(class_weight='auto', max_iter=10000)\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.head.fit(X, y)\n",
    "\n",
    "\n",
    "    def transform(self, X=None):\n",
    "        pass\n",
    "    \n",
    "    def predict(self, X=None):    \n",
    "        return self.head.predict(X)\n",
    "    \n",
    "    def predict_proba(self, X=None):    \n",
    "        return self.head.predict_proba(X)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07fe3749",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 15983/15983 [03:01<00:00, 87.87it/s]\n"
     ]
    }
   ],
   "source": [
    "bert = BERTEmbeddings()\n",
    "X_dstil_numpy = bert.transform(X).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c6b1da98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# SAVE\n",
    "with open('grafn_BERTEmbeddings.pickle', 'wb') as handle:\n",
    "    pickle.dump(X_dstil_numpy, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed4422df-ef02-4800-b41a-69684cb3252e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# LOAD\n",
    "with open('../../pickles/bertcls_embeddings/grafn_BERTEmbeddings.pickle', 'rb') as handle:\n",
    "    X_dstil_numpy=pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b737cfcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.9201313937118724\n",
      "Balanced Accuracy 0.8589558670271413\n",
      "F1 0.9186091268295702 [0.95047623 0.79376363]\n",
      "Precision 0.9181211055266055 [0.93916277 0.83568634]\n",
      "Recall 0.9201313937118724 [0.96206558 0.75584615]\n",
      "Log-likelihood 0.1998107273818329\n",
      "\n",
      "Accuracy 0.9172845299546379\n",
      "Balanced Accuracy 0.8547444944589522\n",
      "F1 0.9157266497180765 [0.94870601 0.78649871]\n",
      "Precision 0.915171387804657 [0.93753834 0.82752761]\n",
      "Recall 0.9172845299546379 [0.96014294 0.74934605]\n",
      "Log-likelihood 0.20453454010072863\n",
      "\n",
      "Accuracy 0.9200375410605349\n",
      "Balanced Accuracy 0.8601000166140556\n",
      "F1 0.9186310526995018 [0.95037471 0.79426916]\n",
      "Precision 0.91810977684571 [0.93986406 0.83288319]\n",
      "Recall 0.9200375410605349 [0.96112311 0.75907692]\n",
      "Log-likelihood 0.2002399955958455\n",
      "\n",
      "Accuracy 0.9201313937118724\n",
      "Balanced Accuracy 0.8580210136177515\n",
      "F1 0.9185245495425799 [0.95050887 0.79319563]\n",
      "Precision 0.9180654228630056 [0.93862705 0.83749572]\n",
      "Recall 0.9201313937118724 [0.96269536 0.75334667]\n",
      "Log-likelihood 0.20160552186328945\n",
      "\n",
      "Accuracy 0.9201626779289849\n",
      "Balanced Accuracy 0.8601212675013972\n",
      "F1 0.9187428065947877 [0.95045815 0.79449187]\n",
      "Precision 0.9182275777955923 [0.93983952 0.83355863]\n",
      "Recall 0.9201626779289849 [0.96131946 0.75892308]\n",
      "Log-likelihood 0.1996493843079303\n",
      "\n",
      "Accuracy 0.9208196464883466\n",
      "Balanced Accuracy 0.8601719888349937\n",
      "F1 0.9193257506041245 [0.95089918 0.79560688]\n",
      "Precision 0.9188475232588464 [0.9396879  0.83718559]\n",
      "Recall 0.9208196464883466 [0.96238121 0.75796276]\n",
      "Log-likelihood 0.19973600715767512\n",
      "\n",
      "Accuracy 0.9220710151728453\n",
      "Balanced Accuracy 0.8614908547176365\n",
      "F1 0.920544703939995 [0.95169391 0.79851169]\n",
      "Precision 0.9201142523608817 [0.94008122 0.84188982]\n",
      "Recall 0.9220710151728453 [0.96359709 0.75938462]\n",
      "Log-likelihood 0.1988639922695779\n",
      "\n",
      "Accuracy 0.9193180040669482\n",
      "Balanced Accuracy 0.8580262370711673\n",
      "F1 0.9178116440182635 [0.94996217 0.79183146]\n",
      "Precision 0.9172965537724426 [0.93886865 0.8327674 ]\n",
      "Recall 0.9193180040669482 [0.96132098 0.7547315 ]\n",
      "Log-likelihood 0.20067983898240388\n",
      "\n",
      "Accuracy 0.9207570780541217\n",
      "Balanced Accuracy 0.8611244996903744\n",
      "F1 0.9193555144267337 [0.95082413 0.79607117]\n",
      "Precision 0.9188504288928142 [0.94025495 0.83499409]\n",
      "Recall 0.9207570780541217 [0.96163361 0.76061538]\n",
      "Log-likelihood 0.19539323005179415\n",
      "\n",
      "Accuracy 0.91997497262631\n",
      "Balanced Accuracy 0.8598137729191934\n",
      "F1 0.9185514434096212 [0.9503436  0.79397552]\n",
      "Precision 0.9180321838541445 [0.93972666 0.83302349]\n",
      "Recall 0.91997497262631 [0.96120317 0.75842437]\n",
      "Log-likelihood 0.2036850859176829\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import log_loss,accuracy_score, balanced_accuracy_score, f1_score, precision_score, recall_score, roc_auc_score\n",
    "from imblearn.metrics import geometric_mean_score\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def log_los_nonorm(x,y,average=False):\n",
    "    return log_loss(x,y,normalize=True)\n",
    "\n",
    "scores = {\n",
    "    'Accuracy': {'func': accuracy_score},\n",
    "    'Balanced Accuracy': {'func': balanced_accuracy_score},\n",
    "    'F1': {'func': f1_score},\n",
    "    'Precision': {'func': precision_score},\n",
    "    'Recall': {'func': recall_score},\n",
    "    'Log-likelihood': {'func': log_los_nonorm},\n",
    "    #'G-mean': {'func': geometric_mean_score}\n",
    "}\n",
    "\n",
    "for score_name, score_dict in scores.items():\n",
    "    scores[score_name][\"list\"] = []\n",
    "    scores[score_name][\"lab\"] = []\n",
    "\n",
    "\n",
    "for fold,j in enumerate(foldids):\n",
    "    train = foldids[fold][1]\n",
    "    test = foldids[fold][2]\n",
    "    xin, yin = X_dstil_numpy[train], np.array(y[train])\n",
    "    cls = BertHead()\n",
    "    \n",
    "    cls.fit(xin, yin)\n",
    "    y_pred = cls.predict(X_dstil_numpy[test])\n",
    "    y_pred_proba = cls.predict_proba(X_dstil_numpy[test])\n",
    "    \n",
    "    for score_name, score_dict in scores.items():\n",
    "        if score_name == \"Log-likelihood\":\n",
    "            scorval=score_dict['func'](y[test], y_pred_proba)\n",
    "            score_dict['list'].append(scorval)\n",
    "            print(score_name, scorval)\n",
    "        elif score_name in [\"F1\",\"Precision\",\"Recall\"]:\n",
    "            scorvaln = score_dict['func'](y[test], y_pred, average=None)\n",
    "            score_dict['lab'].append(scorvaln)\n",
    "            scorval = score_dict['func'](y[test], y_pred, average=\"weighted\")\n",
    "            score_dict['list'].append(scorval)\n",
    "            print(score_name, scorval, scorvaln)  \n",
    "        else:\n",
    "            scorval=score_dict['func'](y[test], y_pred)\n",
    "            score_dict['list'].append(scorval)\n",
    "            print(score_name, scorval)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4236666d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Score                | Average      | Kat_1      | Kat_2      |\n",
      "| Accuracy             | 92.0 ± 0.116 | -          | -          |\n",
      "| Balanced Accuracy    | 85.9 ± 0.186 | -          | -          |\n",
      "| F1                   | 91.9 ± 0.117 | 95.0 ± 0.1 | 79.4 ± 0.3 |\n",
      "| Log-likelihood       | 0.20 ± 0.002 | -          | -          |\n",
      "| Precision            | 91.8 ± 0.120 | 93.9 ± 0.1 | 83.5 ± 0.4 |\n",
      "| Recall               | 92.0 ± 0.116 | 96.2 ± 0.1 | 75.7 ± 0.3 |\n"
     ]
    }
   ],
   "source": [
    "numlabels = scores[\"F1\"][\"lab\"][0].shape[0]\n",
    "scores[\"F1\"][\"lab\"][0].shape[0] \n",
    "head = \"| %-20s | %-12s |\" +  numlabels * \" %-10s |\" \n",
    "headv = [\"Score\", \"Average\"]\n",
    "headv.extend([\"Kat_\"+str(i+1) for i in range(numlabels)])\n",
    "row=head % tuple(headv)\n",
    "#print(\"+\"*len(row))\n",
    "print(row)\n",
    "#print(\"+\"*len(row))\n",
    "\n",
    "for score_name, score_dict in sorted(scores.items()) :\n",
    "    if score_name == \"Log-likelihood\":\n",
    "        headv = [score_name, np.mean(score_dict['list'])*1, np.std(score_dict['list'])*1]\n",
    "    else:\n",
    "        headv = [score_name, np.mean(score_dict['list'])*100, np.std(score_dict['list'])*100]\n",
    "    \n",
    "    for i in range(numlabels):\n",
    "        if score_name == \"Log-likelihood\":\n",
    "            head = \"| %-20s | %3.2f ± %3.3f |\" + numlabels * \" %-10s |\" \n",
    "            headv.append(\"-\")\n",
    "        elif score_name in [\"F1\",\"Precision\",\"Recall\"]:\n",
    "            head = \"| %-20s | %4.1f ± %3.3f |\" + numlabels* \" %4.1f ± %3.1f |\"\n",
    "            vals = [v[i] for v in scores[score_name][\"lab\"]]\n",
    "            headv.append(np.mean(vals)*100)\n",
    "            headv.append(np.std(vals)*100)\n",
    "        else:\n",
    "            head = \"| %-20s | %4.1f ± %3.3f |\" + numlabels * \" %-10s |\" \n",
    "            headv.append(\"-\")\n",
    "    print(head % tuple(headv))\n",
    "    \n",
    "#print(\"+\"*len(row))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env.hator",
   "language": "python",
   "name": "env.hator"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
