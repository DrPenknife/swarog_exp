{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "690ba15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9fea8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "! id=\"12vbx8UMl4KpoSPM4ZHqqggjtKrn35odG\"; \\\n",
    "conf=$(wget --quiet --save-cookies /tmp/cookies.txt \\\n",
    "--keep-session-cookies --no-check-certificate \\\n",
    "'https://docs.google.com/uc?export=download&id='$id -O- | \\\n",
    "sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p'); \\\n",
    "wget --load-cookies /tmp/cookies.txt \\\n",
    "\"https://docs.google.com/uc?export=download&confirm=$conf&id=$id\" -O qprop.csv && \\\n",
    "rm -rf /tmp/cookies.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3c12c2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels\n",
      " 0    45534\n",
      "1     5736\n",
      "Name: label, dtype: int64\n",
      "shape  \n",
      " (51270, 14)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 10/10 [00:00<00:00, 605.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shapes X (51270,) y (51270,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "\n",
    "data = pd.read_csv(\"../../raw/qprop.csv\",sep=\"\\t\")\n",
    "print(\"labels\\n\",data[\"label\"].value_counts())\n",
    "print(\"shape  \\n\",data.shape)\n",
    "\n",
    "bootstrap_size = 0\n",
    "\n",
    "if bootstrap_size != 0:\n",
    "    bootstrap_factor = bootstrap_size / data.shape[0]\n",
    "    bootstrap = np.random.uniform(size=data.shape[0]) < bootstrap_factor\n",
    "    data = data.iloc[bootstrap]\n",
    "\n",
    "X, y = data[\"text\"].values, data[\"label\"].values\n",
    "\n",
    "rskf = RepeatedStratifiedKFold(n_splits=2, n_repeats=5, random_state=1410)\n",
    "foldids = []\n",
    "for fold_idx, (train, test) in tqdm(enumerate(rskf.split(X, y)), total=rskf.get_n_splits()):\n",
    "    foldids.append((fold_idx,train,test))\n",
    "    \n",
    "print(\"shapes X\",X.shape,\"y\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd21fdc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['text', 'event_location', 'average_tone', 'article_URL',\n",
       "       'MBFC_factuality_label', 'article_URL2', 'MBFC_factuality_label2',\n",
       "       'URL_to_MBFC_page', 'source_name', 'MBFC_notes_about_source',\n",
       "       'MBFC_bias_label', 'source_URL', 'published_utc', 'label'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08651559",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "transformers.logging.set_verbosity_error()\n",
    "from torch.utils.data import DataLoader \n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModel\n",
    "from transformers import TFDistilBertModel, DistilBertTokenizerFast\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from scipy.sparse import csr_matrix\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(\"using device:\", device)\n",
    "\n",
    "if \"disilbert_model\" not in locals():\n",
    "    disilbert_tokenizer =  AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "    disilbert_model = AutoModel.from_pretrained(\"distilbert-base-uncased\")\n",
    "    handle = disilbert_model.to(device)\n",
    "\n",
    "\n",
    "class BERTEmbeddings(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.tokenizer =  disilbert_tokenizer\n",
    "        self.model = disilbert_tokenizer\n",
    "        self.max_length = 256\n",
    "        self.model_name = disilbert_model\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        pass\n",
    "    \n",
    "    def encode(self, txt):\n",
    "        return self.tokenizer(txt, max_length=self.max_length, \n",
    "                              truncation=True, padding=True, return_tensors=\"pt\")\n",
    "\n",
    "    def transform(self, X=None):\n",
    "        dataloader = DataLoader(X, batch_size=4, shuffle=False)\n",
    "        allembeds = []\n",
    "        for batch in tqdm(dataloader):\n",
    "            batchenc = disilbert_tokenizer(batch, max_length=256, truncation=True, padding=True, return_tensors=\"pt\")\n",
    "            input_ids = batchenc['input_ids'].to(device)\n",
    "            attention_mask = batchenc['attention_mask'].to(device)\n",
    "            batchout = disilbert_model(input_ids, attention_mask=attention_mask, output_hidden_states=True)\n",
    "            embeds = [vec[0].cpu().detach().numpy() for vec in batchout[1][-1]]\n",
    "            allembeds.extend(embeds)\n",
    "        return csr_matrix(allembeds)\n",
    "\n",
    "\n",
    "class BertHead(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.head = LogisticRegression(class_weight='auto', max_iter=10000)\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.head.fit(X, y)\n",
    "\n",
    "\n",
    "    def transform(self, X=None):\n",
    "        pass\n",
    "    \n",
    "    def predict(self, X=None):    \n",
    "        return self.head.predict(X)\n",
    "    \n",
    "    def predict_proba(self, X=None):    \n",
    "        return self.head.predict_proba(X)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "940fa452",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 3205/3205 [01:39<00:00, 32.16it/s]\n"
     ]
    }
   ],
   "source": [
    "bert = BERTEmbeddings()\n",
    "X_dstil_numpy = bert.transform(X).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "48445835",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# SAVE\n",
    "with open('qprop_BERTEmbeddings.pickle', 'wb') as handle:\n",
    "    pickle.dump(X_dstil_numpy, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c7791cc-c24b-468b-a4e0-b44743c66328",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# LOAD\n",
    "with open('../../pickles/bertcls_embeddings/qprop_BERTEmbeddings.pickle', 'rb') as handle:\n",
    "    X_dstil_numpy=pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e4087a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.9425394967817438\n",
      "Balanced Accuracy 0.8148175127951653\n",
      "F1 0.9399287559755203 [0.96802483 0.7168941 ]\n",
      "Precision 0.9392494389122782 [0.95695279 0.7987152 ]\n",
      "Recall 0.9425394967817438 [0.97935609 0.65027894]\n",
      "Log-likelihood 0.14983674875876737\n",
      "\n",
      "Accuracy 0.942032377608738\n",
      "Balanced Accuracy 0.8049323297520286\n",
      "F1 0.9387593291117811 [0.96782157 0.70805501]\n",
      "Precision 0.9384164750521965 [0.95446974 0.8109811 ]\n",
      "Recall 0.942032377608738 [0.98155225 0.62831241]\n",
      "Log-likelihood 0.14875411432786673\n",
      "\n",
      "Accuracy 0.9409401209284182\n",
      "Balanced Accuracy 0.8105648168006508\n",
      "F1 0.9382398307969639 [0.96713697 0.70884615]\n",
      "Precision 0.9374753989627116 [0.95601425 0.79030875]\n",
      "Recall 0.9409401209284182 [0.97852154 0.64260809]\n",
      "Log-likelihood 0.15060901882233826\n",
      "\n",
      "Accuracy 0.9432416617905208\n",
      "Balanced Accuracy 0.8121653036684344\n",
      "F1 0.9403454030825453 [0.96845528 0.71720117]\n",
      "Precision 0.9398774052475104 [0.95620344 0.81027668]\n",
      "Recall 0.9432416617905208 [0.98102517 0.64330544]\n",
      "Log-likelihood 0.1498183520103225\n",
      "\n",
      "Accuracy 0.9404720109225668\n",
      "Balanced Accuracy 0.8060347520901665\n",
      "F1 0.9374982075647613 [0.9669081  0.70403413]\n",
      "Precision 0.9368151122851 [0.95489785 0.79326923]\n",
      "Recall 0.9404720109225668 [0.97922432 0.63284519]\n",
      "Log-likelihood 0.15234057448090887\n",
      "\n",
      "Accuracy 0.9431246342890579\n",
      "Balanced Accuracy 0.8095090284275137\n",
      "F1 0.9400490741831102 [0.96841147 0.71490027]\n",
      "Precision 0.9396878436994107 [0.95553465 0.81389136]\n",
      "Recall 0.9431246342890579 [0.98164009 0.63737796]\n",
      "Log-likelihood 0.1478864521173979\n",
      "\n",
      "Accuracy 0.9424224692802808\n",
      "Balanced Accuracy 0.8107898543972751\n",
      "F1 0.9395349085083649 [0.96799375 0.71362049]\n",
      "Precision 0.9389836484859246 [0.95592959 0.80446194]\n",
      "Recall 0.9424224692802808 [0.98036632 0.64121339]\n",
      "Log-likelihood 0.1498456087678259\n",
      "\n",
      "Accuracy 0.9403159742539496\n",
      "Balanced Accuracy 0.8070135369900611\n",
      "F1 0.9374383663700587 [0.9668084  0.70429068]\n",
      "Precision 0.9366975503010889 [0.9551631  0.79011275]\n",
      "Recall 0.9403159742539496 [0.97874116 0.63528591]\n",
      "Log-likelihood 0.15131637607645704\n",
      "\n",
      "Accuracy 0.9413692217671152\n",
      "Balanced Accuracy 0.8037971028316144\n",
      "F1 0.9380997172628994 [0.96744851 0.70512066]\n",
      "Precision 0.9376787659486565 [0.9542425  0.80619112]\n",
      "Recall 0.9413692217671152 [0.98102517 0.62656904]\n",
      "Log-likelihood 0.15193464539435997\n",
      "\n",
      "Accuracy 0.9427735517846694\n",
      "Balanced Accuracy 0.8163206656187578\n",
      "F1 0.9402386615769975 [0.96814678 0.71869607]\n",
      "Precision 0.9395451007228294 [0.95731707 0.79846613]\n",
      "Recall 0.9427735517846694 [0.97922432 0.65341702]\n",
      "Log-likelihood 0.1491862413664949\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import log_loss,accuracy_score, balanced_accuracy_score, f1_score, precision_score, recall_score, roc_auc_score\n",
    "from imblearn.metrics import geometric_mean_score\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def log_los_nonorm(x,y,average=False):\n",
    "    return log_loss(x,y,normalize=True)\n",
    "\n",
    "scores = {\n",
    "    'Accuracy': {'func': accuracy_score},\n",
    "    'Balanced Accuracy': {'func': balanced_accuracy_score},\n",
    "    'F1': {'func': f1_score},\n",
    "    'Precision': {'func': precision_score},\n",
    "    'Recall': {'func': recall_score},\n",
    "    'Log-likelihood': {'func': log_los_nonorm},\n",
    "    #'G-mean': {'func': geometric_mean_score}\n",
    "}\n",
    "\n",
    "for score_name, score_dict in scores.items():\n",
    "    scores[score_name][\"list\"] = []\n",
    "    scores[score_name][\"lab\"] = []\n",
    "\n",
    "\n",
    "for fold,j in enumerate(foldids):\n",
    "    train = foldids[fold][1]\n",
    "    test = foldids[fold][2]\n",
    "    xin, yin = X_dstil_numpy[train], np.array(y[train])\n",
    "    cls = BertHead()\n",
    "    \n",
    "    cls.fit(xin, yin)\n",
    "    y_pred = cls.predict(X_dstil_numpy[test])\n",
    "    y_pred_proba = cls.predict_proba(X_dstil_numpy[test])\n",
    "    \n",
    "    for score_name, score_dict in scores.items():\n",
    "        if score_name == \"Log-likelihood\":\n",
    "            scorval=score_dict['func'](y[test], y_pred_proba)\n",
    "            score_dict['list'].append(scorval)\n",
    "            print(score_name, scorval)\n",
    "        elif score_name in [\"F1\",\"Precision\",\"Recall\"]:\n",
    "            scorvaln = score_dict['func'](y[test], y_pred, average=None)\n",
    "            score_dict['lab'].append(scorvaln)\n",
    "            scorval = score_dict['func'](y[test], y_pred, average=\"weighted\")\n",
    "            score_dict['list'].append(scorval)\n",
    "            print(score_name, scorval, scorvaln)  \n",
    "        else:\n",
    "            scorval=score_dict['func'](y[test], y_pred)\n",
    "            score_dict['list'].append(scorval)\n",
    "            print(score_name, scorval)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3d1ebf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Score                | Average      | Kat_1      | Kat_2      |\n",
      "| Accuracy             | 94.2 ± 0.103 | -          | -          |\n",
      "| Balanced Accuracy    | 81.0 ± 0.395 | -          | -          |\n",
      "| F1                   | 93.9 ± 0.108 | 96.8 ± 0.1 | 71.1 ± 0.5 |\n",
      "| Log-likelihood       | 0.15 ± 0.001 | -          | -          |\n",
      "| Precision            | 93.8 ± 0.114 | 95.6 ± 0.1 | 80.2 ± 0.8 |\n",
      "| Recall               | 94.2 ± 0.103 | 98.0 ± 0.1 | 63.9 ± 0.8 |\n"
     ]
    }
   ],
   "source": [
    "numlabels = scores[\"F1\"][\"lab\"][0].shape[0]\n",
    "scores[\"F1\"][\"lab\"][0].shape[0] \n",
    "head = \"| %-20s | %-12s |\" +  numlabels * \" %-10s |\" \n",
    "headv = [\"Score\", \"Average\"]\n",
    "headv.extend([\"Kat_\"+str(i+1) for i in range(numlabels)])\n",
    "row=head % tuple(headv)\n",
    "#print(\"+\"*len(row))\n",
    "print(row)\n",
    "#print(\"+\"*len(row))\n",
    "\n",
    "for score_name, score_dict in sorted(scores.items()) :\n",
    "    if score_name == \"Log-likelihood\":\n",
    "        headv = [score_name, np.mean(score_dict['list'])*1, np.std(score_dict['list'])*1]\n",
    "    else:\n",
    "        headv = [score_name, np.mean(score_dict['list'])*100, np.std(score_dict['list'])*100]\n",
    "    \n",
    "    for i in range(numlabels):\n",
    "        if score_name == \"Log-likelihood\":\n",
    "            head = \"| %-20s | %3.2f ± %3.3f |\" + numlabels * \" %-10s |\" \n",
    "            headv.append(\"-\")\n",
    "        elif score_name in [\"F1\",\"Precision\",\"Recall\"]:\n",
    "            head = \"| %-20s | %4.1f ± %3.3f |\" + numlabels* \" %4.1f ± %3.1f |\"\n",
    "            vals = [v[i] for v in scores[score_name][\"lab\"]]\n",
    "            headv.append(np.mean(vals)*100)\n",
    "            headv.append(np.std(vals)*100)\n",
    "        else:\n",
    "            head = \"| %-20s | %4.1f ± %3.3f |\" + numlabels * \" %-10s |\" \n",
    "            headv.append(\"-\")\n",
    "    print(head % tuple(headv))\n",
    "    \n",
    "#print(\"+\"*len(row))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env.hator",
   "language": "python",
   "name": "env.hator"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
