{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4aefad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d503a6af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-08-25 12:33:21--  https://docs.google.com/uc?export=download&confirm=&id=18E24-G2Xq-y5HfM6ZatUB_8WKL_r6HOV\n",
      "Resolving docs.google.com (docs.google.com)... 142.250.203.206, 2a00:1450:401b:810::200e\n",
      "Connecting to docs.google.com (docs.google.com)|142.250.203.206|:443... connected.\n",
      "HTTP request sent, awaiting response... 303 See Other\n",
      "Location: https://doc-0k-34-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/hu3hf9fb264l5mne6gmhhtkla9f5dc4e/1661423550000/05536367513713019519/*/18E24-G2Xq-y5HfM6ZatUB_8WKL_r6HOV?e=download&uuid=a2cba134-b25d-4da1-a1bb-a764bceac670 [following]\n",
      "Warning: wildcards not supported in HTTP.\n",
      "--2022-08-25 12:33:24--  https://doc-0k-34-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/hu3hf9fb264l5mne6gmhhtkla9f5dc4e/1661423550000/05536367513713019519/*/18E24-G2Xq-y5HfM6ZatUB_8WKL_r6HOV?e=download&uuid=a2cba134-b25d-4da1-a1bb-a764bceac670\n",
      "Resolving doc-0k-34-docs.googleusercontent.com (doc-0k-34-docs.googleusercontent.com)... 142.250.75.1, 2a00:1450:401b:80d::2001\n",
      "Connecting to doc-0k-34-docs.googleusercontent.com (doc-0k-34-docs.googleusercontent.com)|142.250.75.1|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 51522510 (49M) [text/csv]\n",
      "Saving to: ‘pubhealth.csv’\n",
      "\n",
      "pubhealth.csv       100%[===================>]  49,13M  1,79MB/s    in 14s     \n",
      "\n",
      "2022-08-25 12:33:39 (3,40 MB/s) - ‘pubhealth.csv’ saved [51522510/51522510]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!id=\"18E24-G2Xq-y5HfM6ZatUB_8WKL_r6HOV\"; conf=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id='$id -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p'); wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$conf&id=$id\" -O pubhealth.csv && rm -rf /tmp/cookies.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f796758",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels\n",
      " 1    6306\n",
      "0    3769\n",
      "Name: label, dtype: int64\n",
      "shape  \n",
      " (10075, 11)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 10/10 [00:00<00:00, 1807.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shapes X (10075,) y (10075,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "\n",
    "data = pd.read_csv(\"../../raw/pubhealth.csv\",sep=\",\")\n",
    "print(\"labels\\n\",data[\"label\"].value_counts())\n",
    "print(\"shape  \\n\",data.shape)\n",
    "\n",
    "bootstrap_size = 0\n",
    "\n",
    "if bootstrap_size != 0:\n",
    "    bootstrap_factor = bootstrap_size / data.shape[0]\n",
    "    bootstrap = np.random.uniform(size=data.shape[0]) < bootstrap_factor\n",
    "    data = data.iloc[bootstrap]\n",
    "\n",
    "X, y = data[\"text\"].values, data[\"label\"].values\n",
    "\n",
    "rskf = RepeatedStratifiedKFold(n_splits=2, n_repeats=5, random_state=1410)\n",
    "foldids = []\n",
    "for fold_idx, (train, test) in tqdm(enumerate(rskf.split(X, y)), total=rskf.get_n_splits()):\n",
    "    foldids.append((fold_idx,train,test))\n",
    "    \n",
    "print(\"shapes X\",X.shape,\"y\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b756ff71",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0.1', 'claim_id', 'claim', 'date_published', 'explanation',\n",
       "       'fact_checkers', 'text', 'sources', 'label', 'subjects', 'Unnamed: 0'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2c31e30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "transformers.logging.set_verbosity_error()\n",
    "from torch.utils.data import DataLoader \n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModel\n",
    "from transformers import TFDistilBertModel, DistilBertTokenizerFast\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from scipy.sparse import csr_matrix\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(\"using device:\", device)\n",
    "\n",
    "if \"disilbert_model\" not in locals():\n",
    "    disilbert_tokenizer =  AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "    disilbert_model = AutoModel.from_pretrained(\"distilbert-base-uncased\")\n",
    "    handle = disilbert_model.to(device)\n",
    "\n",
    "\n",
    "class BERTEmbeddings(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.tokenizer =  disilbert_tokenizer\n",
    "        self.model = disilbert_tokenizer\n",
    "        self.max_length = 256\n",
    "        self.model_name = disilbert_model\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        pass\n",
    "    \n",
    "    def encode(self, txt):\n",
    "        return self.tokenizer(txt, max_length=self.max_length, \n",
    "                              truncation=True, padding=True, return_tensors=\"pt\")\n",
    "\n",
    "    def transform(self, X=None):\n",
    "        dataloader = DataLoader(X, batch_size=4, shuffle=False)\n",
    "        allembeds = []\n",
    "        for batch in tqdm(dataloader):\n",
    "            batchenc = disilbert_tokenizer(batch, max_length=256, truncation=True, padding=True, return_tensors=\"pt\")\n",
    "            input_ids = batchenc['input_ids'].to(device)\n",
    "            attention_mask = batchenc['attention_mask'].to(device)\n",
    "            batchout = disilbert_model(input_ids, attention_mask=attention_mask, output_hidden_states=True)\n",
    "            embeds = [vec[0].cpu().detach().numpy() for vec in batchout[1][-1]]\n",
    "            allembeds.extend(embeds)\n",
    "        return csr_matrix(allembeds)\n",
    "\n",
    "\n",
    "class BertHead(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.head = LogisticRegression(class_weight='auto', max_iter=10000)\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.head.fit(X, y)\n",
    "\n",
    "\n",
    "    def transform(self, X=None):\n",
    "        pass\n",
    "    \n",
    "    def predict(self, X=None):    \n",
    "        return self.head.predict(X)\n",
    "    \n",
    "    def predict_proba(self, X=None):    \n",
    "        return self.head.predict_proba(X)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07fe3749",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 630/630 [00:20<00:00, 30.83it/s]\n"
     ]
    }
   ],
   "source": [
    "bert = BERTEmbeddings()\n",
    "X_dstil_numpy = bert.transform(X).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "09a23149",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# SAVE\n",
    "with open('pubhealth_BERTEmbeddings.pickle', 'wb') as handle:\n",
    "    pickle.dump(X_dstil_numpy, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96b41e15-dae3-40c8-88fe-5cab18f73698",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# LOAD\n",
    "with open('../../pickles/bertcls_embeddings/pubhealth_BERTEmbeddings.pickle', 'rb') as handle:\n",
    "    X_dstil_numpy=pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b737cfcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.8157999206034141\n",
      "Balanced Accuracy 0.8047291073046512\n",
      "F1 0.8160494368962884 [0.75553214 0.8522293 ]\n",
      "Precision 0.8163437625778484 [0.75039246 0.85577231]\n",
      "Recall 0.8157999206034141 [0.76074271 0.84871551]\n",
      "Log-likelihood 0.406668256145782\n",
      "\n",
      "Accuracy 0.8183442525312686\n",
      "Balanced Accuracy 0.8026682201361155\n",
      "F1 0.8176982496480985 [0.75303644 0.85633537]\n",
      "Precision 0.817320078425967 [0.7660626  0.84794776]\n",
      "Recall 0.8183442525312686 [0.74044586 0.86489058]\n",
      "Log-likelihood 0.3920066757368861\n",
      "\n",
      "Accuracy 0.8191742755061532\n",
      "Balanced Accuracy 0.8083850082570513\n",
      "F1 0.8194284106221118 [0.76007374 0.8549132 ]\n",
      "Precision 0.8197310936086666 [0.75470711 0.85860525]\n",
      "Recall 0.8191742755061532 [0.76551724 0.85125278]\n",
      "Log-likelihood 0.3909357344116411\n",
      "\n",
      "Accuracy 0.8209251538614255\n",
      "Balanced Accuracy 0.8065455808945479\n",
      "F1 0.8205082779506149 [0.75791734 0.857908  ]\n",
      "Precision 0.8202104694411543 [0.76655809 0.85226917]\n",
      "Recall 0.8209251538614255 [0.74946921 0.86362195]\n",
      "Log-likelihood 0.39837984251249425\n",
      "\n",
      "Accuracy 0.8251290194521635\n",
      "Balanced Accuracy 0.8128223636114315\n",
      "F1 0.8250443991710715 [0.76575379 0.86049089]\n",
      "Precision 0.8249652479119872 [0.76759062 0.85926629]\n",
      "Recall 0.8251290194521635 [0.76392573 0.861719  ]\n",
      "Log-likelihood 0.3923068146602711\n",
      "\n",
      "Accuracy 0.813579511614056\n",
      "Balanced Accuracy 0.797794184489143\n",
      "F1 0.8129607996889001 [0.74683203 0.85247447]\n",
      "Precision 0.8125752000575567 [0.75890411 0.84464508]\n",
      "Recall 0.813579511614056 [0.735138   0.86045036]\n",
      "Log-likelihood 0.4007881631686106\n",
      "\n",
      "Accuracy 0.815005954743946\n",
      "Balanced Accuracy 0.8006812593117918\n",
      "F1 0.8146602132334574 [0.75053533 0.85299685]\n",
      "Precision 0.8143916979881094 [0.75742842 0.84844682]\n",
      "Recall 0.815005954743946 [0.74376658 0.85759594]\n",
      "Log-likelihood 0.40605938746029163\n",
      "\n",
      "Accuracy 0.8155648203295612\n",
      "Balanced Accuracy 0.8048274719658358\n",
      "F1 0.8158803229833848 [0.75559063 0.85190499]\n",
      "Precision 0.8162679499021553 [0.74908712 0.85641026]\n",
      "Recall 0.8155648203295612 [0.76220807 0.84744688]\n",
      "Log-likelihood 0.3981863618218669\n",
      "\n",
      "Accuracy 0.8197697499007542\n",
      "Balanced Accuracy 0.8064072699067286\n",
      "F1 0.8195540877044386 [0.75773746 0.85651075]\n",
      "Precision 0.8193709209914205 [0.76221149 0.85354331]\n",
      "Recall 0.8197697499007542 [0.75331565 0.85949889]\n",
      "Log-likelihood 0.4022147070746437\n",
      "\n",
      "Accuracy 0.8155648203295612\n",
      "Balanced Accuracy 0.8017298761062662\n",
      "F1 0.8153130376173285 [0.75180337 0.85326173]\n",
      "Precision 0.8151030024075956 [0.75685853 0.8499056 ]\n",
      "Recall 0.8155648203295612 [0.74681529 0.85664447]\n",
      "Log-likelihood 0.4044929436309028\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import log_loss,accuracy_score, balanced_accuracy_score, f1_score, precision_score, recall_score, roc_auc_score\n",
    "from imblearn.metrics import geometric_mean_score\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def log_los_nonorm(x,y,average=False):\n",
    "    return log_loss(x,y,normalize=True)\n",
    "\n",
    "scores = {\n",
    "    'Accuracy': {'func': accuracy_score},\n",
    "    'Balanced Accuracy': {'func': balanced_accuracy_score},\n",
    "    'F1': {'func': f1_score},\n",
    "    'Precision': {'func': precision_score},\n",
    "    'Recall': {'func': recall_score},\n",
    "    'Log-likelihood': {'func': log_los_nonorm},\n",
    "    #'G-mean': {'func': geometric_mean_score}\n",
    "}\n",
    "\n",
    "for score_name, score_dict in scores.items():\n",
    "    scores[score_name][\"list\"] = []\n",
    "    scores[score_name][\"lab\"] = []\n",
    "\n",
    "\n",
    "for fold,j in enumerate(foldids):\n",
    "    train = foldids[fold][1]\n",
    "    test = foldids[fold][2]\n",
    "    xin, yin = X_dstil_numpy[train], np.array(y[train])\n",
    "    cls = BertHead()\n",
    "    \n",
    "    cls.fit(xin, yin)\n",
    "    y_pred = cls.predict(X_dstil_numpy[test])\n",
    "    y_pred_proba = cls.predict_proba(X_dstil_numpy[test])\n",
    "    \n",
    "    for score_name, score_dict in scores.items():\n",
    "        if score_name == \"Log-likelihood\":\n",
    "            scorval=score_dict['func'](y[test], y_pred_proba)\n",
    "            score_dict['list'].append(scorval)\n",
    "            print(score_name, scorval)\n",
    "        elif score_name in [\"F1\",\"Precision\",\"Recall\"]:\n",
    "            scorvaln = score_dict['func'](y[test], y_pred, average=None)\n",
    "            score_dict['lab'].append(scorvaln)\n",
    "            scorval = score_dict['func'](y[test], y_pred, average=\"weighted\")\n",
    "            score_dict['list'].append(scorval)\n",
    "            print(score_name, scorval, scorvaln)  \n",
    "        else:\n",
    "            scorval=score_dict['func'](y[test], y_pred)\n",
    "            score_dict['list'].append(scorval)\n",
    "            print(score_name, scorval)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd11aeaf-b4f5-4cd8-af80-449d5bfbc921",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Score                | Average      | Kat_1      | Kat_2      |\n",
      "| Accuracy             | 81.8 ± 0.330 | -          | -          |\n",
      "| Balanced Accuracy    | 80.5 ± 0.403 | -          | -          |\n",
      "| F1                   | 81.8 ± 0.334 | 75.5 ± 0.5 | 85.5 ± 0.3 |\n",
      "| Log-likelihood       | 0.40 ± 0.006 | -          | -          |\n",
      "| Precision            | 81.8 ± 0.338 | 75.9 ± 0.6 | 85.3 ± 0.5 |\n",
      "| Recall               | 81.8 ± 0.330 | 75.2 ± 1.0 | 85.7 ± 0.6 |\n"
     ]
    }
   ],
   "source": [
    "numlabels = scores[\"F1\"][\"lab\"][0].shape[0]\n",
    "scores[\"F1\"][\"lab\"][0].shape[0] \n",
    "head = \"| %-20s | %-12s |\" +  numlabels * \" %-10s |\" \n",
    "headv = [\"Score\", \"Average\"]\n",
    "headv.extend([\"Kat_\"+str(i+1) for i in range(numlabels)])\n",
    "row=head % tuple(headv)\n",
    "#print(\"+\"*len(row))\n",
    "print(row)\n",
    "#print(\"+\"*len(row))\n",
    "\n",
    "for score_name, score_dict in sorted(scores.items()) :\n",
    "    if score_name == \"Log-likelihood\":\n",
    "        headv = [score_name, np.mean(score_dict['list'])*1, np.std(score_dict['list'])*1]\n",
    "    else:\n",
    "        headv = [score_name, np.mean(score_dict['list'])*100, np.std(score_dict['list'])*100]\n",
    "    \n",
    "    for i in range(numlabels):\n",
    "        if score_name == \"Log-likelihood\":\n",
    "            head = \"| %-20s | %3.2f ± %3.3f |\" + numlabels * \" %-10s |\" \n",
    "            headv.append(\"-\")\n",
    "        elif score_name in [\"F1\",\"Precision\",\"Recall\"]:\n",
    "            head = \"| %-20s | %4.1f ± %3.3f |\" + numlabels* \" %4.1f ± %3.1f |\"\n",
    "            vals = [v[i] for v in scores[score_name][\"lab\"]]\n",
    "            headv.append(np.mean(vals)*100)\n",
    "            headv.append(np.std(vals)*100)\n",
    "        else:\n",
    "            head = \"| %-20s | %4.1f ± %3.3f |\" + numlabels * \" %-10s |\" \n",
    "            headv.append(\"-\")\n",
    "    print(head % tuple(headv))\n",
    "    \n",
    "#print(\"+\"*len(row))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env.hator",
   "language": "python",
   "name": "env.hator"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
