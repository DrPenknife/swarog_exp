{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4aefad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d503a6af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "--2022-08-25 13:40:49--  https://docs.google.com/uc?export=download&confirm=&id=1fdWdDm8LYw68kIZ6Z7xlT3Re8QqtLWis\n",
      "Resolving docs.google.com (docs.google.com)... 142.250.186.206, 2a00:1450:401b:80d::200e\n",
      "Connecting to docs.google.com (docs.google.com)|142.250.186.206|:443... connected.\n",
      "HTTP request sent, awaiting response... 303 See Other\n",
      "Location: https://doc-0o-34-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/5s8se6csd5q1pm9jf4qfko82i3unu6tk/1661427600000/05536367513713019519/*/1fdWdDm8LYw68kIZ6Z7xlT3Re8QqtLWis?e=download&uuid=259db83d-7360-4079-86c4-7e69043a1bd3 [following]\n",
      "Warning: wildcards not supported in HTTP.\n",
      "--2022-08-25 13:40:50--  https://doc-0o-34-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/5s8se6csd5q1pm9jf4qfko82i3unu6tk/1661427600000/05536367513713019519/*/1fdWdDm8LYw68kIZ6Z7xlT3Re8QqtLWis?e=download&uuid=259db83d-7360-4079-86c4-7e69043a1bd3\n",
      "Resolving doc-0o-34-docs.googleusercontent.com (doc-0o-34-docs.googleusercontent.com)... 142.250.75.1, 2a00:1450:401b:801::2001\n",
      "Connecting to doc-0o-34-docs.googleusercontent.com (doc-0o-34-docs.googleusercontent.com)|142.250.75.1|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 16417084 (16M) [text/csv]\n",
      "Saving to: ‘mmcovid_en.csv’\n",
      "\n",
      "mmcovid_en.csv      100%[===================>]  15,66M  3,84MB/s    in 4,1s    \n",
      "\n",
      "2022-08-25 13:40:54 (3,79 MB/s) - ‘mmcovid_en.csv’ saved [16417084/16417084]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!id=\"1fdWdDm8LYw68kIZ6Z7xlT3Re8QqtLWis\"; conf=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id='$id -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p'); wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$conf&id=$id\" -O mmcovid_en.csv && rm -rf /tmp/cookies.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f796758",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels\n",
      " 0    5304\n",
      "1    2028\n",
      "Name: label, dtype: int64\n",
      "shape  \n",
      " (7332, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 10/10 [00:00<00:00, 2573.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shapes X (7332,) y (7332,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "\n",
    "data = pd.read_csv(\"raw/mmcovid_en.csv\",sep=\",\")\n",
    "print(\"labels\\n\",data[\"label\"].value_counts())\n",
    "print(\"shape  \\n\",data.shape)\n",
    "\n",
    "bootstrap_size = 0\n",
    "\n",
    "if bootstrap_size != 0:\n",
    "    bootstrap_factor = bootstrap_size / data.shape[0]\n",
    "    bootstrap = np.random.uniform(size=data.shape[0]) < bootstrap_factor\n",
    "    data = data.iloc[bootstrap]\n",
    "\n",
    "    \n",
    "X, y = data[\"text\"].astype(str).values, data[\"label\"].values\n",
    "\n",
    "rskf = RepeatedStratifiedKFold(n_splits=2, n_repeats=5, random_state=1410)\n",
    "foldids = []\n",
    "for fold_idx, (train, test) in tqdm(enumerate(rskf.split(X, y)), total=rskf.get_n_splits()):\n",
    "    foldids.append((fold_idx,train,test))\n",
    "    \n",
    "print(\"shapes X\",X.shape,\"y\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "206399a9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'lang', 'label', 'text'], dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "05333ffa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0,\n",
       " 'This article by Daniel Jolley and Pia Lamberty is republished here with permission from The Conversation. This content is shared here because the topic may interest Snopes readers; it does not, however, represent the work of Snopes fact-checkers or editors. The novel coronavirus continues to spread around the world, with new cases being reported all the time. Spreading just as fast, it seems, are conspiracy theories that claim powerful actors are plotting something sinister to do with the virus. Our research into medical conspiracy theories shows that this has the potential to be just as dangerous for societies as the outbreak itself. One conspiracy theory proposes that the coronavirus is actually a bio-weapon engineered by the CIA as a way to wage war on China. Others are convinced that the UK and US governments introduced the coronavirus as a way to make money from a potential vaccine. Although many of these conspiracy theories seem far-fetched, the belief that evil powers are pursuing a secret plan is widespread in every society. Often these relate to health. A large 2019 YouGov poll found 16% of respondents in Spain believe that HIV was created and spread around the world on purpose by a secret group or organisation. And 27% of French and 12% of British respondents were convinced that “the truth about the harmful effects of vaccines is being deliberately hidden from the public”. The spread of fake news and conspiracy theories around the coronavirus is such a significant problem that the World Health Organisation (WHO) has created a “myth busters” webpage to try and tackle them. Spread of conspiracy theories Research shows that conspiracy theories have a tendency to arise in relation to moments of crisis in society – like terrorist attacks, rapid political changes or economic crisis. Conspiracy theories bloom in periods of uncertainty and threat, where we seek to make sense of a chaotic world. These are the same conditions produced by virus outbreaks, which explains the spread of conspiracy theories in relation to coronavirus. Similar conditions occurred with the 2015-16 outbreak of Zika virus. Zika conspiracy theories proposed that the virus was a biological weapon rather than a natural occurrence. Research examining comments on Reddit during the Zika virus outbreak found conspiracy talk emerged as a way for people to cope with the extreme uncertainty they felt over Zika. Trust in the recommendations from health professionals and organisations is an important resource for dealing with a health crisis. But people who believe in conspiracy theories generally do not trust groups they perceive as powerful, including managers, politicians and drug companies. If people do not trust, they are less likely to follow medical advice. Researchers have shown that medical conspiracy theories have the power to increase distrust in medical authorities, which can impact people’s willingness to protect themselves. People who endorse medical conspiracy theories are less likely to get vaccinated or use antibiotics and are more likely to take herbal supplements or vitamins. Plus, they are more likely to say they would trust medical advice from nonprofessionals such as friends and family. Severe consequences In light of these results, people who endorse conspiracy theories about the coronavirus may be less likely to follow health advice like frequent hand-cleaning with alcohol-based hand rub or soap, or self-isolating after visiting at-risk areas. Instead, these people may be more likely to have negative attitudes towards prevention behaviour or use dangerous alternatives as treatments. This would increase the likelihood of the virus spreading and put more people in danger. Already, we can see “alternative healing approaches” to coronavirus cropping up – some of them very dangerous. Promoters of the popular QAnon conspiracy theory, for example, have said the coronavirus was planned by the so-called “deep state” and claimed the virus can be warded off by drinking bleach. The spread of medical conspiracy theories can also have severe consequences for other sections of society. For example, during the Black Death in Europe, Jews were scapegoated as responsible for the pandemic. These conspiracy theories led to violent attacks and massacres of Jewish communities all over Europe. The outbreak of the coronavirus has led to a worldwide increase in racist attacks targeted towards people perceived as East Asian. It is possible to intervene and halt the spread of conspiracy theories, however. Research shows that campaigns promoting counterarguments to medical conspiracy theories are likely to have some success in rectifying conspiracy beliefs. Games such as Bad News, in which people can take the role of a fake news producer, have been shown to improve people’s ability to spot and resist misinformation. Conspiracy theories can be very harmful for society. Not only can they influence people’s health choices, they can interfere with how different groups relate to each other and increase hostility and violence towards those who are perceived to be “conspiring”. So as well as acting to combat the spread of the coronavirus, governments should also act to stop misinformation and conspiracy theories relating to the virus from getting out of hand.  Daniel Jolley, Senior Lecturer in Psychology, Northumbria University, Newcastle and Pia Lamberty, PhD Researcher in Social and Legal Psychology, Johannes Gutenberg University of Mainz This article is republished from The Conversation under a Creative Commons license. Read the original article.')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0],X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2c31e30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "transformers.logging.set_verbosity_error()\n",
    "from torch.utils.data import DataLoader \n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModel\n",
    "from transformers import TFDistilBertModel, DistilBertTokenizerFast\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from scipy.sparse import csr_matrix\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(\"using device:\", device)\n",
    "\n",
    "if \"disilbert_model\" not in locals():\n",
    "    disilbert_tokenizer =  AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "    disilbert_model = AutoModel.from_pretrained(\"distilbert-base-uncased\")\n",
    "    handle = disilbert_model.to(device)\n",
    "\n",
    "\n",
    "class BERTEmbeddings(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.tokenizer =  disilbert_tokenizer\n",
    "        self.model = disilbert_tokenizer\n",
    "        self.max_length = 256\n",
    "        self.model_name = disilbert_model\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        pass\n",
    "    \n",
    "    def encode(self, txt):\n",
    "        return self.tokenizer(txt, max_length=self.max_length, \n",
    "                              truncation=True, padding=True, return_tensors=\"pt\")\n",
    "\n",
    "    def transform(self, X=None):\n",
    "        dataloader = DataLoader(X, batch_size=4, shuffle=False)\n",
    "        allembeds = []\n",
    "        for batch in tqdm(dataloader):\n",
    "            batchenc = disilbert_tokenizer(batch, max_length=256, truncation=True, padding=True, return_tensors=\"pt\")\n",
    "            input_ids = batchenc['input_ids'].to(device)\n",
    "            attention_mask = batchenc['attention_mask'].to(device)\n",
    "            batchout = disilbert_model(input_ids, attention_mask=attention_mask, output_hidden_states=True)\n",
    "            embeds = [vec[0].cpu().detach().numpy() for vec in batchout[1][-1]]\n",
    "            allembeds.extend(embeds)\n",
    "        return csr_matrix(allembeds)\n",
    "\n",
    "\n",
    "class BertHead(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.head = LogisticRegression(class_weight='auto', max_iter=10000)\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.head.fit(X, y)\n",
    "\n",
    "\n",
    "    def transform(self, X=None):\n",
    "        pass\n",
    "    \n",
    "    def predict(self, X=None):    \n",
    "        return self.head.predict(X)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07fe3749",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 1833/1833 [00:15<00:00, 119.51it/s]\n"
     ]
    }
   ],
   "source": [
    "bert = BERTEmbeddings()\n",
    "X_dstil_numpy = bert.transform(X).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6a40e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# SAVE\n",
    "with open('mmcovid_en_BERTEmbeddings.pickle', 'wb') as handle:\n",
    "    pickle.dump(X_dstil_numpy, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b737cfcb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " BAC= 0.8763922728854856\n",
      " BAC= 0.8911706694512125\n",
      " BAC= 0.8927369764473837\n",
      " BAC= 0.8716498433693004\n",
      " BAC= 0.8888937231697412\n",
      " BAC= 0.8771899292261283\n",
      " BAC= 0.8851229841048845\n",
      " BAC= 0.8854710523262559\n",
      " BAC= 0.8838902424875276\n",
      " BAC= 0.8760877131917857\n",
      "----------\n",
      "AVG. BAC= 0.8828605406659704 +/- 0.006793676991393898\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "arr = []\n",
    "\n",
    "for fold,j in enumerate(foldids):\n",
    "    train = foldids[fold][1]\n",
    "    test = foldids[fold][2]\n",
    "    xin, yin = X_dstil_numpy[train], np.array(y[train])\n",
    "    cls = BertHead()\n",
    "    \n",
    "    cls.fit(xin, yin)\n",
    "    y_pred = cls.predict(X_dstil_numpy[test])\n",
    "\n",
    "    bac = balanced_accuracy_score(y[test], y_pred)\n",
    "    arr.append(bac)\n",
    "\n",
    "    print(\" BAC=\", bac)\n",
    "\n",
    "print(10*\"-\")\n",
    "print(\"AVG. BAC=\",np.mean(arr),\"+/-\",np.std(arr))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
