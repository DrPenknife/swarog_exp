{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477c4765",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e84036e8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-08-25 12:33:21--  https://docs.google.com/uc?export=download&confirm=&id=18E24-G2Xq-y5HfM6ZatUB_8WKL_r6HOV\n",
      "Resolving docs.google.com (docs.google.com)... 142.250.203.206, 2a00:1450:401b:810::200e\n",
      "Connecting to docs.google.com (docs.google.com)|142.250.203.206|:443... connected.\n",
      "HTTP request sent, awaiting response... 303 See Other\n",
      "Location: https://doc-0k-34-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/hu3hf9fb264l5mne6gmhhtkla9f5dc4e/1661423550000/05536367513713019519/*/18E24-G2Xq-y5HfM6ZatUB_8WKL_r6HOV?e=download&uuid=a2cba134-b25d-4da1-a1bb-a764bceac670 [following]\n",
      "Warning: wildcards not supported in HTTP.\n",
      "--2022-08-25 12:33:24--  https://doc-0k-34-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/hu3hf9fb264l5mne6gmhhtkla9f5dc4e/1661423550000/05536367513713019519/*/18E24-G2Xq-y5HfM6ZatUB_8WKL_r6HOV?e=download&uuid=a2cba134-b25d-4da1-a1bb-a764bceac670\n",
      "Resolving doc-0k-34-docs.googleusercontent.com (doc-0k-34-docs.googleusercontent.com)... 142.250.75.1, 2a00:1450:401b:80d::2001\n",
      "Connecting to doc-0k-34-docs.googleusercontent.com (doc-0k-34-docs.googleusercontent.com)|142.250.75.1|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 51522510 (49M) [text/csv]\n",
      "Saving to: ‘pubhealth.csv’\n",
      "\n",
      "pubhealth.csv       100%[===================>]  49,13M  1,79MB/s    in 14s     \n",
      "\n",
      "2022-08-25 12:33:39 (3,40 MB/s) - ‘pubhealth.csv’ saved [51522510/51522510]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!id=\"18E24-G2Xq-y5HfM6ZatUB_8WKL_r6HOV\"; conf=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id='$id -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p'); wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$conf&id=$id\" -O pubhealth.csv && rm -rf /tmp/cookies.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c26a61d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels\n",
      " 0    494808\n",
      "1    262288\n",
      "Name: label, dtype: int64\n",
      "shape  \n",
      " (757096, 9)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 10/10 [00:00<00:00, 38.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shapes X (757096,) y (757096,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "\n",
    "data = pd.read_csv(\"../../raw/nela-gt-2020.csv\",sep=\",\")\n",
    "print(\"labels\\n\",data[\"label\"].value_counts())\n",
    "print(\"shape  \\n\",data.shape)\n",
    "\n",
    "bootstrap_size = 0\n",
    "\n",
    "if bootstrap_size != 0:\n",
    "    bootstrap_factor = bootstrap_size / data.shape[0]\n",
    "    bootstrap = np.random.uniform(size=data.shape[0]) < bootstrap_factor\n",
    "    data = data.iloc[bootstrap]\n",
    "\n",
    "data[\"text\"] = [ str(v) for v in data[\"text\"]]\n",
    "X, y = data[\"text\"].values, data[\"label\"].values\n",
    "\n",
    "rskf = RepeatedStratifiedKFold(n_splits=2, n_repeats=5, random_state=1410)\n",
    "foldids = []\n",
    "for fold_idx, (train, test) in tqdm(enumerate(rskf.split(X, y)), total=rskf.get_n_splits()):\n",
    "    foldids.append((fold_idx,train,test))\n",
    "    \n",
    "print(\"shapes X\",X.shape,\"y\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b30aa57",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'source', 'title', 'text', 'author', 'url',\n",
       "       'published_utc', 'collection_utc', 'label'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bbe3e515",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# SAVE\n",
    "with open('nela-gt-X.pickle', 'wb') as handle:\n",
    "    pickle.dump(X, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open('nela-gt-y.pickle', 'wb') as handle:\n",
    "    pickle.dump(y, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "014cbce8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 10/10 [00:00<00:00, 37.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shapes X (757096,) (757096,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# load\n",
    "# with open('nela-gt-X.pickle', 'rb') as handle:\n",
    "#     X=pickle.load(handle)\n",
    "    \n",
    "with open('../../pickles/products/nela-gt-X.pickle', 'rb') as handle:\n",
    "    X=pickle.load(handle)    \n",
    "    \n",
    "with open('../../pickles/products/nela-gt-y.pickle', 'rb') as handle:\n",
    "    y=pickle.load(handle)\n",
    "    \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "\n",
    "rskf = RepeatedStratifiedKFold(n_splits=2, n_repeats=5, random_state=1410)\n",
    "foldids = []\n",
    "for fold_idx, (train, test) in tqdm(enumerate(rskf.split(X, y)), total=rskf.get_n_splits()):\n",
    "    foldids.append((fold_idx,train,test))\n",
    "    \n",
    "print(\"shapes X\", X.shape,y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7aaaa67",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "transformers.logging.set_verbosity_error()\n",
    "from torch.utils.data import DataLoader \n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModel\n",
    "from transformers import TFDistilBertModel, DistilBertTokenizerFast\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from scipy.sparse import csr_matrix\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(\"using device:\", device)\n",
    "\n",
    "if \"disilbert_model\" not in locals():\n",
    "    disilbert_tokenizer =  AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "    disilbert_model = AutoModel.from_pretrained(\"distilbert-base-uncased\")\n",
    "    handle = disilbert_model.to(device)\n",
    "\n",
    "\n",
    "class BERTEmbeddings(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.tokenizer =  disilbert_tokenizer\n",
    "        self.model = disilbert_tokenizer\n",
    "        self.max_length = 256\n",
    "        self.model_name = disilbert_model\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        pass\n",
    "    \n",
    "    def encode(self, txt):\n",
    "        return self.tokenizer(txt, max_length=self.max_length, \n",
    "                              truncation=True, padding=True, return_tensors=\"pt\")\n",
    "\n",
    "    def transform(self, X=None):\n",
    "        dataloader = DataLoader(X, batch_size=4, shuffle=False)\n",
    "        allembeds = []\n",
    "        for batch in tqdm(dataloader):\n",
    "            batchenc = disilbert_tokenizer(batch, max_length=256, truncation=True, padding=True, return_tensors=\"pt\")\n",
    "            input_ids = batchenc['input_ids'].to(device)\n",
    "            attention_mask = batchenc['attention_mask'].to(device)\n",
    "            batchout = disilbert_model(input_ids, attention_mask=attention_mask, output_hidden_states=True)\n",
    "            embeds = [vec[0].cpu().detach().numpy() for vec in batchout[1][-1]]\n",
    "            allembeds.extend(embeds)\n",
    "        return csr_matrix(allembeds)\n",
    "\n",
    "\n",
    "class BertHead(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.head = LogisticRegression(class_weight='auto', max_iter=10000)\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.head.fit(X, y)\n",
    "\n",
    "\n",
    "    def transform(self, X=None):\n",
    "        pass\n",
    "    \n",
    "    def predict(self, X=None):    \n",
    "        return self.head.predict(X)\n",
    "    \n",
    "    def predict_proba(self, X=None):    \n",
    "        return self.head.predict_proba(X)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af643837",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 47319/47319 [24:03<00:00, 32.78it/s]\n"
     ]
    }
   ],
   "source": [
    "bert = BERTEmbeddings()\n",
    "X_dstil_numpy = bert.transform(X).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da0d9c3d",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'pickles/bertcls_embeddings/nela-gt_BERTEmbeddings.pickle'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [3], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpickle\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# SAVE\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpickles/bertcls_embeddings/nela-gt_BERTEmbeddings.pickle\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mwb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handle:\n\u001b[1;32m      5\u001b[0m     pickle\u001b[38;5;241m.\u001b[39mdump(X_dstil_numpy, handle, protocol\u001b[38;5;241m=\u001b[39mpickle\u001b[38;5;241m.\u001b[39mHIGHEST_PROTOCOL)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'pickles/bertcls_embeddings/nela-gt_BERTEmbeddings.pickle'"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# SAVE\n",
    "with open('pickles/bertcls_embeddings/nela-gt_BERTEmbeddings.pickle', 'wb') as handle:\n",
    "    pickle.dump(X_dstil_numpy, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "143f4f5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 10/10 [00:00<00:00, 35.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shapes X (757096, 768) y (757096,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "with open('../../pickles/products/nela-gt-y.pickle', 'rb') as handle:\n",
    "    y=pickle.load(handle)\n",
    "\n",
    "# load\n",
    "with open('../../pickles/bertcls_embeddings/nela-gt_BERTEmbeddings.pickle', 'rb') as handle:\n",
    "    X_dstil_numpy = pickle.load(handle)\n",
    "    \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "\n",
    "rskf = RepeatedStratifiedKFold(n_splits=2, n_repeats=5, random_state=1410)\n",
    "foldids = []\n",
    "for fold_idx, (train, test) in tqdm(enumerate(rskf.split(X_dstil_numpy, y)), total=rskf.get_n_splits()):\n",
    "    foldids.append((fold_idx,train,test))\n",
    "    \n",
    "print(\"shapes X\",X_dstil_numpy.shape,\"y\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc74e9fd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.8267115398839777\n",
      "Balanced Accuracy 0.7971207305688068\n",
      "F1 0.8244339959346526 [0.87079225 0.73697885]\n",
      "Precision 0.8242570074839703 [0.84923739 0.77713136]\n",
      "Recall 0.8267115398839777 [0.89346979 0.70077167]\n",
      "Log-likelihood 0.3897019096148514\n",
      "\n",
      "Accuracy 0.8275198917970773\n",
      "Balanced Accuracy 0.7978627738341977\n",
      "F1 0.8252196411380559 [0.87143752 0.73802932]\n",
      "Precision 0.8250791442440715 [0.84959955 0.77882124]\n",
      "Recall 0.8275198917970773 [0.89442774 0.70129781]\n",
      "Log-likelihood 0.38967154333319703\n",
      "\n",
      "Accuracy 0.826801356763211\n",
      "Balanced Accuracy 0.7968597865578693\n",
      "F1 0.8244447360276969 [0.87096139 0.73669076]\n",
      "Precision 0.8243251113127108 [0.84876406 0.77822088]\n",
      "Recall 0.826801356763211 [0.89435094 0.69936863]\n",
      "Log-likelihood 0.3902715987716882\n",
      "\n",
      "Accuracy 0.8280006762682671\n",
      "Balanced Accuracy 0.7986910388460167\n",
      "F1 0.8257724253162558 [0.87171202 0.73910709]\n",
      "Precision 0.8255948062962692 [0.85039558 0.77880799]\n",
      "Recall 0.8280006762682671 [0.89412459 0.70325749]\n",
      "Log-likelihood 0.38914869114841866\n",
      "\n",
      "Accuracy 0.8273561080761225\n",
      "Balanced Accuracy 0.7975654774731351\n",
      "F1 0.8250277875723958 [0.87134837 0.73764372]\n",
      "Precision 0.8249028204596062 [0.84930618 0.77886572]\n",
      "Recall 0.8273561080761225 [0.89456516 0.70056579]\n",
      "Log-likelihood 0.38897342924070377\n",
      "\n",
      "Accuracy 0.8271949660280863\n",
      "Balanced Accuracy 0.7977288560557525\n",
      "F1 0.8249402366318712 [0.87113163 0.73779987]\n",
      "Precision 0.8247601592779845 [0.84970043 0.77771018]\n",
      "Recall 0.8271949660280863 [0.89367189 0.70178582]\n",
      "Log-likelihood 0.3905559415965548\n",
      "\n",
      "Accuracy 0.8269889155404334\n",
      "Balanced Accuracy 0.7978327952394528\n",
      "F1 0.8248046653003978 [0.87088386 0.73787597]\n",
      "Precision 0.8245738291465512 [0.8500483  0.77651608]\n",
      "Recall 0.8269889155404334 [0.89276649 0.7028991 ]\n",
      "Log-likelihood 0.389678502343718\n",
      "\n",
      "Accuracy 0.8267115398839777\n",
      "Balanced Accuracy 0.7966226610365492\n",
      "F1 0.8243227818814588 [0.8709336  0.73639118]\n",
      "Precision 0.8242240194918141 [0.84849298 0.77844047]\n",
      "Recall 0.8267115398839777 [0.89459346 0.69865186]\n",
      "Log-likelihood 0.3900129113089033\n",
      "\n",
      "Accuracy 0.8273481830573666\n",
      "Balanced Accuracy 0.7976991606431374\n",
      "F1 0.825051408924042 [0.87130218 0.73779903]\n",
      "Precision 0.8249039895807307 [0.84951369 0.77847764]\n",
      "Recall 0.8273481830573666 [0.89423776 0.70116056]\n",
      "Log-likelihood 0.38919983923406126\n",
      "\n",
      "Accuracy 0.8271685492989\n",
      "Balanced Accuracy 0.797463194664491\n",
      "F1 0.8248610243774346 [0.87117893 0.73748199]\n",
      "Precision 0.8247164052266646 [0.8493268  0.77828874]\n",
      "Recall 0.8271685492989 [0.89418522 0.70074117]\n",
      "Log-likelihood 0.39034560010845276\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import log_loss,accuracy_score, balanced_accuracy_score, f1_score, precision_score, recall_score, roc_auc_score\n",
    "from imblearn.metrics import geometric_mean_score\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def log_los_nonorm(x,y,average=False):\n",
    "    return log_loss(x,y,normalize=True)\n",
    "\n",
    "scores = {\n",
    "    'Accuracy': {'func': accuracy_score},\n",
    "    'Balanced Accuracy': {'func': balanced_accuracy_score},\n",
    "    'F1': {'func': f1_score},\n",
    "    'Precision': {'func': precision_score},\n",
    "    'Recall': {'func': recall_score},\n",
    "    'Log-likelihood': {'func': log_los_nonorm},\n",
    "    #'G-mean': {'func': geometric_mean_score}\n",
    "}\n",
    "\n",
    "for score_name, score_dict in scores.items():\n",
    "    scores[score_name][\"list\"] = []\n",
    "    scores[score_name][\"lab\"] = []\n",
    "\n",
    "\n",
    "for fold,j in enumerate(foldids):\n",
    "    train = foldids[fold][1]\n",
    "    test = foldids[fold][2]\n",
    "    xin, yin = X_dstil_numpy[train], np.array(y[train])\n",
    "    cls = BertHead()\n",
    "    \n",
    "    cls.fit(xin, yin)\n",
    "    y_pred = cls.predict(X_dstil_numpy[test])\n",
    "    y_pred_proba = cls.predict_proba(X_dstil_numpy[test])\n",
    "    \n",
    "    for score_name, score_dict in scores.items():\n",
    "        if score_name == \"Log-likelihood\":\n",
    "            scorval=score_dict['func'](y[test], y_pred_proba)\n",
    "            score_dict['list'].append(scorval)\n",
    "            print(score_name, scorval)\n",
    "        elif score_name in [\"F1\",\"Precision\",\"Recall\"]:\n",
    "            scorvaln = score_dict['func'](y[test], y_pred, average=None)\n",
    "            score_dict['lab'].append(scorvaln)\n",
    "            scorval = score_dict['func'](y[test], y_pred, average=\"weighted\")\n",
    "            score_dict['list'].append(scorval)\n",
    "            print(score_name, scorval, scorvaln)  \n",
    "        else:\n",
    "            scorval=score_dict['func'](y[test], y_pred)\n",
    "            score_dict['list'].append(scorval)\n",
    "            print(score_name, scorval)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b50a84f0-9e39-4c35-8434-bab20e6cff22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Score                | Average      | Kat_1      | Kat_2      |\n",
      "| Accuracy             | 82.7 ± 0.038 | -          | -          |\n",
      "| Balanced Accuracy    | 79.8 ± 0.055 | -          | -          |\n",
      "| F1                   | 82.5 ± 0.041 | 87.1 ± 0.0 | 73.8 ± 0.1 |\n",
      "| Log-likelihood       | 0.39 ± 0.001 | -          | -          |\n",
      "| Precision            | 82.5 ± 0.040 | 84.9 ± 0.1 | 77.8 ± 0.1 |\n",
      "| Recall               | 82.7 ± 0.038 | 89.4 ± 0.1 | 70.1 ± 0.1 |\n"
     ]
    }
   ],
   "source": [
    "numlabels = scores[\"F1\"][\"lab\"][0].shape[0]\n",
    "scores[\"F1\"][\"lab\"][0].shape[0] \n",
    "head = \"| %-20s | %-12s |\" +  numlabels * \" %-10s |\" \n",
    "headv = [\"Score\", \"Average\"]\n",
    "headv.extend([\"Kat_\"+str(i+1) for i in range(numlabels)])\n",
    "row=head % tuple(headv)\n",
    "#print(\"+\"*len(row))\n",
    "print(row)\n",
    "#print(\"+\"*len(row))\n",
    "\n",
    "for score_name, score_dict in sorted(scores.items()) :\n",
    "    if score_name == \"Log-likelihood\":\n",
    "        headv = [score_name, np.mean(score_dict['list'])*1, np.std(score_dict['list'])*1]\n",
    "    else:\n",
    "        headv = [score_name, np.mean(score_dict['list'])*100, np.std(score_dict['list'])*100]\n",
    "    \n",
    "    for i in range(numlabels):\n",
    "        if score_name == \"Log-likelihood\":\n",
    "            head = \"| %-20s | %3.2f ± %3.3f |\" + numlabels * \" %-10s |\" \n",
    "            headv.append(\"-\")\n",
    "        elif score_name in [\"F1\",\"Precision\",\"Recall\"]:\n",
    "            head = \"| %-20s | %4.1f ± %3.3f |\" + numlabels* \" %4.1f ± %3.1f |\"\n",
    "            vals = [v[i] for v in scores[score_name][\"lab\"]]\n",
    "            headv.append(np.mean(vals)*100)\n",
    "            headv.append(np.std(vals)*100)\n",
    "        else:\n",
    "            head = \"| %-20s | %4.1f ± %3.3f |\" + numlabels * \" %-10s |\" \n",
    "            headv.append(\"-\")\n",
    "    print(head % tuple(headv))\n",
    "    \n",
    "#print(\"+\"*len(row))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env.hator",
   "language": "python",
   "name": "env.hator"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
