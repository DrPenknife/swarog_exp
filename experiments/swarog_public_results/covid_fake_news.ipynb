{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4aefad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d503a6af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-08-25 12:41:11--  https://docs.google.com/uc?export=download&confirm=&id=18nemaqdNT-0ZtEWyD57a6tO3LXUcgtMj\n",
      "Resolving docs.google.com (docs.google.com)... 142.250.186.206, 2a00:1450:401b:80e::200e\n",
      "Connecting to docs.google.com (docs.google.com)|142.250.186.206|:443... connected.\n",
      "HTTP request sent, awaiting response... 303 See Other\n",
      "Location: https://doc-00-34-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/qovriuqek2b1t5a9u0d4c8i6pfiqjbm9/1661424000000/05536367513713019519/*/18nemaqdNT-0ZtEWyD57a6tO3LXUcgtMj?e=download&uuid=8af1858f-825c-4f7d-9a17-50ce4fdfb6a1 [following]\n",
      "Warning: wildcards not supported in HTTP.\n",
      "--2022-08-25 12:41:12--  https://doc-00-34-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/qovriuqek2b1t5a9u0d4c8i6pfiqjbm9/1661424000000/05536367513713019519/*/18nemaqdNT-0ZtEWyD57a6tO3LXUcgtMj?e=download&uuid=8af1858f-825c-4f7d-9a17-50ce4fdfb6a1\n",
      "Resolving doc-00-34-docs.googleusercontent.com (doc-00-34-docs.googleusercontent.com)... 142.250.75.1, 2a00:1450:401b:801::2001\n",
      "Connecting to doc-00-34-docs.googleusercontent.com (doc-00-34-docs.googleusercontent.com)|142.250.75.1|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 977685 (955K) [text/csv]\n",
      "Saving to: ‘covid_fake_news.csv’\n",
      "\n",
      "covid_fake_news.csv 100%[===================>] 954,77K  2,80MB/s    in 0,3s    \n",
      "\n",
      "2022-08-25 12:41:12 (2,80 MB/s) - ‘covid_fake_news.csv’ saved [977685/977685]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!id=\"18nemaqdNT-0ZtEWyD57a6tO3LXUcgtMj\"; conf=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id='$id -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p'); wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$conf&id=$id\" -O covid_fake_news.csv && rm -rf /tmp/cookies.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d25e385e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"text\"] = X\n",
    "data[\"label\"] = 1-y\n",
    "data.to_csv(\"raw/covid_fake_news.csv\",sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f796758",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels\n",
      " 1    8511\n",
      "0     461\n",
      "Name: label, dtype: int64\n",
      "shape  \n",
      " (8972, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 10/10 [00:00<00:00, 1512.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shapes X (8972,) y (8972,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "\n",
    "data = pd.read_csv(\"../../raw/covid_fake_news.csv\",sep=\"\\t\")\n",
    "print(\"labels\\n\",data[\"label\"].value_counts())\n",
    "print(\"shape  \\n\",data.shape)\n",
    "\n",
    "bootstrap_size = 0\n",
    "\n",
    "if bootstrap_size != 0:\n",
    "    bootstrap_factor = bootstrap_size / data.shape[0]\n",
    "    bootstrap = np.random.uniform(size=data.shape[0]) < bootstrap_factor\n",
    "    data = data.iloc[bootstrap]\n",
    "\n",
    "X, y = data[\"title\"].values, data[\"label\"].values\n",
    "\n",
    "rskf = RepeatedStratifiedKFold(n_splits=2, n_repeats=5, random_state=1410)\n",
    "foldids = []\n",
    "for fold_idx, (train, test) in tqdm(enumerate(rskf.split(X, y)), total=rskf.get_n_splits()):\n",
    "    foldids.append((fold_idx,train,test))\n",
    "    \n",
    "print(\"shapes X\",X.shape,\"y\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5638e27c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'title', 'label', 'text'], dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e2c31e30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "transformers.logging.set_verbosity_error()\n",
    "from torch.utils.data import DataLoader \n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModel\n",
    "from transformers import TFDistilBertModel, DistilBertTokenizerFast\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from scipy.sparse import csr_matrix\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(\"using device:\", device)\n",
    "\n",
    "if \"disilbert_model\" not in locals():\n",
    "    disilbert_tokenizer =  AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "    disilbert_model = AutoModel.from_pretrained(\"distilbert-base-uncased\")\n",
    "    handle = disilbert_model.to(device)\n",
    "\n",
    "\n",
    "class BERTEmbeddings(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.tokenizer =  disilbert_tokenizer\n",
    "        self.model = disilbert_tokenizer\n",
    "        self.max_length = 256\n",
    "        self.model_name = disilbert_model\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        pass\n",
    "    \n",
    "    def encode(self, txt):\n",
    "        return self.tokenizer(txt, max_length=self.max_length, \n",
    "                              truncation=True, padding=True, return_tensors=\"pt\")\n",
    "\n",
    "    def transform(self, X=None):\n",
    "        dataloader = DataLoader(X, batch_size=4, shuffle=False)\n",
    "        allembeds = []\n",
    "        for batch in tqdm(dataloader):\n",
    "            batchenc = disilbert_tokenizer(batch, max_length=256, truncation=True, padding=True, return_tensors=\"pt\")\n",
    "            input_ids = batchenc['input_ids'].to(device)\n",
    "            attention_mask = batchenc['attention_mask'].to(device)\n",
    "            batchout = disilbert_model(input_ids, attention_mask=attention_mask, output_hidden_states=True)\n",
    "            embeds = [vec[0].cpu().detach().numpy() for vec in batchout[1][-1]]\n",
    "            allembeds.extend(embeds)\n",
    "        return csr_matrix(allembeds)\n",
    "\n",
    "\n",
    "class BertHead(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.head = LogisticRegression(class_weight='auto', max_iter=10000)\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.head.fit(X, y)\n",
    "\n",
    "\n",
    "    def transform(self, X=None):\n",
    "        pass\n",
    "    \n",
    "    def predict(self, X=None):    \n",
    "        return self.head.predict(X)\n",
    "    \n",
    "    def predict_proba(self, X=None):    \n",
    "        return self.head.predict_proba(X)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07fe3749",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 561/561 [00:04<00:00, 134.35it/s]\n"
     ]
    }
   ],
   "source": [
    "bert = BERTEmbeddings()\n",
    "X_dstil_numpy = bert.transform(X).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4925460b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# SAVE\n",
    "with open('covid_fake_news_BERTEmbeddings.pickle', 'wb') as handle:\n",
    "    pickle.dump(X_dstil_numpy, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ea9657f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# LOAD\n",
    "with open('../../pickles/bertcls_embeddings/covid_fake_news_BERTEmbeddings.pickle', 'rb') as handle:\n",
    "    X_dstil_numpy=pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b737cfcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.9719126170307624\n",
      "Balanced Accuracy 0.8083442301405688\n",
      "F1 0.9704276929382857 [0.69565217 0.98527693]\n",
      "Precision 0.9698884467882206 [0.7826087 0.9800093]\n",
      "Recall 0.9719126170307624 [0.62608696 0.9906015 ]\n",
      "Log-likelihood 0.08265961043378738\n",
      "\n",
      "Accuracy 0.9736959429335711\n",
      "Balanced Accuracy 0.7773406382102034\n",
      "F1 0.9708193476806144 [0.68617021 0.98627268]\n",
      "Precision 0.972031002536266 [0.88965517 0.97650311]\n",
      "Recall 0.9736959429335711 [0.55844156 0.99623972]\n",
      "Log-likelihood 0.07848217226762058\n",
      "\n",
      "Accuracy 0.9719126170307624\n",
      "Balanced Accuracy 0.8104006619810395\n",
      "F1 0.9704994475326 [0.69711538 0.98527349]\n",
      "Precision 0.9699444589190097 [0.77956989 0.98023256]\n",
      "Recall 0.9719126170307624 [0.63043478 0.99036654]\n",
      "Log-likelihood 0.07957285118617873\n",
      "\n",
      "Accuracy 0.9728042799821668\n",
      "Balanced Accuracy 0.7911995564169477\n",
      "F1 0.9705652349131253 [0.69035533 0.98577757]\n",
      "Precision 0.9706265111365114 [0.83435583 0.97802452]\n",
      "Recall 0.9728042799821668 [0.58874459 0.99365452]\n",
      "Log-likelihood 0.07854661879993707\n",
      "\n",
      "Accuracy 0.9716897012929113\n",
      "Balanced Accuracy 0.7732674076495587\n",
      "F1 0.9688848101585297 [0.66666667 0.98521709]\n",
      "Precision 0.9693091297143949 [0.8410596  0.97623991]\n",
      "Recall 0.9716897012929113 [0.55217391 0.9943609 ]\n",
      "Log-likelihood 0.07989264717066502\n",
      "\n",
      "Accuracy 0.9739188586714222\n",
      "Balanced Accuracy 0.8081630472934821\n",
      "F1 0.9721702837197544 [0.71111111 0.98634294]\n",
      "Precision 0.9719844984786653 [0.82758621 0.97982375]\n",
      "Recall 0.9739188586714222 [0.62337662 0.99294947]\n",
      "Log-likelihood 0.08208790048734811\n",
      "\n",
      "Accuracy 0.9741417744092733\n",
      "Balanced Accuracy 0.809519042170644\n",
      "F1 0.9724341241656095 [0.71287129 0.98646125]\n",
      "Precision 0.9722384553506666 [0.82758621 0.98005566]\n",
      "Recall 0.9741417744092733 [0.62608696 0.99295113]\n",
      "Log-likelihood 0.0762830253210633\n",
      "\n",
      "Accuracy 0.9707980383415069\n",
      "Balanced Accuracy 0.7942359638011811\n",
      "F1 0.9689186927709891 [0.67813268 0.9847052 ]\n",
      "Precision 0.9684154647663833 [0.78409091 0.97842227]\n",
      "Recall 0.9707980383415069 [0.5974026  0.99106933]\n",
      "Log-likelihood 0.08234221263253422\n",
      "\n",
      "Accuracy 0.9716897012929113\n",
      "Balanced Accuracy 0.7753238394900295\n",
      "F1 0.9689707882558556 [0.66840731 0.98521365]\n",
      "Precision 0.969289099782189 [0.83660131 0.97645973]\n",
      "Recall 0.9716897012929113 [0.55652174 0.99412594]\n",
      "Log-likelihood 0.08217066212789267\n",
      "\n",
      "Accuracy 0.9728042799821668\n",
      "Balanced Accuracy 0.7952935431196301\n",
      "F1 0.9707191896659643 [0.69346734 0.98577094]\n",
      "Precision 0.9706340446559458 [0.82634731 0.97846724]\n",
      "Recall 0.9728042799821668 [0.5974026  0.99318449]\n",
      "Log-likelihood 0.07823606445021188\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import log_loss,accuracy_score, balanced_accuracy_score, f1_score, precision_score, recall_score, roc_auc_score\n",
    "from imblearn.metrics import geometric_mean_score\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def log_los_nonorm(x,y,average=False):\n",
    "    return log_loss(x,y,normalize=True)\n",
    "\n",
    "scores = {\n",
    "    'Accuracy': {'func': accuracy_score},\n",
    "    'Balanced Accuracy': {'func': balanced_accuracy_score},\n",
    "    'F1': {'func': f1_score},\n",
    "    'Precision': {'func': precision_score},\n",
    "    'Recall': {'func': recall_score},\n",
    "    'Log-likelihood': {'func': log_los_nonorm},\n",
    "    #'G-mean': {'func': geometric_mean_score}\n",
    "}\n",
    "\n",
    "for score_name, score_dict in scores.items():\n",
    "    scores[score_name][\"list\"] = []\n",
    "    scores[score_name][\"lab\"] = []\n",
    "\n",
    "\n",
    "for fold,j in enumerate(foldids):\n",
    "    train = foldids[fold][1]\n",
    "    test = foldids[fold][2]\n",
    "    xin, yin = X_dstil_numpy[train], np.array(y[train])\n",
    "    cls = BertHead()\n",
    "    \n",
    "    cls.fit(xin, yin)\n",
    "    y_pred = cls.predict(X_dstil_numpy[test])\n",
    "    y_pred_proba = cls.predict_proba(X_dstil_numpy[test])\n",
    "    \n",
    "    for score_name, score_dict in scores.items():\n",
    "        if score_name == \"Log-likelihood\":\n",
    "            scorval=score_dict['func'](y[test], y_pred_proba)\n",
    "            score_dict['list'].append(scorval)\n",
    "            print(score_name, scorval)\n",
    "        elif score_name in [\"F1\",\"Precision\",\"Recall\"]:\n",
    "            scorvaln = score_dict['func'](y[test], y_pred, average=None)\n",
    "            score_dict['lab'].append(scorvaln)\n",
    "            scorval = score_dict['func'](y[test], y_pred, average=\"weighted\")\n",
    "            score_dict['list'].append(scorval)\n",
    "            print(score_name, scorval, scorvaln)  \n",
    "        else:\n",
    "            scorval=score_dict['func'](y[test], y_pred)\n",
    "            score_dict['list'].append(scorval)\n",
    "            print(score_name, scorval)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4236666d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Score                | Average      | Kat_1      | Kat_2      |\n",
      "| Accuracy             | 97.3 ± 0.106 | -          | -          |\n",
      "| Balanced Accuracy    | 79.4 ± 1.407 | -          | -          |\n",
      "| F1                   | 97.0 ± 0.119 | 69.0 ± 1.5 | 98.6 ± 0.1 |\n",
      "| Log-likelihood       | 0.08 ± 0.002 | -          | -          |\n",
      "| Precision            | 97.0 ± 0.124 | 82.3 ± 3.2 | 97.8 ± 0.2 |\n",
      "| Recall               | 97.3 ± 0.106 | 59.6 ± 2.9 | 99.3 ± 0.2 |\n"
     ]
    }
   ],
   "source": [
    "numlabels = scores[\"F1\"][\"lab\"][0].shape[0]\n",
    "scores[\"F1\"][\"lab\"][0].shape[0] \n",
    "head = \"| %-20s | %-12s |\" +  numlabels * \" %-10s |\" \n",
    "headv = [\"Score\", \"Average\"]\n",
    "headv.extend([\"Kat_\"+str(i+1) for i in range(numlabels)])\n",
    "row=head % tuple(headv)\n",
    "#print(\"+\"*len(row))\n",
    "print(row)\n",
    "#print(\"+\"*len(row))\n",
    "\n",
    "for score_name, score_dict in sorted(scores.items()) :\n",
    "    if score_name == \"Log-likelihood\":\n",
    "        headv = [score_name, np.mean(score_dict['list'])*1, np.std(score_dict['list'])*1]\n",
    "    else:\n",
    "        headv = [score_name, np.mean(score_dict['list'])*100, np.std(score_dict['list'])*100]\n",
    "    \n",
    "    for i in range(numlabels):\n",
    "        if score_name == \"Log-likelihood\":\n",
    "            head = \"| %-20s | %3.2f ± %3.3f |\" + numlabels * \" %-10s |\" \n",
    "            headv.append(\"-\")\n",
    "        elif score_name in [\"F1\",\"Precision\",\"Recall\"]:\n",
    "            head = \"| %-20s | %4.1f ± %3.3f |\" + numlabels* \" %4.1f ± %3.1f |\"\n",
    "            vals = [v[i] for v in scores[score_name][\"lab\"]]\n",
    "            headv.append(np.mean(vals)*100)\n",
    "            headv.append(np.std(vals)*100)\n",
    "        else:\n",
    "            head = \"| %-20s | %4.1f ± %3.3f |\" + numlabels * \" %-10s |\" \n",
    "            headv.append(\"-\")\n",
    "    print(head % tuple(headv))\n",
    "    \n",
    "#print(\"+\"*len(row))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env.hator",
   "language": "python",
   "name": "env.hator"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
