{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4aefad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d503a6af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-08-25 12:41:11--  https://docs.google.com/uc?export=download&confirm=&id=18nemaqdNT-0ZtEWyD57a6tO3LXUcgtMj\n",
      "Resolving docs.google.com (docs.google.com)... 142.250.186.206, 2a00:1450:401b:80e::200e\n",
      "Connecting to docs.google.com (docs.google.com)|142.250.186.206|:443... connected.\n",
      "HTTP request sent, awaiting response... 303 See Other\n",
      "Location: https://doc-00-34-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/qovriuqek2b1t5a9u0d4c8i6pfiqjbm9/1661424000000/05536367513713019519/*/18nemaqdNT-0ZtEWyD57a6tO3LXUcgtMj?e=download&uuid=8af1858f-825c-4f7d-9a17-50ce4fdfb6a1 [following]\n",
      "Warning: wildcards not supported in HTTP.\n",
      "--2022-08-25 12:41:12--  https://doc-00-34-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/qovriuqek2b1t5a9u0d4c8i6pfiqjbm9/1661424000000/05536367513713019519/*/18nemaqdNT-0ZtEWyD57a6tO3LXUcgtMj?e=download&uuid=8af1858f-825c-4f7d-9a17-50ce4fdfb6a1\n",
      "Resolving doc-00-34-docs.googleusercontent.com (doc-00-34-docs.googleusercontent.com)... 142.250.75.1, 2a00:1450:401b:801::2001\n",
      "Connecting to doc-00-34-docs.googleusercontent.com (doc-00-34-docs.googleusercontent.com)|142.250.75.1|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 977685 (955K) [text/csv]\n",
      "Saving to: ‘covid_fake_news.csv’\n",
      "\n",
      "covid_fake_news.csv 100%[===================>] 954,77K  2,80MB/s    in 0,3s    \n",
      "\n",
      "2022-08-25 12:41:12 (2,80 MB/s) - ‘covid_fake_news.csv’ saved [977685/977685]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!id=\"18nemaqdNT-0ZtEWyD57a6tO3LXUcgtMj\"; conf=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id='$id -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p'); wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$conf&id=$id\" -O covid_fake_news.csv && rm -rf /tmp/cookies.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d25e385e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"text\"] = X\n",
    "data[\"label\"] = 1-y\n",
    "data.to_csv(\"raw/covid_fake_news.csv\",sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f796758",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels\n",
      " 1    8511\n",
      "0     461\n",
      "Name: label, dtype: int64\n",
      "shape  \n",
      " (8972, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 10/10 [00:00<00:00, 1512.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shapes X (8972,) y (8972,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "\n",
    "data = pd.read_csv(\"../../raw/covid_fake_news.csv\",sep=\"\\t\")\n",
    "print(\"labels\\n\",data[\"label\"].value_counts())\n",
    "print(\"shape  \\n\",data.shape)\n",
    "\n",
    "bootstrap_size = 0\n",
    "\n",
    "if bootstrap_size != 0:\n",
    "    bootstrap_factor = bootstrap_size / data.shape[0]\n",
    "    bootstrap = np.random.uniform(size=data.shape[0]) < bootstrap_factor\n",
    "    data = data.iloc[bootstrap]\n",
    "\n",
    "X, y = data[\"title\"].values, data[\"label\"].values\n",
    "\n",
    "rskf = RepeatedStratifiedKFold(n_splits=2, n_repeats=5, random_state=1410)\n",
    "foldids = []\n",
    "for fold_idx, (train, test) in tqdm(enumerate(rskf.split(X, y)), total=rskf.get_n_splits()):\n",
    "    foldids.append((fold_idx,train,test))\n",
    "    \n",
    "print(\"shapes X\",X.shape,\"y\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5638e27c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'title', 'label', 'text'], dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2c31e30",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unable to compare versions for numpy>=1.17: need=1.17 found=None. This is unusual. Consider reinstalling numpy.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m\n\u001b[1;32m      2\u001b[0m transformers\u001b[38;5;241m.\u001b[39mlogging\u001b[38;5;241m.\u001b[39mset_verbosity_error()\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataLoader \n",
      "File \u001b[0;32m/media/rkozik/02FF-A831/repos/swarog_exp/env.hator/lib/python3.9/site-packages/transformers/__init__.py:30\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TYPE_CHECKING\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# Check the dependencies satisfy the minimal versions required.\u001b[39;00m\n\u001b[0;32m---> 30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dependency_versions_check\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     32\u001b[0m     OptionalDependencyNotAvailable,\n\u001b[1;32m     33\u001b[0m     _LazyModule,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     44\u001b[0m     logging,\n\u001b[1;32m     45\u001b[0m )\n\u001b[1;32m     48\u001b[0m logger \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mget_logger(\u001b[38;5;18m__name__\u001b[39m)  \u001b[38;5;66;03m# pylint: disable=invalid-name\u001b[39;00m\n",
      "File \u001b[0;32m/media/rkozik/02FF-A831/repos/swarog_exp/env.hator/lib/python3.9/site-packages/transformers/dependency_versions_check.py:41\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_tokenizers_available():\n\u001b[1;32m     39\u001b[0m             \u001b[38;5;28;01mcontinue\u001b[39;00m  \u001b[38;5;66;03m# not required, check version only if installed\u001b[39;00m\n\u001b[0;32m---> 41\u001b[0m     \u001b[43mrequire_version_core\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdeps\u001b[49m\u001b[43m[\u001b[49m\u001b[43mpkg\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcan\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt find \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpkg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdeps\u001b[38;5;241m.\u001b[39mkeys()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, check dependency_versions_table.py\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/media/rkozik/02FF-A831/repos/swarog_exp/env.hator/lib/python3.9/site-packages/transformers/utils/versions.py:123\u001b[0m, in \u001b[0;36mrequire_version_core\u001b[0;34m(requirement)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;124;03m\"\"\"require_version wrapper which emits a core-specific hint on failure\"\"\"\u001b[39;00m\n\u001b[1;32m    122\u001b[0m hint \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTry: pip install transformers -U or pip install -e \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.[dev]\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m if you\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mre working with git main\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 123\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequire_version\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequirement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhint\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/media/rkozik/02FF-A831/repos/swarog_exp/env.hator/lib/python3.9/site-packages/transformers/utils/versions.py:117\u001b[0m, in \u001b[0;36mrequire_version\u001b[0;34m(requirement, hint)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m want_ver \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m op, want_ver \u001b[38;5;129;01min\u001b[39;00m wanted\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m--> 117\u001b[0m         \u001b[43m_compare_versions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgot_ver\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwant_ver\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequirement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpkg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhint\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/media/rkozik/02FF-A831/repos/swarog_exp/env.hator/lib/python3.9/site-packages/transformers/utils/versions.py:45\u001b[0m, in \u001b[0;36m_compare_versions\u001b[0;34m(op, got_ver, want_ver, requirement, pkg, hint)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_compare_versions\u001b[39m(op, got_ver, want_ver, requirement, pkg, hint):\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m got_ver \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m want_ver \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 45\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     46\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable to compare versions for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrequirement\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: need=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mwant_ver\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m found=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgot_ver\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. This is unusual. Consider\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     47\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m reinstalling \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpkg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     48\u001b[0m         )\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ops[op](version\u001b[38;5;241m.\u001b[39mparse(got_ver), version\u001b[38;5;241m.\u001b[39mparse(want_ver)):\n\u001b[1;32m     50\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[1;32m     51\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrequirement\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is required for a normal functioning of this module, but found \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpkg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m==\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgot_ver\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhint\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     52\u001b[0m         )\n",
      "\u001b[0;31mValueError\u001b[0m: Unable to compare versions for numpy>=1.17: need=1.17 found=None. This is unusual. Consider reinstalling numpy."
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "transformers.logging.set_verbosity_error()\n",
    "from torch.utils.data import DataLoader \n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModel\n",
    "from transformers import TFDistilBertModel, DistilBertTokenizerFast\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from scipy.sparse import csr_matrix\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(\"using device:\", device)\n",
    "\n",
    "if \"disilbert_model\" not in locals():\n",
    "    disilbert_tokenizer =  AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "    disilbert_model = AutoModel.from_pretrained(\"distilbert-base-uncased\")\n",
    "    handle = disilbert_model.to(device)\n",
    "\n",
    "\n",
    "class BERTEmbeddings(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.tokenizer =  disilbert_tokenizer\n",
    "        self.model = disilbert_tokenizer\n",
    "        self.max_length = 256\n",
    "        self.model_name = disilbert_model\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        pass\n",
    "    \n",
    "    def encode(self, txt):\n",
    "        return self.tokenizer(txt, max_length=self.max_length, \n",
    "                              truncation=True, padding=True, return_tensors=\"pt\")\n",
    "\n",
    "    def transform(self, X=None):\n",
    "        dataloader = DataLoader(X, batch_size=4, shuffle=False)\n",
    "        allembeds = []\n",
    "        for batch in tqdm(dataloader):\n",
    "            batchenc = disilbert_tokenizer(batch, max_length=256, truncation=True, padding=True, return_tensors=\"pt\")\n",
    "            input_ids = batchenc['input_ids'].to(device)\n",
    "            attention_mask = batchenc['attention_mask'].to(device)\n",
    "            batchout = disilbert_model(input_ids, attention_mask=attention_mask, output_hidden_states=True)\n",
    "            embeds = [vec[0].cpu().detach().numpy() for vec in batchout[1][-1]]\n",
    "            allembeds.extend(embeds)\n",
    "        return csr_matrix(allembeds)\n",
    "\n",
    "\n",
    "class BertHead(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.head = LogisticRegression(class_weight='auto', max_iter=10000)\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        self.head.fit(X, y)\n",
    "\n",
    "\n",
    "    def transform(self, X=None):\n",
    "        pass\n",
    "    \n",
    "    def predict(self, X=None):    \n",
    "        return self.head.predict(X)\n",
    "    \n",
    "    def predict_proba(self, X=None):    \n",
    "        return self.head.predict_proba(X)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07fe3749",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 561/561 [00:04<00:00, 134.35it/s]\n"
     ]
    }
   ],
   "source": [
    "bert = BERTEmbeddings()\n",
    "X_dstil_numpy = bert.transform(X).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4925460b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# SAVE\n",
    "with open('covid_fake_news_BERTEmbeddings.pickle', 'wb') as handle:\n",
    "    pickle.dump(X_dstil_numpy, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ea9657f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# LOAD\n",
    "with open('../../pickles/bertcls_embeddings/covid_fake_news_BERTEmbeddings.pickle', 'rb') as handle:\n",
    "    X_dstil_numpy=pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b737cfcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.9719126170307624\n",
      "Balanced Accuracy 0.8083442301405688\n",
      "F1 0.9704276929382857 [0.69565217 0.98527693]\n",
      "Precision 0.9698884467882206 [0.7826087 0.9800093]\n",
      "Recall 0.9719126170307624 [0.62608696 0.9906015 ]\n",
      "Log-likelihood 0.08265961043378738\n",
      "\n",
      "Accuracy 0.9736959429335711\n",
      "Balanced Accuracy 0.7773406382102034\n",
      "F1 0.9708193476806144 [0.68617021 0.98627268]\n",
      "Precision 0.972031002536266 [0.88965517 0.97650311]\n",
      "Recall 0.9736959429335711 [0.55844156 0.99623972]\n",
      "Log-likelihood 0.07848217226762058\n",
      "\n",
      "Accuracy 0.9719126170307624\n",
      "Balanced Accuracy 0.8104006619810395\n",
      "F1 0.9704994475326 [0.69711538 0.98527349]\n",
      "Precision 0.9699444589190097 [0.77956989 0.98023256]\n",
      "Recall 0.9719126170307624 [0.63043478 0.99036654]\n",
      "Log-likelihood 0.07957285118617873\n",
      "\n",
      "Accuracy 0.9728042799821668\n",
      "Balanced Accuracy 0.7911995564169477\n",
      "F1 0.9705652349131253 [0.69035533 0.98577757]\n",
      "Precision 0.9706265111365114 [0.83435583 0.97802452]\n",
      "Recall 0.9728042799821668 [0.58874459 0.99365452]\n",
      "Log-likelihood 0.07854661879993707\n",
      "\n",
      "Accuracy 0.9716897012929113\n",
      "Balanced Accuracy 0.7732674076495587\n",
      "F1 0.9688848101585297 [0.66666667 0.98521709]\n",
      "Precision 0.9693091297143949 [0.8410596  0.97623991]\n",
      "Recall 0.9716897012929113 [0.55217391 0.9943609 ]\n",
      "Log-likelihood 0.07989264717066502\n",
      "\n",
      "Accuracy 0.9739188586714222\n",
      "Balanced Accuracy 0.8081630472934821\n",
      "F1 0.9721702837197544 [0.71111111 0.98634294]\n",
      "Precision 0.9719844984786653 [0.82758621 0.97982375]\n",
      "Recall 0.9739188586714222 [0.62337662 0.99294947]\n",
      "Log-likelihood 0.08208790048734811\n",
      "\n",
      "Accuracy 0.9741417744092733\n",
      "Balanced Accuracy 0.809519042170644\n",
      "F1 0.9724341241656095 [0.71287129 0.98646125]\n",
      "Precision 0.9722384553506666 [0.82758621 0.98005566]\n",
      "Recall 0.9741417744092733 [0.62608696 0.99295113]\n",
      "Log-likelihood 0.0762830253210633\n",
      "\n",
      "Accuracy 0.9707980383415069\n",
      "Balanced Accuracy 0.7942359638011811\n",
      "F1 0.9689186927709891 [0.67813268 0.9847052 ]\n",
      "Precision 0.9684154647663833 [0.78409091 0.97842227]\n",
      "Recall 0.9707980383415069 [0.5974026  0.99106933]\n",
      "Log-likelihood 0.08234221263253422\n",
      "\n",
      "Accuracy 0.9716897012929113\n",
      "Balanced Accuracy 0.7753238394900295\n",
      "F1 0.9689707882558556 [0.66840731 0.98521365]\n",
      "Precision 0.969289099782189 [0.83660131 0.97645973]\n",
      "Recall 0.9716897012929113 [0.55652174 0.99412594]\n",
      "Log-likelihood 0.08217066212789267\n",
      "\n",
      "Accuracy 0.9728042799821668\n",
      "Balanced Accuracy 0.7952935431196301\n",
      "F1 0.9707191896659643 [0.69346734 0.98577094]\n",
      "Precision 0.9706340446559458 [0.82634731 0.97846724]\n",
      "Recall 0.9728042799821668 [0.5974026  0.99318449]\n",
      "Log-likelihood 0.07823606445021188\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import log_loss,accuracy_score, balanced_accuracy_score, f1_score, precision_score, recall_score, roc_auc_score\n",
    "from imblearn.metrics import geometric_mean_score\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def log_los_nonorm(x,y,average=False):\n",
    "    return log_loss(x,y,normalize=True)\n",
    "\n",
    "scores = {\n",
    "    'Accuracy': {'func': accuracy_score},\n",
    "    'Balanced Accuracy': {'func': balanced_accuracy_score},\n",
    "    'F1': {'func': f1_score},\n",
    "    'Precision': {'func': precision_score},\n",
    "    'Recall': {'func': recall_score},\n",
    "    'Log-likelihood': {'func': log_los_nonorm},\n",
    "    #'G-mean': {'func': geometric_mean_score}\n",
    "}\n",
    "\n",
    "for score_name, score_dict in scores.items():\n",
    "    scores[score_name][\"list\"] = []\n",
    "    scores[score_name][\"lab\"] = []\n",
    "\n",
    "\n",
    "for fold,j in enumerate(foldids):\n",
    "    train = foldids[fold][1]\n",
    "    test = foldids[fold][2]\n",
    "    xin, yin = X_dstil_numpy[train], np.array(y[train])\n",
    "    cls = BertHead()\n",
    "    \n",
    "    cls.fit(xin, yin)\n",
    "    y_pred = cls.predict(X_dstil_numpy[test])\n",
    "    y_pred_proba = cls.predict_proba(X_dstil_numpy[test])\n",
    "    \n",
    "    for score_name, score_dict in scores.items():\n",
    "        if score_name == \"Log-likelihood\":\n",
    "            scorval=score_dict['func'](y[test], y_pred_proba)\n",
    "            score_dict['list'].append(scorval)\n",
    "            print(score_name, scorval)\n",
    "        elif score_name in [\"F1\",\"Precision\",\"Recall\"]:\n",
    "            scorvaln = score_dict['func'](y[test], y_pred, average=None)\n",
    "            score_dict['lab'].append(scorvaln)\n",
    "            scorval = score_dict['func'](y[test], y_pred, average=\"weighted\")\n",
    "            score_dict['list'].append(scorval)\n",
    "            print(score_name, scorval, scorvaln)  \n",
    "        else:\n",
    "            scorval=score_dict['func'](y[test], y_pred)\n",
    "            score_dict['list'].append(scorval)\n",
    "            print(score_name, scorval)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4236666d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Score                | Average      | Kat_1      | Kat_2      |\n",
      "| Accuracy             | 97.3 ± 0.106 | -          | -          |\n",
      "| Balanced Accuracy    | 79.4 ± 1.407 | -          | -          |\n",
      "| F1                   | 97.0 ± 0.119 | 69.0 ± 1.5 | 98.6 ± 0.1 |\n",
      "| Log-likelihood       | 0.08 ± 0.002 | -          | -          |\n",
      "| Precision            | 97.0 ± 0.124 | 82.3 ± 3.2 | 97.8 ± 0.2 |\n",
      "| Recall               | 97.3 ± 0.106 | 59.6 ± 2.9 | 99.3 ± 0.2 |\n"
     ]
    }
   ],
   "source": [
    "numlabels = scores[\"F1\"][\"lab\"][0].shape[0]\n",
    "scores[\"F1\"][\"lab\"][0].shape[0] \n",
    "head = \"| %-20s | %-12s |\" +  numlabels * \" %-10s |\" \n",
    "headv = [\"Score\", \"Average\"]\n",
    "headv.extend([\"Kat_\"+str(i+1) for i in range(numlabels)])\n",
    "row=head % tuple(headv)\n",
    "#print(\"+\"*len(row))\n",
    "print(row)\n",
    "#print(\"+\"*len(row))\n",
    "\n",
    "for score_name, score_dict in sorted(scores.items()) :\n",
    "    if score_name == \"Log-likelihood\":\n",
    "        headv = [score_name, np.mean(score_dict['list'])*1, np.std(score_dict['list'])*1]\n",
    "    else:\n",
    "        headv = [score_name, np.mean(score_dict['list'])*100, np.std(score_dict['list'])*100]\n",
    "    \n",
    "    for i in range(numlabels):\n",
    "        if score_name == \"Log-likelihood\":\n",
    "            head = \"| %-20s | %3.2f ± %3.3f |\" + numlabels * \" %-10s |\" \n",
    "            headv.append(\"-\")\n",
    "        elif score_name in [\"F1\",\"Precision\",\"Recall\"]:\n",
    "            head = \"| %-20s | %4.1f ± %3.3f |\" + numlabels* \" %4.1f ± %3.1f |\"\n",
    "            vals = [v[i] for v in scores[score_name][\"lab\"]]\n",
    "            headv.append(np.mean(vals)*100)\n",
    "            headv.append(np.std(vals)*100)\n",
    "        else:\n",
    "            head = \"| %-20s | %4.1f ± %3.3f |\" + numlabels * \" %-10s |\" \n",
    "            headv.append(\"-\")\n",
    "    print(head % tuple(headv))\n",
    "    \n",
    "#print(\"+\"*len(row))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env.hator",
   "language": "python",
   "name": "env.hator"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
