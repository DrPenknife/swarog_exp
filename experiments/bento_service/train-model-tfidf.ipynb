{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3fe62a1",
   "metadata": {},
   "source": [
    "# Un-pickle bert `CLS` tokens and sync db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f7877d7d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 8972/8972 [00:00<00:00, 1286188.24it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 7332/7332 [00:00<00:00, 817280.67it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 10075/10075 [00:00<00:00, 1454951.55it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 51270/51270 [00:00<00:00, 2032263.84it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 44898/44898 [00:00<00:00, 1608863.48it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 63930/63930 [00:00<00:00, 1566166.82it/s]\n"
     ]
    }
   ],
   "source": [
    "import pickle5 as pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "import sqlite3\n",
    "conn = sqlite3.connect('../swarog.sqlite')\n",
    "c = conn.cursor()\n",
    "\n",
    "c.execute('''DROP TABLE if exists bertcls''')\n",
    "c.execute('''CREATE TABLE if not exists bertcls\n",
    "             (dataset TEXT, gid INT, did INT)''')\n",
    "\n",
    "conn.commit()\n",
    "\n",
    "\n",
    "DATA = {\n",
    "    \"X\" : [],\n",
    "    \"category\" : [],\n",
    "    \"y\" : []\n",
    "}\n",
    "\n",
    "X=DATA[\"X\"]\n",
    "category=DATA[\"category\"]\n",
    "y=DATA[\"y\"]\n",
    "\n",
    "_global_index = 1\n",
    "with open('../covid_fake_news_BERTEmbeddings.pickle', 'rb') as handle:\n",
    "    dst = pickle.load(handle)\n",
    "    X.extend(dst)\n",
    "    category.extend(np.repeat(0,len(dst)))\n",
    "    data = pd.read_csv(\"../raw/covid_fake_news.csv\",sep=\"\\t\")\n",
    "    y.extend(data[\"label\"].values)\n",
    "    values_to_insert = [('covid_fake_news',_global_index + index,index+1) for index, row in tqdm(enumerate(dst),total=len(dst))]\n",
    "    _global_index+=len(dst)\n",
    "    c.executemany(\"\"\"INSERT INTO bertcls(dataset, gid, did) VALUES (?,?,?)\"\"\", values_to_insert)\n",
    "    conn.commit()\n",
    "        \n",
    "with open('../mmcovid_en_BERTEmbeddings.pickle', 'rb') as handle:\n",
    "    dst = pickle.load(handle)\n",
    "    X.extend(dst)\n",
    "    category.extend(np.repeat(1,len(dst)))\n",
    "    data = pd.read_csv(\"../raw/mmcovid_en.csv\",sep=\",\")\n",
    "    y.extend(data[\"label\"].values)\n",
    "    values_to_insert = [('mmcovid_en',_global_index + index,index+1) for index, row in tqdm(enumerate(dst),total=len(dst))]\n",
    "    _global_index+=len(dst)\n",
    "    c.executemany(\"\"\"INSERT INTO bertcls(dataset, gid, did) VALUES (?,?,?)\"\"\", values_to_insert)\n",
    "    conn.commit()\n",
    "\n",
    "with open('../pubhealth_BERTEmbeddings.pickle', 'rb') as handle:\n",
    "    dst = pickle.load(handle)\n",
    "    X.extend(dst)\n",
    "    category.extend(np.repeat(2,len(dst)))\n",
    "    data = pd.read_csv(\"../raw/pubhealth.csv\",sep=\",\")\n",
    "    y.extend(data[\"label\"].values)\n",
    "    values_to_insert = [('pubhealth',_global_index + index,index+1) for index, row in tqdm(enumerate(dst),total=len(dst))]\n",
    "    _global_index+=len(dst)\n",
    "    c.executemany(\"\"\"INSERT INTO bertcls(dataset, gid, did) VALUES (?,?,?)\"\"\", values_to_insert)\n",
    "    conn.commit()\n",
    "    \n",
    "with open('../qprop_BERTEmbeddings.pickle', 'rb') as handle:\n",
    "    dst = pickle.load(handle)\n",
    "    X.extend(dst)\n",
    "    category.extend(np.repeat(3,len(dst)))\n",
    "    data = pd.read_csv(\"../raw/qprop.csv\",sep=\"\\t\")\n",
    "    y.extend(data[\"label\"].values)\n",
    "    values_to_insert = [('qprop',_global_index + index,index+1) for index, row in tqdm(enumerate(dst),total=len(dst))]\n",
    "    _global_index+=len(dst)\n",
    "    c.executemany(\"\"\"INSERT INTO bertcls(dataset, gid, did) VALUES (?,?,?)\"\"\", values_to_insert)\n",
    "    conn.commit()\n",
    "    \n",
    "with open('../isot_BERTEmbeddings.pickle', 'rb') as handle:\n",
    "    dst = pickle.load(handle)\n",
    "    X.extend(dst)\n",
    "    category.extend(np.repeat(4,len(dst)))\n",
    "    data = pd.read_csv(\"../raw/isot.csv\",sep=\",\")\n",
    "    y.extend(data[\"label\"].values)\n",
    "    values_to_insert = [('isot',_global_index + index,index+1) for index, row in tqdm(enumerate(dst),total=len(dst))]\n",
    "    _global_index+=len(dst)\n",
    "    c.executemany(\"\"\"INSERT INTO bertcls(dataset, gid, did) VALUES (?,?,?)\"\"\", values_to_insert)\n",
    "    conn.commit()\n",
    "    \n",
    "with open('../grafn_BERTEmbeddings.pickle', 'rb') as handle:\n",
    "    dst = pickle.load(handle)\n",
    "    X.extend(dst)\n",
    "    category.extend(np.repeat(5,len(dst)))\n",
    "    data = pd.read_csv(\"../raw/grafn.csv\",sep=\",\")\n",
    "    y.extend(data[\"label\"].values)\n",
    "    values_to_insert = [('grafn',_global_index + index,index+1) for index, row in tqdm(enumerate(dst),total=len(dst))]\n",
    "    _global_index+=len(dst)\n",
    "    c.executemany(\"\"\"INSERT INTO bertcls(dataset, gid, did) VALUES (?,?,?)\"\"\", values_to_insert)\n",
    "    conn.commit()\n",
    "    \n",
    "DATA[\"X\"]=np.array(X)\n",
    "DATA[\"category\"]=np.array(category)\n",
    "DATA[\"y\"]=np.array(y)\n",
    "DATA[\"folds\"] = []\n",
    "\n",
    "conn.close()\n",
    "\n",
    "with open(f'swarog_bertcls.pickle', 'wb') as handle:\n",
    "        pickle.dump(DATA[\"X\"], handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad215bc",
   "metadata": {},
   "source": [
    "# Creates Annoy index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5955914",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pickle5 as pickle\n",
    "import sqlite3\n",
    "from tqdm import tqdm\n",
    "from annoy import AnnoyIndex\n",
    "\n",
    "tfidf = AnnoyIndex(7000, 'angular')\n",
    "\n",
    "with open(f'swarog_tfidf.pickle', 'rb') as handle:\n",
    "        tfidfvec = pickle.load(handle)\n",
    "        for index,row in tqdm(enumerate(tfidfvec),total=tfidfvec.shape[0]):\n",
    "            tfidf.add_item(index+1, row.toarray()[0])\n",
    "    \n",
    "print(\"building model...\")\n",
    "tfidf.build(100)\n",
    "print(\"saving model...\")\n",
    "tfidf.save('swarog_tfidf.ann')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1dc5e242",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████| 186477/186477 [00:10<00:00, 17129.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building model...\n",
      "saving model...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pickle5 as pickle\n",
    "from tqdm import tqdm\n",
    "from annoy import AnnoyIndex\n",
    "\n",
    "bert = AnnoyIndex(768, 'angular')\n",
    "\n",
    "with open(f'swarog_bertcls.pickle', 'rb') as handle:\n",
    "        bertclsvec = pickle.load(handle)\n",
    "        for index,row in tqdm(enumerate(bertclsvec),total=bertclsvec.shape[0]):\n",
    "            bert.add_item(index+1, row)\n",
    "    \n",
    "print(\"building model...\")\n",
    "bert.build(100)\n",
    "print(\"saving model...\")\n",
    "bert.save('swarog_bertcls.ann')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6998b3a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load model...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from annoy import AnnoyIndex\n",
    "tfidf = AnnoyIndex(7000, 'angular')\n",
    "print(\"load model...\")\n",
    "tfidf.load('swarog_tfidf.ann')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2f06d07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load model...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from annoy import AnnoyIndex\n",
    "bert = AnnoyIndex(768, 'angular')\n",
    "print(\"load model...\")\n",
    "bert.load('swarog_bertcls.ann')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb2242b",
   "metadata": {},
   "source": [
    "<hr style=\"border: 5px dashed red\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad1e5ad",
   "metadata": {},
   "source": [
    "# 5x2 CV experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bbe31a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, f1_score, precision_score, recall_score, roc_auc_score\n",
    "from imblearn.metrics import geometric_mean_score\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def experiment(foldids, X, y, cls = LogisticRegression(max_iter=10000), fit=True):\n",
    "\n",
    "    scores = {\n",
    "        'Accuracy': {'func': accuracy_score},\n",
    "        'Balanced Accuracy': {'func': balanced_accuracy_score},\n",
    "        'F1': {'func': f1_score},\n",
    "        'Precision': {'func': precision_score},\n",
    "        'Recall': {'func': recall_score},\n",
    "        'G-mean': {'func': geometric_mean_score}\n",
    "    }\n",
    "\n",
    "    for score_name, score_dict in scores.items():\n",
    "        scores[score_name][\"list\"] = []\n",
    "        scores[score_name][\"lab\"] = []\n",
    "\n",
    "    for fold,j in enumerate(foldids):\n",
    "        train = foldids[fold][1]\n",
    "        test = foldids[fold][2]\n",
    "        xin, yin = X[train], np.array(y[train])\n",
    "        \n",
    "        pca = PCA(n_components=512)\n",
    "        pca.fit(xin)\n",
    "        \n",
    "        \n",
    "        if fit == True:\n",
    "            cls.fit(pca.transform(xin), yin)\n",
    "        y_pred = cls.predict(pca.transform(X[test]))\n",
    "        for score_name, score_dict in scores.items():\n",
    "            if score_name in [\"F1\",\"Precision\",\"Recall\"]:\n",
    "                scorvaln = score_dict['func'](y[test], y_pred, average=None)\n",
    "                score_dict['lab'].append(scorvaln)\n",
    "                scorval = score_dict['func'](y[test], y_pred, average=\"weighted\")\n",
    "                score_dict['list'].append(scorval)\n",
    "                #print(score_name, scorval, scorvaln)  \n",
    "            else:\n",
    "                scorval=score_dict['func'](y[test], y_pred)\n",
    "                score_dict['list'].append(scorval)\n",
    "                #print(score_name, scorval)\n",
    "        #print(\" \")\n",
    "\n",
    "    #clear_output()\n",
    "    for score_name, score_dict in scores.items():\n",
    "        score_dict['avg'] = np.mean(score_dict['list'])\n",
    "        score_dict['std'] = np.std(score_dict['list'])\n",
    " \n",
    "    # Print stats\n",
    "    numlabels = scores[\"F1\"][\"lab\"][0].shape[0]\n",
    "    scores[\"F1\"][\"lab\"][0].shape[0] \n",
    "    head = \"| %-20s | %-10s |\" +  numlabels * \" %-10s |\" \n",
    "    headv = [\"Score\", \"Average\"]\n",
    "    headv.extend([\"Kat_\"+str(i+1) for i in range(numlabels)])\n",
    "    row=head % tuple(headv)\n",
    "    print(\"+\"*len(row))\n",
    "    print(row)\n",
    "    print(\"+\"*len(row))\n",
    "    for score_name, score_dict in sorted(scores.items()) :\n",
    "        headv = [score_name, np.mean(score_dict['list'])*100, np.std(score_dict['list'])*100]\n",
    "        for i in range(numlabels):\n",
    "            if score_name in [\"F1\",\"Precision\",\"Recall\"]:\n",
    "                head = \"| %-20s | %4.1f ± %3.1f |\" + numlabels* \" %4.1f ± %3.1f |\"\n",
    "                vals = [v[i] for v in scores[score_name][\"lab\"]]\n",
    "                headv.append(np.mean(vals)*100)\n",
    "                headv.append(np.std(vals)*100)\n",
    "            else:\n",
    "                head = \"| %-20s | %4.1f ± %3.1f |\" + numlabels * \" %-10s |\" \n",
    "                headv.append(\"-\")\n",
    "        print(head % tuple(headv))\n",
    "    print(\"+\"*len(row))\n",
    "    return cls, scores, pca"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d604485c",
   "metadata": {},
   "source": [
    "### Recording test/train folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1919baeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TASK 0\n",
      "TASK 1\n",
      "TASK 2\n",
      "TASK 3\n",
      "TASK 4\n",
      "TASK 5\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "DATA[\"folds\"] = []\n",
    "rskf = RepeatedStratifiedKFold(n_splits=2, n_repeats=5, random_state=1410)\n",
    "\n",
    "\n",
    "for t in range(np.max(DATA[\"category\"]+1)):\n",
    "    print(\"TASK\",t)\n",
    "    X = DATA[\"X\"][DATA[\"category\"] == t]\n",
    "    y = DATA[\"y\"][DATA[\"category\"] == t]\n",
    "\n",
    "    foldids = []\n",
    "    for fold_idx, (train, test) in enumerate(rskf.split(X, y)):\n",
    "        foldids.append((fold_idx,train,test))\n",
    "\n",
    "    #print(\"shapes X\",X.shape,\"y\", y.shape)\n",
    "    DATA[\"folds\"].append(foldids)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c69e4b",
   "metadata": {},
   "source": [
    "<hr style=\"border: 5px dashed red\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d1ebeae",
   "metadata": {},
   "source": [
    "# Single Task Performance (BERT `CLS`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b14d9715",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TASK 0\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "| Score                | Average    | Kat_1      | Kat_2      |\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "| Accuracy             | 97.2 ± 0.1 | -          | -          |\n",
      "| Balanced Accuracy    | 79.3 ± 1.3 | -          | -          |\n",
      "| F1                   | 97.0 ± 0.1 | 68.7 ± 1.6 | 98.5 ± 0.1 |\n",
      "| G-mean               | 76.8 ± 1.7 | -          | -          |\n",
      "| Precision            | 97.0 ± 0.2 | 81.8 ± 3.5 | 97.8 ± 0.1 |\n",
      "| Recall               | 97.2 ± 0.1 | 59.4 ± 2.7 | 99.3 ± 0.2 |\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "TASK 1\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "| Score                | Average    | Kat_1      | Kat_2      |\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "| Accuracy             | 92.6 ± 0.2 | -          | -          |\n",
      "| Balanced Accuracy    | 88.2 ± 0.7 | -          | -          |\n",
      "| F1                   | 92.4 ± 0.3 | 95.1 ± 0.1 | 85.5 ± 0.7 |\n",
      "| G-mean               | 87.7 ± 0.8 | -          | -          |\n",
      "| Precision            | 92.7 ± 0.2 | 92.3 ± 0.6 | 93.9 ± 1.1 |\n",
      "| Recall               | 92.6 ± 0.2 | 98.0 ± 0.4 | 78.5 ± 1.8 |\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "TASK 2\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "| Score                | Average    | Kat_1      | Kat_2      |\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "| Accuracy             | 81.7 ± 0.4 | -          | -          |\n",
      "| Balanced Accuracy    | 80.4 ± 0.5 | -          | -          |\n",
      "| F1                   | 81.7 ± 0.4 | 75.5 ± 0.6 | 85.4 ± 0.3 |\n",
      "| G-mean               | 80.2 ± 0.5 | -          | -          |\n",
      "| Precision            | 81.7 ± 0.4 | 75.8 ± 0.6 | 85.2 ± 0.5 |\n",
      "| Recall               | 81.7 ± 0.4 | 75.2 ± 1.1 | 85.6 ± 0.6 |\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "TASK 3\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "| Score                | Average    | Kat_1      | Kat_2      |\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "| Accuracy             | 94.0 ± 0.1 | -          | -          |\n",
      "| Balanced Accuracy    | 80.5 ± 0.4 | -          | -          |\n",
      "| F1                   | 93.7 ± 0.1 | 96.7 ± 0.1 | 70.3 ± 0.6 |\n",
      "| G-mean               | 78.5 ± 0.5 | -          | -          |\n",
      "| Precision            | 93.7 ± 0.1 | 95.5 ± 0.1 | 79.5 ± 0.8 |\n",
      "| Recall               | 94.0 ± 0.1 | 98.0 ± 0.1 | 63.0 ± 0.9 |\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "TASK 4\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "| Score                | Average    | Kat_1      | Kat_2      |\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "| Accuracy             | 99.7 ± 0.0 | -          | -          |\n",
      "| Balanced Accuracy    | 99.7 ± 0.0 | -          | -          |\n",
      "| F1                   | 99.7 ± 0.0 | 99.7 ± 0.0 | 99.7 ± 0.0 |\n",
      "| G-mean               | 99.7 ± 0.0 | -          | -          |\n",
      "| Precision            | 99.7 ± 0.0 | 99.6 ± 0.1 | 99.7 ± 0.0 |\n",
      "| Recall               | 99.7 ± 0.0 | 99.7 ± 0.0 | 99.6 ± 0.1 |\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "TASK 5\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "| Score                | Average    | Kat_1      | Kat_2      |\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "| Accuracy             | 91.5 ± 0.1 | -          | -          |\n",
      "| Balanced Accuracy    | 85.0 ± 0.2 | -          | -          |\n",
      "| F1                   | 91.3 ± 0.1 | 94.7 ± 0.1 | 78.0 ± 0.2 |\n",
      "| G-mean               | 84.3 ± 0.2 | -          | -          |\n",
      "| Precision            | 91.3 ± 0.1 | 93.6 ± 0.1 | 82.4 ± 0.3 |\n",
      "| Recall               | 91.5 ± 0.1 | 96.0 ± 0.1 | 74.1 ± 0.3 |\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "DATA[\"folds\"] = []\n",
    "rskf = RepeatedStratifiedKFold(n_splits=2, n_repeats=5, random_state=1410)\n",
    "\n",
    "stl=[]\n",
    "\n",
    "for t in range(np.max(DATA[\"category\"]+1)):\n",
    "    print(\"TASK\",t)\n",
    "    X = DATA[\"X\"][DATA[\"category\"] == t]\n",
    "    y = DATA[\"y\"][DATA[\"category\"] == t]\n",
    "\n",
    "    foldids = []\n",
    "    for fold_idx, (train, test) in enumerate(rskf.split(X, y)):\n",
    "        foldids.append((fold_idx,train,test))\n",
    "\n",
    "    #print(\"shapes X\",X.shape,\"y\", y.shape)\n",
    "    DATA[\"folds\"].append(foldids)\n",
    "    model1, scores1, pca = experiment(foldids, X, y, \n",
    "                                 LogisticRegression(max_iter=10000))\n",
    "    stl.append((model1,pca,scores1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d234ab",
   "metadata": {},
   "source": [
    "<hr style=\"border: 5px dashed red\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac0435fa",
   "metadata": {},
   "source": [
    "# Domain Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "721c10a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shapes X (186477, 768) y (186477,)\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "| Score                | Average    | Kat_1      | Kat_2      | Kat_3      | Kat_4      | Kat_5      | Kat_6      |\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "| Accuracy             | 79.6 ± 0.1 | -          | -          | -          | -          | -          | -          |\n",
      "| Balanced Accuracy    | 85.7 ± 0.1 | -          | -          | -          | -          | -          | -          |\n",
      "| F1                   | 79.6 ± 0.1 | 96.7 ± 0.2 | 82.8 ± 0.4 | 72.8 ± 0.5 | 72.8 ± 0.2 | 87.2 ± 0.1 | 77.9 ± 0.1 |\n",
      "| G-mean               | 85.1 ± 0.1 | -          | -          | -          | -          | -          | -          |\n",
      "| Precision            | 80.2 ± 0.1 | 95.2 ± 0.3 | 75.4 ± 0.6 | 61.5 ± 0.7 | 73.1 ± 0.2 | 85.0 ± 0.2 | 83.8 ± 0.3 |\n",
      "| Recall               | 79.6 ± 0.1 | 98.2 ± 0.2 | 91.9 ± 0.5 | 89.3 ± 0.4 | 72.4 ± 0.4 | 89.5 ± 0.2 | 72.9 ± 0.3 |\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n"
     ]
    }
   ],
   "source": [
    "X = DATA[\"X\"]\n",
    "y = DATA[\"y\"]\n",
    "category = DATA[\"category\"]\n",
    "\n",
    "rskf = RepeatedStratifiedKFold(n_splits=2, n_repeats=5, random_state=1410)\n",
    "foldids = []\n",
    "for fold_idx, (train, test) in enumerate(rskf.split(X, y)):\n",
    "    foldids.append((fold_idx,train,test))\n",
    "    \n",
    "print(\"shapes X\",X.shape,\"y\", category.shape)\n",
    "\n",
    "domain_model, domain_scores, domain_pca = experiment(foldids, X, \n",
    "                                         category, LogisticRegression(max_iter=10000, class_weight='balanced'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a936ae23",
   "metadata": {},
   "source": [
    "<hr style=\"border: 5px dashed red\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72997796",
   "metadata": {},
   "source": [
    "# Global model with category pred."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4a2e7f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, f1_score, precision_score, recall_score, roc_auc_score\n",
    "from imblearn.metrics import geometric_mean_score\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def cls_max_predict(X_test):\n",
    "    ypred = np.array([stl[t][0].predict(stl[t][1].transform(X_test)) for t in range(6)])\n",
    "    return np.mean(ypred, axis=0) > 0.5\n",
    "\n",
    "def cls_weighted_predict(X_test):\n",
    "    ypred = np.array([stl[t][0].predict(stl[t][1].transform(X_test)) for t in range(6)])\n",
    "    return np.average(ypred, weights=[78,83,74,73,90,73], axis=0) > 0.4\n",
    "\n",
    "def cls_max_predict_raw(X_test):\n",
    "    ypred = np.array([stl[t][0].predict(stl[t][1].transform(X_test)) for t in range(6)])\n",
    "    return ypred\n",
    "\n",
    "def cls_predict(X_test):\n",
    "    Xd=domain_pca.transform(X_test)\n",
    "    domain_pred = domain_model.predict(Xd)\n",
    "    ypred = []\n",
    "    for i,dpred in enumerate(domain_pred):\n",
    "        model, model_pca, _ = stl[dpred] \n",
    "        xpca = model_pca.transform(X_test[i:i+1])\n",
    "        ypred.append(model.predict(xpca)[0])\n",
    "    return ypred\n",
    "        \n",
    "def experiment2(foldids, X, y, cback):\n",
    "\n",
    "    scores = {\n",
    "        'Accuracy': {'func': accuracy_score},\n",
    "        'Balanced Accuracy': {'func': balanced_accuracy_score},\n",
    "        'F1': {'func': f1_score},\n",
    "        'Precision': {'func': precision_score},\n",
    "        'Recall': {'func': recall_score},\n",
    "        'G-mean': {'func': geometric_mean_score}\n",
    "    }\n",
    "\n",
    "    for score_name, score_dict in scores.items():\n",
    "        scores[score_name][\"list\"] = []\n",
    "        scores[score_name][\"lab\"] = []\n",
    "\n",
    "    for fold,j in enumerate(foldids):\n",
    "        train = foldids[fold][1]\n",
    "        test = foldids[fold][2]\n",
    "        xin, yin = X[train], np.array(y[train])\n",
    "        \n",
    "        y_pred = cback(X[test])\n",
    "        \n",
    "        for score_name, score_dict in scores.items():\n",
    "            if score_name in [\"F1\",\"Precision\",\"Recall\"]:\n",
    "                scorvaln = score_dict['func'](y[test], y_pred, average=None)\n",
    "                score_dict['lab'].append(scorvaln)\n",
    "                scorval = score_dict['func'](y[test], y_pred, average=\"weighted\")\n",
    "                score_dict['list'].append(scorval)\n",
    "                print(score_name, scorval, scorvaln)  \n",
    "            else:\n",
    "                scorval=score_dict['func'](y[test], y_pred)\n",
    "                score_dict['list'].append(scorval)\n",
    "                print(score_name, scorval)\n",
    "        print(\" \")\n",
    "\n",
    "    clear_output()\n",
    "    for score_name, score_dict in scores.items():\n",
    "        score_dict['avg'] = np.mean(score_dict['list'])\n",
    "        score_dict['std'] = np.std(score_dict['list'])\n",
    " \n",
    "    # Print stats\n",
    "    numlabels = scores[\"F1\"][\"lab\"][0].shape[0]\n",
    "    scores[\"F1\"][\"lab\"][0].shape[0] \n",
    "    head = \"| %-20s | %-10s |\" +  numlabels * \" %-10s |\" \n",
    "    headv = [\"Score\", \"Average\"]\n",
    "    headv.extend([\"Kat_\"+str(i+1) for i in range(numlabels)])\n",
    "    row=head % tuple(headv)\n",
    "    print(\"+\"*len(row))\n",
    "    print(row)\n",
    "    print(\"+\"*len(row))\n",
    "    for score_name, score_dict in sorted(scores.items()) :\n",
    "        headv = [score_name, np.mean(score_dict['list'])*100, np.std(score_dict['list'])*100]\n",
    "        for i in range(numlabels):\n",
    "            if score_name in [\"F1\",\"Precision\",\"Recall\"]:\n",
    "                head = \"| %-20s | %4.1f ± %3.1f |\" + numlabels* \" %4.1f ± %3.1f |\"\n",
    "                vals = [v[i] for v in scores[score_name][\"lab\"]]\n",
    "                headv.append(np.mean(vals)*100)\n",
    "                headv.append(np.std(vals)*100)\n",
    "            else:\n",
    "                head = \"| %-20s | %4.1f ± %3.1f |\" + numlabels * \" %-10s |\" \n",
    "                headv.append(\"-\")\n",
    "        print(head % tuple(headv))\n",
    "    print(\"+\"*len(row))\n",
    "    return scores, pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e386678b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 169.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shapes X (186477, 768) y (186477,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.8906895183346025\n",
      "Balanced Accuracy 0.8738772228942854\n",
      "F1 0.890706375178059 [0.9199887  0.82753486]\n",
      "Precision 0.8907234951046911 [0.92023432 0.82705902]\n",
      "Recall 0.8906895183346025 [0.9197432  0.82801124]\n",
      "G-mean 0.8726727407962598\n",
      " \n",
      "Accuracy 0.8902378858405371\n",
      "Balanced Accuracy 0.8740442812747655\n",
      "F1 0.8903299506300135 [0.919563  0.8272626]\n",
      "Precision 0.8904298659660493 [0.92090929 0.82467358]\n",
      "Recall 0.8902378858405371 [0.91822063 0.82986793]\n",
      "G-mean 0.8729271766294437\n",
      " \n",
      "Accuracy 0.8901210866697412\n",
      "Balanced Accuracy 0.8736792558319861\n",
      "F1 0.8901881059739745 [0.9195088 0.8269338]\n",
      "Precision 0.8902592631467223 [0.92048511 0.82505225]\n",
      "Recall 0.8901210866697412 [0.91853456 0.82882395]\n",
      "G-mean 0.8725270445120594\n",
      " \n",
      "Accuracy 0.8908063236019649\n",
      "Balanced Accuracy 0.8742422345763926\n",
      "F1 0.8908483410282234 [0.92004304 0.82786372]\n",
      "Precision 0.8908920018230735 [0.92065762 0.82667567]\n",
      "Recall 0.8908063236019649 [0.91942927 0.8290552 ]\n",
      "G-mean 0.8730736603814897\n",
      " \n",
      "Accuracy 0.8904535655680563\n",
      "Balanced Accuracy 0.8735410651778874\n",
      "F1 0.8904635080996898 [0.9198248  0.82712163]\n",
      "Precision 0.8904735416496804 [0.91996922 0.82684173]\n",
      "Recall 0.8904535655680563 [0.91968042 0.82740171]\n",
      "G-mean 0.8723217025699785\n",
      " \n",
      "Accuracy 0.8904845663785153\n",
      "Balanced Accuracy 0.8743973812452943\n",
      "F1 0.8905837749318338 [0.91973431 0.82769444]\n",
      "Precision 0.8906921527351259 [0.92118979 0.82489657]\n",
      "Recall 0.8904845663785153 [0.91828342 0.83051134]\n",
      "G-mean 0.8732953658976153\n",
      " \n",
      "Accuracy 0.890206887675758\n",
      "Balanced Accuracy 0.8735876304050934\n",
      "F1 0.890253094942496 [0.91959819 0.82694616]\n",
      "Precision 0.8903012673833978 [0.92027038 0.82564812]\n",
      "Recall 0.890206887675758 [0.91892698 0.82824828]\n",
      "G-mean 0.8724102770111375\n",
      " \n",
      "Accuracy 0.8907312469164933\n",
      "Balanced Accuracy 0.874350801684055\n",
      "F1 0.8907944592678206 [0.91996103 0.82787051]\n",
      "Precision 0.890861395461057 [0.92088707 0.82608402]\n",
      "Recall 0.8907312469164933 [0.91903686 0.82966475]\n",
      "G-mean 0.8732081544432301\n",
      " \n",
      "Accuracy 0.8914295520114973\n",
      "Balanced Accuracy 0.874654915501095\n",
      "F1 0.8914379288329449 [0.92054098 0.82865316]\n",
      "Precision 0.89144637151626 [0.92066383 0.82841478]\n",
      "Recall 0.8914295520114973 [0.92041816 0.82889167]\n",
      "G-mean 0.8734568946779143\n",
      " \n",
      "Accuracy 0.8895085694673845\n",
      "Balanced Accuracy 0.8732835056941879\n",
      "F1 0.8896101443677675 [0.91901707 0.82616766]\n",
      "Precision 0.8897211498155903 [0.9204932  0.82333356]\n",
      "Recall 0.8895085694673845 [0.91754568 0.82902133]\n",
      "G-mean 0.872161075430089\n",
      " \n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "| Score                | Average    | Kat_1      | Kat_2      |\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "| Accuracy             | 89.0 ± 0.0 | -          | -          |\n",
      "| Balanced Accuracy    | 87.4 ± 0.0 | -          | -          |\n",
      "| F1                   | 89.1 ± 0.0 | 92.0 ± 0.0 | 82.7 ± 0.1 |\n",
      "| G-mean               | 87.3 ± 0.0 | -          | -          |\n",
      "| Precision            | 89.1 ± 0.0 | 92.1 ± 0.0 | 82.6 ± 0.1 |\n",
      "| Recall               | 89.0 ± 0.0 | 91.9 ± 0.1 | 82.9 ± 0.1 |\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n"
     ]
    }
   ],
   "source": [
    "X = DATA[\"X\"]\n",
    "y = DATA[\"y\"]\n",
    "\n",
    "\n",
    "rskf = RepeatedStratifiedKFold(n_splits=2, n_repeats=5, random_state=1410)\n",
    "foldids = []\n",
    "for fold_idx, (train, test) in tqdm(enumerate(rskf.split(X, y)), total=rskf.get_n_splits()):\n",
    "    foldids.append((fold_idx,train,test))\n",
    "    \n",
    "print(\"shapes X\",X.shape,\"y\", y.shape)\n",
    "\n",
    "gscr, gpca = experiment2(foldids, X, y, cls_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3345fd67",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "pipe_domain = Pipeline([('pca', domain_pca), ('head', domain_model)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc761e8",
   "metadata": {},
   "source": [
    "# Pickle models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1e539126",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# SAVE\n",
    "with open('domain_cls.pickle', 'wb') as handle:\n",
    "    pickle.dump(pipe_domain, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cce3db32",
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_model_pipe = []\n",
    "for i,elem in enumerate(stl):\n",
    "    with open(f'model_{i}.pickle', 'wb') as handle:\n",
    "        p = Pipeline([('pca', elem[1]), ('head', elem[0])])\n",
    "        domain_model_pipe.append(p)\n",
    "        pickle.dump(p, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8392f0a3",
   "metadata": {},
   "source": [
    "# Un-pickle models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "7081447d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# load\n",
    "with open('domain_cls.pickle', 'rb') as handle:\n",
    "    pipe_domain = pickle.load(handle)\n",
    "    \n",
    "domain_model_pipe = []\n",
    "for i in range(6):\n",
    "    with open(f'model_{i}.pickle', 'rb') as handle:\n",
    "        p=pickle.load(handle)\n",
    "        domain_model_pipe.append(p)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "eb987770",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([1, 1], [1, 1])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls_predict(X[0:2]), y[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "46d235e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved: Model(tag=\"big_puppy:wo3hgzkt6wg6itgm\")\n"
     ]
    }
   ],
   "source": [
    "import bentoml\n",
    "\n",
    "from sklearn import svm\n",
    "\n",
    "saved_model = bentoml.sklearn.save_model(\"big_puppy\", bp)\n",
    "print(f\"Model saved: {saved_model}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "161ec780",
   "metadata": {},
   "source": [
    "# BENTO models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "7212662f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Model saved: Model(tag=\"domain_cls:6vgf5nkwiombitgm\")\n"
     ]
    }
   ],
   "source": [
    "import bentoml\n",
    "\n",
    "from sklearn import svm\n",
    "\n",
    "saved_model = bentoml.sklearn.save_model(\"domain_cls\", pipe_domain, signatures={\n",
    "        \"predict\": {\"batchable\": True, \"batch_dim\": 0},\n",
    "        \"predict_proba\": {\"batchable\": True, \"batch_dim\": 0},\n",
    "    })\n",
    "print(f\"Model saved: {saved_model}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "91c92581",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved: Model(tag=\"model_0:7gq6owcwio3oqtgm\")\n",
      "Model saved: Model(tag=\"model_1:7hx67tswiojdktgm\")\n",
      "Model saved: Model(tag=\"model_2:7jkorskwiot2atgm\")\n",
      "Model saved: Model(tag=\"model_3:7kda6x2wioeaytgm\")\n",
      "Model saved: Model(tag=\"model_4:7li2yy2wiowiatgm\")\n",
      "Model saved: Model(tag=\"model_5:7ony5tcwiooustgm\")\n"
     ]
    }
   ],
   "source": [
    "for i in range(6):\n",
    "    saved_model = bentoml.sklearn.save_model(f\"model_{i}\", domain_model_pipe[i], signatures={\n",
    "        \"predict\": {\"batchable\": True, \"batch_dim\": 0},\n",
    "        \"predict_proba\": {\"batchable\": True, \"batch_dim\": 0},\n",
    "    })\n",
    "    print(f\"Model saved: {saved_model}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b369104",
   "metadata": {},
   "source": [
    "### check rest api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "e8837034",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"result\":1,\"result_proba\":[0.12162441839088234,0.8783755816091177],\"domain\":5,\"domain_proba\":[3.727105162009764e-05,0.2524389920779804,0.00014313585175861234,0.011453801048172181,0.35051739023097733,0.3854094097394914]}'"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "requests.post(\n",
    "     \"http://0.0.0.0:3000/predict\",\n",
    "     headers={\"content-type\": \"application/json\"},\n",
    "     data='{\"text\":\"I love it\"}'\n",
    ").text"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "273px",
    "width": "351px"
   },
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
