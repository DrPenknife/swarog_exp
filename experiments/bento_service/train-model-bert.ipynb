{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SQL definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "conn = sqlite3.connect('swarog.sqlite')\n",
    "c = conn.cursor()\n",
    "c.execute('''CREATE TABLE raw\n",
    "             (dataset TEXT, id INT, body TEXT, label INT)''')\n",
    "conn.commit()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "conn = sqlite3.connect('swarog.sqlite')\n",
    "c = conn.cursor()\n",
    "c.execute('''CREATE TABLE bert\n",
    "             (dataset TEXT, id INT, vec TEXT)''')\n",
    "conn.commit()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "conn = sqlite3.connect('swarog.sqlite')\n",
    "c = conn.cursor()\n",
    "c.execute('''CREATE TABLE bertnp\n",
    "             (dataset TEXT, id INT, vec BLOB)''')\n",
    "conn.commit()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "compressor = 'zlib'\n",
    "\n",
    "def adapt_array(arr):\n",
    "    \"\"\"\n",
    "    http://stackoverflow.com/a/31312102/190597 (SoulNibbler)\n",
    "    \"\"\"\n",
    "    # zlib uses similar disk size that Matlab v5 .mat files\n",
    "    # bz2 compress 4 times zlib, but storing process is 20 times slower.\n",
    "    out = io.BytesIO()\n",
    "    np.save(out, arr)\n",
    "    out.seek(0)\n",
    "    return sqlite3.Binary(codecs.encode(out.read(),compressor))  # zlib, bz2\n",
    "\n",
    "def convert_array(text):\n",
    "    out = io.BytesIO(text)\n",
    "    out.seek(0)\n",
    "    out = io.BytesIO(codecs.decode(out.read(),compressor))\n",
    "    return np.load(out)\n",
    "\n",
    "import sqlite3\n",
    "\n",
    "# sqlite3.register_adapter(np.ndarray, adapt_array)\n",
    "# sqlite3.register_converter(\"array\", convert_array)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect('swarog.sqlite')\n",
    "c = conn.cursor()\n",
    "c.execute('''CREATE TABLE bertnp\n",
    "             (dataset TEXT, id INT, vec array)''')\n",
    "conn.commit()\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import raw text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 8972/8972 [00:22<00:00, 400.03it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 7332/7332 [00:19<00:00, 379.15it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 10075/10075 [00:27<00:00, 364.48it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 51270/51270 [02:50<00:00, 299.88it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 44898/44898 [02:41<00:00, 277.39it/s]\n",
      "/tmp/ipykernel_4157/3735554623.py:39: DtypeWarning: Columns (3,5,6,9,10,11,12,13,14,16,22) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv(\"../raw/grafn.csv\",sep=\",\")\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 63930/63930 [03:17<00:00, 323.35it/s]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "conn = sqlite3.connect('swarog.sqlite')\n",
    "c = conn.cursor()\n",
    "\n",
    "data = pd.read_csv(\"../raw/covid_fake_news.csv\",sep=\"\\t\")\n",
    "for index, row in tqdm(data.iterrows(), total=data.shape[0]):\n",
    "    values_to_insert = [('covid_fake_news', index, row['text'], row['label'])]\n",
    "    c.executemany(\"\"\"INSERT INTO raw(dataset, id, body, label) VALUES (?,?,?,?)\"\"\", values_to_insert)\n",
    "    conn.commit()\n",
    "    \n",
    "    \n",
    "data = pd.read_csv(\"../raw/mmcovid_en.csv\",sep=\",\")\n",
    "for index, row in tqdm(data.iterrows(), total=data.shape[0]):\n",
    "    values_to_insert = [('mmcovid_en', index, row['text'], row['label'])]\n",
    "    c.executemany(\"\"\"INSERT INTO raw(dataset, id, body, label) VALUES (?,?,?,?)\"\"\", values_to_insert)\n",
    "    conn.commit()\n",
    "\n",
    "data = pd.read_csv(\"../raw/pubhealth.csv\",sep=\",\")\n",
    "for index, row in tqdm(data.iterrows(), total=data.shape[0]):\n",
    "    values_to_insert = [('pubhealth', index, row['text'], row['label'])]\n",
    "    c.executemany(\"\"\"INSERT INTO raw(dataset, id, body, label) VALUES (?,?,?,?)\"\"\", values_to_insert)\n",
    "    conn.commit()\n",
    "\n",
    "data = pd.read_csv(\"../raw/qprop.csv\",sep=\"\\t\")\n",
    "for index, row in tqdm(data.iterrows(), total=data.shape[0]):\n",
    "    values_to_insert = [('qprop', index, row['text'], row['label'])]\n",
    "    c.executemany(\"\"\"INSERT INTO raw(dataset, id, body, label) VALUES (?,?,?,?)\"\"\", values_to_insert)\n",
    "    conn.commit()\n",
    "    \n",
    "data = pd.read_csv(\"../raw/isot.csv\",sep=\",\")\n",
    "for index, row in tqdm(data.iterrows(), total=data.shape[0]):\n",
    "    values_to_insert = [('isot', index, row['text'], row['label'])]\n",
    "    c.executemany(\"\"\"INSERT INTO raw(dataset, id, body, label) VALUES (?,?,?,?)\"\"\", values_to_insert)\n",
    "    conn.commit()\n",
    "    \n",
    "    \n",
    "data = pd.read_csv(\"../raw/grafn.csv\",sep=\",\")\n",
    "for index, row in tqdm(data.iterrows(), total=data.shape[0]):\n",
    "    values_to_insert = [('grafn', index, row['text'], row['label'])]\n",
    "    c.executemany(\"\"\"INSERT INTO raw(dataset, id, body, label) VALUES (?,?,?,?)\"\"\", values_to_insert)\n",
    "    conn.commit()\n",
    "    \n",
    "        \n",
    "\n",
    "    \n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import bert CLS vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 8972/8972 [00:34<00:00, 259.38it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 7332/7332 [00:18<00:00, 392.50it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 10075/10075 [00:36<00:00, 275.73it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 51270/51270 [02:57<00:00, 288.65it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 44898/44898 [02:15<00:00, 330.69it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 63930/63930 [03:29<00:00, 304.71it/s]\n"
     ]
    }
   ],
   "source": [
    "import pickle \n",
    "import json\n",
    "import codecs\n",
    "\n",
    "conn = sqlite3.connect('swarog.sqlite')\n",
    "c = conn.cursor()\n",
    "\n",
    "\n",
    "with open('../covid_fake_news_BERTEmbeddings.pickle', 'rb') as handle:\n",
    "    dst = pickle.load(handle)\n",
    "    for index, row in tqdm(enumerate(dst),total=len(dst)):\n",
    "        values_to_insert = [('covid_fake_news', index, adapt_array(row))]\n",
    "        c.executemany(\"\"\"INSERT INTO bertnp(dataset, id, vec) VALUES (?,?,?)\"\"\", values_to_insert)\n",
    "        conn.commit()\n",
    "        \n",
    "        \n",
    "with open('../mmcovid_en_BERTEmbeddings.pickle', 'rb') as handle:\n",
    "    dst = pickle.load(handle)\n",
    "    for index, row in tqdm(enumerate(dst),total=len(dst)):\n",
    "        values_to_insert = [('mmcovid_en', index, adapt_array(row))]\n",
    "        c.executemany(\"\"\"INSERT INTO bertnp(dataset, id, vec) VALUES (?,?,?)\"\"\", values_to_insert)\n",
    "        conn.commit()\n",
    "        \n",
    "with open('../pubhealth_BERTEmbeddings.pickle', 'rb') as handle:\n",
    "    dst = pickle.load(handle)\n",
    "    for index, row in tqdm(enumerate(dst),total=len(dst)):\n",
    "        values_to_insert = [('pubhealth', index, adapt_array(row))]\n",
    "        c.executemany(\"\"\"INSERT INTO bertnp(dataset, id, vec) VALUES (?,?,?)\"\"\", values_to_insert)\n",
    "        conn.commit()\n",
    "        \n",
    "with open('../qprop_BERTEmbeddings.pickle', 'rb') as handle:\n",
    "    dst = pickle.load(handle)\n",
    "    for index, row in tqdm(enumerate(dst),total=len(dst)):\n",
    "        values_to_insert = [('qprop', index, adapt_array(row))]\n",
    "        c.executemany(\"\"\"INSERT INTO bertnp(dataset, id, vec) VALUES (?,?,?)\"\"\", values_to_insert)\n",
    "        conn.commit()\n",
    "\n",
    "with open('../isot_BERTEmbeddings.pickle', 'rb') as handle:\n",
    "    dst = pickle.load(handle)\n",
    "    for index, row in tqdm(enumerate(dst),total=len(dst)):\n",
    "        values_to_insert = [('isot', index, adapt_array(row))]\n",
    "        c.executemany(\"\"\"INSERT INTO bertnp(dataset, id, vec) VALUES (?,?,?)\"\"\", values_to_insert)\n",
    "        conn.commit()\n",
    "                \n",
    "with open('../grafn_BERTEmbeddings.pickle', 'rb') as handle:\n",
    "    dst = pickle.load(handle)\n",
    "    for index, row in tqdm(enumerate(dst),total=len(dst)):\n",
    "        values_to_insert = [('grafn', index, adapt_array(row))]\n",
    "        c.executemany(\"\"\"INSERT INTO bertnp(dataset, id, vec) VALUES (?,?,?)\"\"\", values_to_insert)\n",
    "        conn.commit()\n",
    "        \n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Un-pickle `TF-IDF` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "DATA = {\n",
    "    \"X\" : [],\n",
    "    \"category\" : [],\n",
    "    \"y\" : []\n",
    "}\n",
    "\n",
    "X=DATA[\"X\"]\n",
    "category=DATA[\"category\"]\n",
    "y=DATA[\"y\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Un-pickle bert `CLS` tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6542/996138349.py:57: DtypeWarning: Columns (3,5,6,9,10,11,12,13,14,16,22) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv(\"../raw/grafn.csv\",sep=\",\")\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "DATA = {\n",
    "    \"X\" : [],\n",
    "    \"category\" : [],\n",
    "    \"y\" : []\n",
    "}\n",
    "\n",
    "X=DATA[\"X\"]\n",
    "category=DATA[\"category\"]\n",
    "y=DATA[\"y\"]\n",
    "\n",
    "\n",
    "with open('../covid_fake_news_BERTEmbeddings.pickle', 'rb') as handle:\n",
    "    dst = pickle.load(handle)\n",
    "    X.extend(dst)\n",
    "    category.extend(np.repeat(0,len(dst)))\n",
    "    data = pd.read_csv(\"../raw/covid_fake_news.csv\",sep=\"\\t\")\n",
    "    y.extend(data[\"label\"].values)\n",
    "    \n",
    "with open('../mmcovid_en_BERTEmbeddings.pickle', 'rb') as handle:\n",
    "    dst = pickle.load(handle)\n",
    "    X.extend(dst)\n",
    "    category.extend(np.repeat(1,len(dst)))\n",
    "    data = pd.read_csv(\"../raw/mmcovid_en.csv\",sep=\",\")\n",
    "    y.extend(data[\"label\"].values)\n",
    "    \n",
    "\n",
    "with open('../pubhealth_BERTEmbeddings.pickle', 'rb') as handle:\n",
    "    dst = pickle.load(handle)\n",
    "    X.extend(dst)\n",
    "    category.extend(np.repeat(2,len(dst)))\n",
    "    data = pd.read_csv(\"../raw/pubhealth.csv\",sep=\",\")\n",
    "    y.extend(data[\"label\"].values)\n",
    "\n",
    "    \n",
    "with open('../qprop_BERTEmbeddings.pickle', 'rb') as handle:\n",
    "    dst = pickle.load(handle)\n",
    "    X.extend(dst)\n",
    "    category.extend(np.repeat(3,len(dst)))\n",
    "    data = pd.read_csv(\"../raw/qprop.csv\",sep=\"\\t\")\n",
    "    y.extend(data[\"label\"].values)\n",
    "    \n",
    "with open('../isot_BERTEmbeddings.pickle', 'rb') as handle:\n",
    "    dst = pickle.load(handle)\n",
    "    X.extend(dst)\n",
    "    category.extend(np.repeat(4,len(dst)))\n",
    "    data = pd.read_csv(\"../raw/isot.csv\",sep=\",\")\n",
    "    y.extend(data[\"label\"].values)\n",
    "    \n",
    "with open('../grafn_BERTEmbeddings.pickle', 'rb') as handle:\n",
    "    dst = pickle.load(handle)\n",
    "    X.extend(dst)\n",
    "    category.extend(np.repeat(5,len(dst)))\n",
    "    data = pd.read_csv(\"../raw/grafn.csv\",sep=\",\")\n",
    "    y.extend(data[\"label\"].values)\n",
    "    \n",
    "    \n",
    "DATA[\"X\"]=np.array(X)\n",
    "DATA[\"category\"]=np.array(category)\n",
    "DATA[\"y\"]=np.array(y)\n",
    "DATA[\"folds\"] = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5x2 CV experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, f1_score, precision_score, recall_score, roc_auc_score\n",
    "from imblearn.metrics import geometric_mean_score\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def experiment(foldids, X, y, cls = LogisticRegression(max_iter=10000), fit=True):\n",
    "\n",
    "    scores = {\n",
    "        'Accuracy': {'func': accuracy_score},\n",
    "        'Balanced Accuracy': {'func': balanced_accuracy_score},\n",
    "        'F1': {'func': f1_score},\n",
    "        'Precision': {'func': precision_score},\n",
    "        'Recall': {'func': recall_score},\n",
    "        'G-mean': {'func': geometric_mean_score}\n",
    "    }\n",
    "\n",
    "    for score_name, score_dict in scores.items():\n",
    "        scores[score_name][\"list\"] = []\n",
    "        scores[score_name][\"lab\"] = []\n",
    "\n",
    "    for fold,j in enumerate(foldids):\n",
    "        train = foldids[fold][1]\n",
    "        test = foldids[fold][2]\n",
    "        xin, yin = X[train], np.array(y[train])\n",
    "        \n",
    "        pca = PCA(n_components=512)\n",
    "        pca.fit(xin)\n",
    "        \n",
    "        \n",
    "        if fit == True:\n",
    "            cls.fit(pca.transform(xin), yin)\n",
    "        y_pred = cls.predict(pca.transform(X[test]))\n",
    "        for score_name, score_dict in scores.items():\n",
    "            if score_name in [\"F1\",\"Precision\",\"Recall\"]:\n",
    "                scorvaln = score_dict['func'](y[test], y_pred, average=None)\n",
    "                score_dict['lab'].append(scorvaln)\n",
    "                scorval = score_dict['func'](y[test], y_pred, average=\"weighted\")\n",
    "                score_dict['list'].append(scorval)\n",
    "                #print(score_name, scorval, scorvaln)  \n",
    "            else:\n",
    "                scorval=score_dict['func'](y[test], y_pred)\n",
    "                score_dict['list'].append(scorval)\n",
    "                #print(score_name, scorval)\n",
    "        #print(\" \")\n",
    "\n",
    "    #clear_output()\n",
    "    for score_name, score_dict in scores.items():\n",
    "        score_dict['avg'] = np.mean(score_dict['list'])\n",
    "        score_dict['std'] = np.std(score_dict['list'])\n",
    " \n",
    "    # Print stats\n",
    "    numlabels = scores[\"F1\"][\"lab\"][0].shape[0]\n",
    "    scores[\"F1\"][\"lab\"][0].shape[0] \n",
    "    head = \"| %-20s | %-10s |\" +  numlabels * \" %-10s |\" \n",
    "    headv = [\"Score\", \"Average\"]\n",
    "    headv.extend([\"Kat_\"+str(i+1) for i in range(numlabels)])\n",
    "    row=head % tuple(headv)\n",
    "    print(\"+\"*len(row))\n",
    "    print(row)\n",
    "    print(\"+\"*len(row))\n",
    "    for score_name, score_dict in sorted(scores.items()) :\n",
    "        headv = [score_name, np.mean(score_dict['list'])*100, np.std(score_dict['list'])*100]\n",
    "        for i in range(numlabels):\n",
    "            if score_name in [\"F1\",\"Precision\",\"Recall\"]:\n",
    "                head = \"| %-20s | %4.1f ± %3.1f |\" + numlabels* \" %4.1f ± %3.1f |\"\n",
    "                vals = [v[i] for v in scores[score_name][\"lab\"]]\n",
    "                headv.append(np.mean(vals)*100)\n",
    "                headv.append(np.std(vals)*100)\n",
    "            else:\n",
    "                head = \"| %-20s | %4.1f ± %3.1f |\" + numlabels * \" %-10s |\" \n",
    "                headv.append(\"-\")\n",
    "        print(head % tuple(headv))\n",
    "    print(\"+\"*len(row))\n",
    "    return cls, scores, pca"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recording test/train folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TASK 0\n",
      "TASK 1\n",
      "TASK 2\n",
      "TASK 3\n",
      "TASK 4\n",
      "TASK 5\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "DATA[\"folds\"] = []\n",
    "rskf = RepeatedStratifiedKFold(n_splits=2, n_repeats=5, random_state=1410)\n",
    "\n",
    "\n",
    "for t in range(np.max(DATA[\"category\"]+1)):\n",
    "    print(\"TASK\",t)\n",
    "    X = DATA[\"X\"][DATA[\"category\"] == t]\n",
    "    y = DATA[\"y\"][DATA[\"category\"] == t]\n",
    "\n",
    "    foldids = []\n",
    "    for fold_idx, (train, test) in enumerate(rskf.split(X, y)):\n",
    "        foldids.append((fold_idx,train,test))\n",
    "\n",
    "    #print(\"shapes X\",X.shape,\"y\", y.shape)\n",
    "    DATA[\"folds\"].append(foldids)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border: 5px dashed red\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single Task Performance (BERT `CLS`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TASK 0\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "| Score                | Average    | Kat_1      | Kat_2      |\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "| Accuracy             | 97.2 ± 0.1 | -          | -          |\n",
      "| Balanced Accuracy    | 79.3 ± 1.3 | -          | -          |\n",
      "| F1                   | 97.0 ± 0.1 | 68.7 ± 1.6 | 98.5 ± 0.1 |\n",
      "| G-mean               | 76.8 ± 1.7 | -          | -          |\n",
      "| Precision            | 97.0 ± 0.2 | 81.8 ± 3.5 | 97.8 ± 0.1 |\n",
      "| Recall               | 97.2 ± 0.1 | 59.4 ± 2.7 | 99.3 ± 0.2 |\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "TASK 1\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "| Score                | Average    | Kat_1      | Kat_2      |\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "| Accuracy             | 92.6 ± 0.2 | -          | -          |\n",
      "| Balanced Accuracy    | 88.2 ± 0.7 | -          | -          |\n",
      "| F1                   | 92.4 ± 0.3 | 95.1 ± 0.1 | 85.5 ± 0.7 |\n",
      "| G-mean               | 87.7 ± 0.8 | -          | -          |\n",
      "| Precision            | 92.7 ± 0.2 | 92.3 ± 0.6 | 93.9 ± 1.1 |\n",
      "| Recall               | 92.6 ± 0.2 | 98.0 ± 0.4 | 78.5 ± 1.8 |\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "TASK 2\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "| Score                | Average    | Kat_1      | Kat_2      |\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "| Accuracy             | 81.7 ± 0.4 | -          | -          |\n",
      "| Balanced Accuracy    | 80.4 ± 0.5 | -          | -          |\n",
      "| F1                   | 81.7 ± 0.4 | 75.5 ± 0.6 | 85.4 ± 0.3 |\n",
      "| G-mean               | 80.2 ± 0.5 | -          | -          |\n",
      "| Precision            | 81.7 ± 0.4 | 75.8 ± 0.6 | 85.2 ± 0.5 |\n",
      "| Recall               | 81.7 ± 0.4 | 75.2 ± 1.1 | 85.6 ± 0.6 |\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "TASK 3\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "| Score                | Average    | Kat_1      | Kat_2      |\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "| Accuracy             | 94.0 ± 0.1 | -          | -          |\n",
      "| Balanced Accuracy    | 80.5 ± 0.4 | -          | -          |\n",
      "| F1                   | 93.7 ± 0.1 | 96.7 ± 0.1 | 70.3 ± 0.6 |\n",
      "| G-mean               | 78.5 ± 0.5 | -          | -          |\n",
      "| Precision            | 93.7 ± 0.1 | 95.5 ± 0.1 | 79.5 ± 0.8 |\n",
      "| Recall               | 94.0 ± 0.1 | 98.0 ± 0.1 | 63.0 ± 0.9 |\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "TASK 4\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "| Score                | Average    | Kat_1      | Kat_2      |\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "| Accuracy             | 99.7 ± 0.0 | -          | -          |\n",
      "| Balanced Accuracy    | 99.7 ± 0.0 | -          | -          |\n",
      "| F1                   | 99.7 ± 0.0 | 99.7 ± 0.0 | 99.7 ± 0.0 |\n",
      "| G-mean               | 99.7 ± 0.0 | -          | -          |\n",
      "| Precision            | 99.7 ± 0.0 | 99.6 ± 0.1 | 99.7 ± 0.0 |\n",
      "| Recall               | 99.7 ± 0.0 | 99.7 ± 0.0 | 99.6 ± 0.1 |\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "TASK 5\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "| Score                | Average    | Kat_1      | Kat_2      |\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "| Accuracy             | 91.5 ± 0.1 | -          | -          |\n",
      "| Balanced Accuracy    | 85.0 ± 0.2 | -          | -          |\n",
      "| F1                   | 91.3 ± 0.1 | 94.7 ± 0.1 | 78.0 ± 0.2 |\n",
      "| G-mean               | 84.3 ± 0.2 | -          | -          |\n",
      "| Precision            | 91.3 ± 0.1 | 93.6 ± 0.1 | 82.4 ± 0.3 |\n",
      "| Recall               | 91.5 ± 0.1 | 96.0 ± 0.1 | 74.1 ± 0.3 |\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "DATA[\"folds\"] = []\n",
    "rskf = RepeatedStratifiedKFold(n_splits=2, n_repeats=5, random_state=1410)\n",
    "\n",
    "stl=[]\n",
    "\n",
    "for t in range(np.max(DATA[\"category\"]+1)):\n",
    "    print(\"TASK\",t)\n",
    "    X = DATA[\"X\"][DATA[\"category\"] == t]\n",
    "    y = DATA[\"y\"][DATA[\"category\"] == t]\n",
    "\n",
    "    foldids = []\n",
    "    for fold_idx, (train, test) in enumerate(rskf.split(X, y)):\n",
    "        foldids.append((fold_idx,train,test))\n",
    "\n",
    "    #print(\"shapes X\",X.shape,\"y\", y.shape)\n",
    "    DATA[\"folds\"].append(foldids)\n",
    "    model1, scores1, pca = experiment(foldids, X, y, \n",
    "                                 LogisticRegression(max_iter=10000))\n",
    "    stl.append((model1,pca,scores1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border: 5px dashed red\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Domain Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shapes X (186477, 768) y (186477,)\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "| Score                | Average    | Kat_1      | Kat_2      | Kat_3      | Kat_4      | Kat_5      | Kat_6      |\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "| Accuracy             | 79.6 ± 0.1 | -          | -          | -          | -          | -          | -          |\n",
      "| Balanced Accuracy    | 85.7 ± 0.1 | -          | -          | -          | -          | -          | -          |\n",
      "| F1                   | 79.6 ± 0.1 | 96.7 ± 0.2 | 82.8 ± 0.4 | 72.8 ± 0.5 | 72.8 ± 0.2 | 87.2 ± 0.1 | 77.9 ± 0.1 |\n",
      "| G-mean               | 85.1 ± 0.1 | -          | -          | -          | -          | -          | -          |\n",
      "| Precision            | 80.2 ± 0.1 | 95.2 ± 0.3 | 75.4 ± 0.6 | 61.5 ± 0.7 | 73.1 ± 0.2 | 85.0 ± 0.2 | 83.8 ± 0.3 |\n",
      "| Recall               | 79.6 ± 0.1 | 98.2 ± 0.2 | 91.9 ± 0.5 | 89.3 ± 0.4 | 72.4 ± 0.4 | 89.5 ± 0.2 | 72.9 ± 0.3 |\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n"
     ]
    }
   ],
   "source": [
    "X = DATA[\"X\"]\n",
    "y = DATA[\"y\"]\n",
    "category = DATA[\"category\"]\n",
    "\n",
    "rskf = RepeatedStratifiedKFold(n_splits=2, n_repeats=5, random_state=1410)\n",
    "foldids = []\n",
    "for fold_idx, (train, test) in enumerate(rskf.split(X, y)):\n",
    "    foldids.append((fold_idx,train,test))\n",
    "    \n",
    "print(\"shapes X\",X.shape,\"y\", category.shape)\n",
    "\n",
    "domain_model, domain_scores, domain_pca = experiment(foldids, X, \n",
    "                                         category, LogisticRegression(max_iter=10000, class_weight='balanced'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border: 5px dashed red\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global model with category pred."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, f1_score, precision_score, recall_score, roc_auc_score\n",
    "from imblearn.metrics import geometric_mean_score\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def cls_max_predict(X_test):\n",
    "    ypred = np.array([stl[t][0].predict(stl[t][1].transform(X_test)) for t in range(6)])\n",
    "    return np.mean(ypred, axis=0) > 0.5\n",
    "\n",
    "def cls_weighted_predict(X_test):\n",
    "    ypred = np.array([stl[t][0].predict(stl[t][1].transform(X_test)) for t in range(6)])\n",
    "    return np.average(ypred, weights=[78,83,74,73,90,73], axis=0) > 0.4\n",
    "\n",
    "def cls_max_predict_raw(X_test):\n",
    "    ypred = np.array([stl[t][0].predict(stl[t][1].transform(X_test)) for t in range(6)])\n",
    "    return ypred\n",
    "\n",
    "def cls_predict(X_test):\n",
    "    Xd=domain_pca.transform(X_test)\n",
    "    domain_pred = domain_model.predict(Xd)\n",
    "    ypred = []\n",
    "    for i,dpred in enumerate(domain_pred):\n",
    "        model, model_pca, _ = stl[dpred] \n",
    "        xpca = model_pca.transform(X_test[i:i+1])\n",
    "        ypred.append(model.predict(xpca)[0])\n",
    "    return ypred\n",
    "        \n",
    "def experiment2(foldids, X, y, cback):\n",
    "\n",
    "    scores = {\n",
    "        'Accuracy': {'func': accuracy_score},\n",
    "        'Balanced Accuracy': {'func': balanced_accuracy_score},\n",
    "        'F1': {'func': f1_score},\n",
    "        'Precision': {'func': precision_score},\n",
    "        'Recall': {'func': recall_score},\n",
    "        'G-mean': {'func': geometric_mean_score}\n",
    "    }\n",
    "\n",
    "    for score_name, score_dict in scores.items():\n",
    "        scores[score_name][\"list\"] = []\n",
    "        scores[score_name][\"lab\"] = []\n",
    "\n",
    "    for fold,j in enumerate(foldids):\n",
    "        train = foldids[fold][1]\n",
    "        test = foldids[fold][2]\n",
    "        xin, yin = X[train], np.array(y[train])\n",
    "        \n",
    "        y_pred = cback(X[test])\n",
    "        \n",
    "        for score_name, score_dict in scores.items():\n",
    "            if score_name in [\"F1\",\"Precision\",\"Recall\"]:\n",
    "                scorvaln = score_dict['func'](y[test], y_pred, average=None)\n",
    "                score_dict['lab'].append(scorvaln)\n",
    "                scorval = score_dict['func'](y[test], y_pred, average=\"weighted\")\n",
    "                score_dict['list'].append(scorval)\n",
    "                print(score_name, scorval, scorvaln)  \n",
    "            else:\n",
    "                scorval=score_dict['func'](y[test], y_pred)\n",
    "                score_dict['list'].append(scorval)\n",
    "                print(score_name, scorval)\n",
    "        print(\" \")\n",
    "\n",
    "    clear_output()\n",
    "    for score_name, score_dict in scores.items():\n",
    "        score_dict['avg'] = np.mean(score_dict['list'])\n",
    "        score_dict['std'] = np.std(score_dict['list'])\n",
    " \n",
    "    # Print stats\n",
    "    numlabels = scores[\"F1\"][\"lab\"][0].shape[0]\n",
    "    scores[\"F1\"][\"lab\"][0].shape[0] \n",
    "    head = \"| %-20s | %-10s |\" +  numlabels * \" %-10s |\" \n",
    "    headv = [\"Score\", \"Average\"]\n",
    "    headv.extend([\"Kat_\"+str(i+1) for i in range(numlabels)])\n",
    "    row=head % tuple(headv)\n",
    "    print(\"+\"*len(row))\n",
    "    print(row)\n",
    "    print(\"+\"*len(row))\n",
    "    for score_name, score_dict in sorted(scores.items()) :\n",
    "        headv = [score_name, np.mean(score_dict['list'])*100, np.std(score_dict['list'])*100]\n",
    "        for i in range(numlabels):\n",
    "            if score_name in [\"F1\",\"Precision\",\"Recall\"]:\n",
    "                head = \"| %-20s | %4.1f ± %3.1f |\" + numlabels* \" %4.1f ± %3.1f |\"\n",
    "                vals = [v[i] for v in scores[score_name][\"lab\"]]\n",
    "                headv.append(np.mean(vals)*100)\n",
    "                headv.append(np.std(vals)*100)\n",
    "            else:\n",
    "                head = \"| %-20s | %4.1f ± %3.1f |\" + numlabels * \" %-10s |\" \n",
    "                headv.append(\"-\")\n",
    "        print(head % tuple(headv))\n",
    "    print(\"+\"*len(row))\n",
    "    return scores, pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 169.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shapes X (186477, 768) y (186477,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.8906895183346025\n",
      "Balanced Accuracy 0.8738772228942854\n",
      "F1 0.890706375178059 [0.9199887  0.82753486]\n",
      "Precision 0.8907234951046911 [0.92023432 0.82705902]\n",
      "Recall 0.8906895183346025 [0.9197432  0.82801124]\n",
      "G-mean 0.8726727407962598\n",
      " \n",
      "Accuracy 0.8902378858405371\n",
      "Balanced Accuracy 0.8740442812747655\n",
      "F1 0.8903299506300135 [0.919563  0.8272626]\n",
      "Precision 0.8904298659660493 [0.92090929 0.82467358]\n",
      "Recall 0.8902378858405371 [0.91822063 0.82986793]\n",
      "G-mean 0.8729271766294437\n",
      " \n",
      "Accuracy 0.8901210866697412\n",
      "Balanced Accuracy 0.8736792558319861\n",
      "F1 0.8901881059739745 [0.9195088 0.8269338]\n",
      "Precision 0.8902592631467223 [0.92048511 0.82505225]\n",
      "Recall 0.8901210866697412 [0.91853456 0.82882395]\n",
      "G-mean 0.8725270445120594\n",
      " \n",
      "Accuracy 0.8908063236019649\n",
      "Balanced Accuracy 0.8742422345763926\n",
      "F1 0.8908483410282234 [0.92004304 0.82786372]\n",
      "Precision 0.8908920018230735 [0.92065762 0.82667567]\n",
      "Recall 0.8908063236019649 [0.91942927 0.8290552 ]\n",
      "G-mean 0.8730736603814897\n",
      " \n",
      "Accuracy 0.8904535655680563\n",
      "Balanced Accuracy 0.8735410651778874\n",
      "F1 0.8904635080996898 [0.9198248  0.82712163]\n",
      "Precision 0.8904735416496804 [0.91996922 0.82684173]\n",
      "Recall 0.8904535655680563 [0.91968042 0.82740171]\n",
      "G-mean 0.8723217025699785\n",
      " \n",
      "Accuracy 0.8904845663785153\n",
      "Balanced Accuracy 0.8743973812452943\n",
      "F1 0.8905837749318338 [0.91973431 0.82769444]\n",
      "Precision 0.8906921527351259 [0.92118979 0.82489657]\n",
      "Recall 0.8904845663785153 [0.91828342 0.83051134]\n",
      "G-mean 0.8732953658976153\n",
      " \n",
      "Accuracy 0.890206887675758\n",
      "Balanced Accuracy 0.8735876304050934\n",
      "F1 0.890253094942496 [0.91959819 0.82694616]\n",
      "Precision 0.8903012673833978 [0.92027038 0.82564812]\n",
      "Recall 0.890206887675758 [0.91892698 0.82824828]\n",
      "G-mean 0.8724102770111375\n",
      " \n",
      "Accuracy 0.8907312469164933\n",
      "Balanced Accuracy 0.874350801684055\n",
      "F1 0.8907944592678206 [0.91996103 0.82787051]\n",
      "Precision 0.890861395461057 [0.92088707 0.82608402]\n",
      "Recall 0.8907312469164933 [0.91903686 0.82966475]\n",
      "G-mean 0.8732081544432301\n",
      " \n",
      "Accuracy 0.8914295520114973\n",
      "Balanced Accuracy 0.874654915501095\n",
      "F1 0.8914379288329449 [0.92054098 0.82865316]\n",
      "Precision 0.89144637151626 [0.92066383 0.82841478]\n",
      "Recall 0.8914295520114973 [0.92041816 0.82889167]\n",
      "G-mean 0.8734568946779143\n",
      " \n",
      "Accuracy 0.8895085694673845\n",
      "Balanced Accuracy 0.8732835056941879\n",
      "F1 0.8896101443677675 [0.91901707 0.82616766]\n",
      "Precision 0.8897211498155903 [0.9204932  0.82333356]\n",
      "Recall 0.8895085694673845 [0.91754568 0.82902133]\n",
      "G-mean 0.872161075430089\n",
      " \n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "| Score                | Average    | Kat_1      | Kat_2      |\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "| Accuracy             | 89.0 ± 0.0 | -          | -          |\n",
      "| Balanced Accuracy    | 87.4 ± 0.0 | -          | -          |\n",
      "| F1                   | 89.1 ± 0.0 | 92.0 ± 0.0 | 82.7 ± 0.1 |\n",
      "| G-mean               | 87.3 ± 0.0 | -          | -          |\n",
      "| Precision            | 89.1 ± 0.0 | 92.1 ± 0.0 | 82.6 ± 0.1 |\n",
      "| Recall               | 89.0 ± 0.0 | 91.9 ± 0.1 | 82.9 ± 0.1 |\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n"
     ]
    }
   ],
   "source": [
    "X = DATA[\"X\"]\n",
    "y = DATA[\"y\"]\n",
    "\n",
    "\n",
    "rskf = RepeatedStratifiedKFold(n_splits=2, n_repeats=5, random_state=1410)\n",
    "foldids = []\n",
    "for fold_idx, (train, test) in tqdm(enumerate(rskf.split(X, y)), total=rskf.get_n_splits()):\n",
    "    foldids.append((fold_idx,train,test))\n",
    "    \n",
    "print(\"shapes X\",X.shape,\"y\", y.shape)\n",
    "\n",
    "gscr, gpca = experiment2(foldids, X, y, cls_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "pipe_domain = Pipeline([('pca', domain_pca), ('head', domain_model)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pickle models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# SAVE\n",
    "with open('domain_cls.pickle', 'wb') as handle:\n",
    "    pickle.dump(pipe_domain, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_model_pipe = []\n",
    "for i,elem in enumerate(stl):\n",
    "    with open(f'model_{i}.pickle', 'wb') as handle:\n",
    "        p = Pipeline([('pca', elem[1]), ('head', elem[0])])\n",
    "        domain_model_pipe.append(p)\n",
    "        pickle.dump(p, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Un-pickle models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle5 as pickle\n",
    "# load\n",
    "with open('../../pickles/models/domain_cls.pickle', 'rb') as handle:\n",
    "    pipe_domain = pickle.load(handle)\n",
    "    \n",
    "domain_model_pipe = []\n",
    "for i in range(6):\n",
    "    with open(f'../../pickles/models/model_{i}.pickle', 'rb') as handle:\n",
    "        p=pickle.load(handle)\n",
    "        domain_model_pipe.append(p)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cls_predict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-537d6c1da7af>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcls_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'cls_predict' is not defined"
     ]
    }
   ],
   "source": [
    "cls_predict(X[0:2]), y[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved: Model(tag=\"big_puppy:wo3hgzkt6wg6itgm\")\n"
     ]
    }
   ],
   "source": [
    "import bentoml\n",
    "\n",
    "from sklearn import svm\n",
    "\n",
    "saved_model = bentoml.sklearn.save_model(\"big_puppy\", bp)\n",
    "print(f\"Model saved: {saved_model}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BENTO models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved: Model(tag=\"domain_cls:4ljhzhc27sjskdg5\")\n"
     ]
    }
   ],
   "source": [
    "import bentoml\n",
    "\n",
    "from sklearn import svm\n",
    "\n",
    "saved_model = bentoml.sklearn.save_model(\"domain_cls\", pipe_domain, signatures={\n",
    "        \"predict\": {\"batchable\": True, \"batch_dim\": 0},\n",
    "        \"predict_proba\": {\"batchable\": True, \"batch_dim\": 0},\n",
    "    })\n",
    "print(f\"Model saved: {saved_model}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved: Model(tag=\"model_0:4zhlxcc27sxigdg5\")\n",
      "Model saved: Model(tag=\"model_1:426ssdc27s5j2dg5\")\n",
      "Model saved: Model(tag=\"model_2:44j2ors27sxkedg5\")\n",
      "Model saved: Model(tag=\"model_3:45jvync27svgwdg5\")\n",
      "Model saved: Model(tag=\"model_4:46tsvgs27s3rgdg5\")\n",
      "Model saved: Model(tag=\"model_5:476kxhc27sbbcdg5\")\n"
     ]
    }
   ],
   "source": [
    "for i in range(6):\n",
    "    saved_model = bentoml.sklearn.save_model(f\"model_{i}\", domain_model_pipe[i], signatures={\n",
    "        \"predict\": {\"batchable\": True, \"batch_dim\": 0},\n",
    "        \"predict_proba\": {\"batchable\": True, \"batch_dim\": 0},\n",
    "    })\n",
    "    print(f\"Model saved: {saved_model}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check rest api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"result\":1,\"result_proba\":[0.12162435873841593,0.8783756412615841],\"domain\":5,\"domain_proba\":[3.7271139151509206e-05,0.2524385728679994,0.0001431362617570179,0.011453838931336738,0.350516113051998,0.38541106774775735],\"similar_articles\":[{\"text\":\"LUDHIANA: A 22-year-old man was sentenced to 10-year rigorous imprisonment for raping a minor in 2015. The court of additional sessions judge Karamjit Singh Sular also imposed a fine of Rs 40,000 on the convict and in default of payment of fine, he will have to further undergo a rigorous imprisonment of two years.On November 12, 2015, police had booked the 22-year-old accused under section 376 ( rape ) of Indian Penal Code (IPC) and section 3 and 4 of Protection of Children from Sexual Offences Act (POCSO).As per prosecution, a police party led by sub-inspector Suresh Kumar reached the place of the incident after receiving information about the accused. The accused was arrested from near a gurdwara in Meherban area. Later, the father of the rape survivor recorded his statement with the police. According to the father, his elder daughter, aged 9, had gone to a gurdwara in the village to play. A student of Class V, the father said, the daughter did not return for some time. At around 2.30 pm, he along with his wife went to the gurdwara to locate her. On reaching there, they heard screams from a room built on a vacant plot in front of the gurdwara. Both went inside and saw the 22-year-old accused raping his daughter. The father of the rape survivor knew the accused as he used to live at the back of their house. The accused pushed the complainant and fled from the spot.The rape survivor said she was playing on the street when the accused lured her with money. Then, he took her to a room and tried to rape her. Later, police arrested the accused and registered a case against him. Thereafter, they produced a challan against him in the court of law. During the trial of the case, he pleaded innocence and claimed false implication.District attorney Ravinder Abrol said the prosecution pleaded for severe punishment to the accused based on the prosecution evidence including a statement of prosecutrix, complainant, other witnesses and medical examination reports. The court turned down the plea of the accused and sentenced him under sections 376 of the IPC and section 4 of POSCO.\",\"label\":0,\"distance\":0.6646488904953003},{\"text\":\"AP reported:California s elected Democrats had tough words for President Donald Trump and the GOP Congress on Saturday, urging their party s fired-up activists to work against the 14 Republicans in the state s congressional delegation.The party s leaders blasted Trump s alleged ties to Russia and presented California as the epicenter of liberal resistance to the president. The world, literally the world, is counting on all of you, counting on California to reject Trump s deception and destructiveness,  said Lt. Gov. Gavin Newsom, who is among a crowded field of Democrats running for governor next year.U.S. Sen. Kamala Harris, often mentioned as a potential candidate for president in 2020, accused Trump of putting  Russia first, America second. In a sign of the vigor of the party s distaste for the president, outgoing party Chair John Burton, a longtime Democratic lawmaker and powerbroker known for his blunt and profane manner, extended two middle fingers in the air as the crowd cheered and joined him. F  Donald Trump,  he said:Outgoing @ca_dem chair @Johnburton gets standing O w final words to his party, finger upraised:  F@ck Donald Trump!  pic.twitter.com/VIqNQlhDJc  Carla Marinucci (@cmarinucci) May 20, 2017And we though Tom Perez was bad!\",\"label\":1,\"distance\":0.7604187726974487},{\"text\":\"There are some people you probably shouldn t cross. Donald Trump is one, and conservative author and political analyst Ann Coulter is the other one Conservative columnist Ann Coulter flew into a fit of fury Saturday after Delta Airlines booted her from her reserved  Comfort+  seat   which comes with 3 additional inches of legroom   and gave it to another passenger.In a two-hour tweeting tantrum,she quoted her exchange with a flight attendant:  Why are you taking me out of the extra room seat I specifically booked?  she asked.Their answer, she said, was  I don t know. Before Coulter posted a picture of the woman Delta gave her extra-legroom reserved seat to, she tweeted this:Suckiest @Delta moved me from my PRE-BOOKED SEAT & gave it to some woman, not elderly, child, or sick. I have pictures so don t lie, @Delta!  Ann Coulter (@AnnCoulter) July 16, 2017But at least @Delta was nice @ it, summarily snatching my ticket from my hand & ordering me to move w/o explanation, compensation or apology  Ann Coulter (@AnnCoulter) July 16, 2017The 6-foot-tall Coulter, who is 55, tweeted a picture of the woman who got her aisle seat on the flight from LaGuardia to Florida, noting,  Delta didn t give my extra room seat to an air marshal or tall person.   NYP.@Delta didn t give my extra room seat to an air marshall or tall person. Here s the woman given my PRE-BOOKED seat: pic.twitter.com/iDNB8xXXOd  Ann Coulter (@AnnCoulter) July 15, 2017The long-legged Coulter, who still appeared to furious about Delta s decision to boot her from her reserved seat with extra legroom, tweeted again to Delta about the  daschund-legged woman  who they gave her seat to:So glad I took time investigate the aircraft & PRE-BOOK a specific seat on @Delta, so some woman could waltz at the last min & take my seat.  Ann Coulter (@AnnCoulter) July 15, 2017Hey @Delta, if it was so important for the dachshund-legged woman to take my seat, she should have BOOKED THE SEAT IN ADVANCE. Like I did.  Ann Coulter (@AnnCoulter) July 16, 2017The sharp-tongued conservative firebrand continued to rip into Delta Airlines in a series of tweets criticizing their customer service:.@Delta motto: \\\\\"How can we make your flight more uncomfortable?\\\\\"  Ann Coulter (@AnnCoulter) July 16, 2017.@Delta employee questionnaire: What is your ideal job: Prison guard? Animal handler? Stasi policeman? All of the above: HIRED!  Ann Coulter (@AnnCoulter) July 16, 2017A Delta spokesman said it appeared Coulter was in the same extra-room row, just in a different seat. But he promised to look into it.\",\"label\":1,\"distance\":0.7604187726974487},{\"text\":\"By Marty McCarthy Updated February 07, 2017 10:42:33 Map: Brisbane 4000 \\\\nA Queensland meat processor predicts the price of beef could fall by as much as 30 per cent if the US starts exporting beef to Australia again. \\\\nAustralia has not accepted imports of beef products from the US since 2001, following outbreaks of mad cow disease around the world. \\\\nHowever, the Federal Government is currently assessing the biosecurity risk of uncooked beef imports , and trade could resume by as early as July if it is deemed to be safe. \\\\nFood Standards Australia New Zealand recently assessed the mad cow risk of US beef was very low. \\\\n\\\\\"It is not assured US beef will come to Australia but it is highly likely in the back half of the year,\\\\\" said Terry Nolan from Nolan Meats at Gympie near the Sunshine Coast. \\\\nUS beef is traditionally more expensive than local meat, and therefore American exporters don\\'t think it is worth selling in Australia. \\\\nHowever, a shortage of cattle in Australia means local prices are higher than usual, providing an incentive for US exporters. \\\\nMr Nolan said if beef imports from the US resume, beef prices in Australia would fall. \\\\n\\\\\"Australia has a depleted herd and we\\'re seeing record cattle prices, whereas the US has large inventories of cold stored beef,\\\\\" he said. \\\\n\\\\\"They have an increasing herd and a decreasing price of their live cattle, so I think it is almost inevitable we will see US beef come to Australia. \\\\n\\\\\"I think that could severely depress the price of livestock in Australia and could be detrimental to the producing sector.\\\\\" \\\\nWhile Mr Nolan predicted the trade would have a negative impact on beef farmers, he said consumers would benefit. \\\\n\\\\\"I think we could see an easing of [beef prices] by as much as 20 to 30 per cent, which would be welcomed by consumers,\\\\\" he said. \\\\nAustralia\\'s Department of Agriculture said it expects the US to only export 100 tonne of beef per year, focussing on specialist cuts, and is therefore not a big risk to Australian farmers. \\\\n\\\\\"I think that number is underestimated because there could be a wide range of chilled and frozen products coming in,\\\\\" Mr Nolan said. \\\\n\\\\\"It could be high quality table meats and products that are suitable for manufacturing, such as grinding and the food manufacturing sector.\\\\\" \\\\nJoel Haggard, the senior vice president for the Asia Pacific region of US Meat Export Federation, said it was too early to know how significant US beef exports to Australia could become. \\\\n\\\\\"While our organization and our exporters have received enquiries from Australian buyers about US beef, we anticipate demand will primarily be for specialty and premium products,\\\\\" he said. \\\\n\\\\\"The nature and scope of that demand will also be shaped by final import conditions which have yet to be determined.\\\\\" \\\\nBlair Angus, a grazier at Clermont in central Queensland, said he does not think US imports would threaten the viability of Australian producers. \\\\n\\\\\"I am sure producers will be concerned about it and it is something we shouldn\\'t take lightly but we have to have faith in our authorities to implement these types of trade,\\\\\" he said. \\\\n\\\\\"I don\\'t see a lot of product coming in here unless it is high end specialist product.\\\\\" \\\\nFurthermore, Mr Angus said the lure of the Australian market to US exporters could only be short lived, if the price of Australian beef starts to drop. \\\\n\\\\\"I think once things stabilise number wise there won\\'t be that attraction for the US to export to Australia.\\\\\" Photo: Australia\\'s Department of Agriculture expects the US to only export 100 tonne of beef per year if trade to Australia resumes (ABC Rural: Caddie Brain) Free trade critical, but food safety should not be jeopardised. \\\\nDespite the concerns, Mr Nolan said two-way trade with the US was critical to the profitability of Australia\\'s beef sector. \\\\n\\\\\"Australia is a trading nation, we have huge agricultural resource capacity and too small a population to absorb all the production,\\\\\" he said. \\\\n\\\\\"So we support free trade and I say that loud and clear, the future of our red meat industry is in international market access.\\\\\" \\\\nThat sentiment is shared by Mr Angus, who said Australian authorities should use the opportunity to reduce the cost of exporting Australian product to the US. \\\\n\\\\\"We do need this as a nation but it has to be bi-lateral, the same systems must be imposed on their product coming in as our product going out,\\\\\" he said. \\\\n\\\\\"I see it as an opportunity to negotiate.\\\\\" \\\\nThe US does not have the same level of food safety and export protocols as those imposed on Australian producers. \\\\nAustralia has the Australian Livestock Production Assurance program to demonstrate animals are free of disease, the National Livestock Identification System for the traceability of cattle and the National Vendor Declaration system. \\\\nThe US Meat Export Federation said it was awaiting a final determination of Australia\\'s biosecurity review, but was confident its product was safe to export.\",\"label\":0,\"distance\":0.8035925030708313},{\"text\":\" \",\"label\":1,\"distance\":0.8515824675559998},{\"text\":\"On Sunday, on CNN s State of the Union, Trump campaign spokesman Stephen Miller got into a bizarre argument with the show s host Jake Tapper.Tapper questioned whether Trump s recent attack on Ted Cruz s wife was befitting of a person running for president. In an apparent attempt to bring the GOP primary election to its rock bottom, Trump recently took to Twitter where he retweeted a photo that attacked Cruz s wife. The image showed two photos, one of Cruz s wife and one of Trump s wife. The image had a weird threat written on it, which said,  No need to spill the beans. The images are worth a thousand words. Miller defended the retweet earlier in the week during an earlier interview on CNN.He wanted to evade the question at all costs, so he decided to try and steer the conversation towards immigration.Tapper wasn t having it. He pressed the issue, and that s when Miller got a little erratic. Miller said: We get wrong what we re mad about in America! We don t get mad when Americans are murdered by illegal immigrants. We don t get mad when people have their jobs taken by cheaper foreign workers here on visa programs. We don t get mad when entire cities are crushed by our trade policies that send jobs overseas. Tapper wasn t going to let Miller off the hook that easy. He continued to press Miller, stating that he doesn t want to know why Miller was being so evasive. You want to get into an argument? Then we ll get into an argument!  Miller exclaimed.  He just accused me of standing up for sexism, and that is absolutely inappropriate! Miller continued, saying: I said in that interview that it is a trivial issue to be debating retweets when it is a fact you have Americans dying every single day as a result of immigration policies! Americans all over this country see their communities destroyed by uncontrolled migration. The irony of the interview is that Miller is using evasion tactics that Cruz is famous for. When pressed on social issues, Cruz often jumps to a completely different topic. This was best exemplified when reporters asked Cruz about his stance on LGBT issues, particularly his lack of support for gay marriage. Cruz, then inexplicably went into a rant about the dangers of the Islamic State.You can watch the segment below.https://www.youtube.com/watch?v=MaKL5HFa4ZAFeatured image from video screenshot \",\"label\":1,\"distance\":0.9692625403404236},{\"text\":\"(CNN) — Puebla is the fourth-largest city in Mexico , just a two-hour drive from the capital (it\\'s 67 miles, but there\\'s no accounting for Distrito Federal traffic).  Yet it often gets tacked on as a day trip from Mexico City instead of treated like a destination in its own right. That\\'s all about to change, though, as a slate of new hotels and structural improvements make this vibrant city easier to travel to than ever.  Following an earthquake in Puebla in September 2017, many of the city\\'s most famous attractions have gotten fixed up and are ready to host visitors again--which means that contributing to the city\\'s economy is more vital than ever.  What to know  The narrow streets of central Puebla are lined with colorful row houses. Getty Images  First things first: Puebla is the capital of Puebla state, and people from there are called poblanos. If you\\'re not up for driving, you can fly to Puebla directly from several US cities, including Dallas and Houston. Puebla\\'s previous governor sunk a lot of money into projects like new bridges, trains and hotels, many of which are now completed and ready to handle visitors.  Within Mexico, Puebla has a reputation for strong religious roots. The Spanish built the city at the intersection of two rivers and dubbed it their new Jerusalem, and there seems to be a stunning church on every corner. Locals will tell you there are 365 -- one for every day of the year.  And Puebla is the city attached to Cinco de Mayo, when the Mexican army defeated French forces on May 5, 1862 in the Battle of Puebla. All that and Puebla\\'s city center is a UNESCO World Heritage site, too. Talk about crossing a lot off your list at once.  What to do  Talavera pottery, like Champagne, is a product unique to its region. Getty Images  First, you\\'ll want to get started on a few of those 365 churches. While you could easily drive yourself crazy trying to see them all, you\\'re best off focusing on a few of the most celebrated.  Start at the central Church of Santo Domingo, which is most notable for its over-the-top Baroque-style Capilla del Rosario, which drips with so much gold you\\'ll wonder how it doesn\\'t come crashing down to the floor. Then stop into the Templo de San Francisco, a bright-yellow structure that pays homage to local hero Blessed Sebastian of Aparicio (who happens to be a step away from sainthood), and Puebla Cathedral, with its stunning black limestone front and stunning gold organ, which is the second-tallest church in the country.  Related content The most beautiful small towns in Mexico  As you\\'ll see from its church interiors, Puebla is known for its Baroque architecture, which made it a logical home for the International Museum of the Baroque , which opened in 2016. The museum -- which looks more like the Guggenheim Bilbao on the outside with minimalist sweeps of white and silver -- gives useful background on Baroque art and shows off some classic examples.  Beyond art, history buffs will want to visit the Biblioteca Palafoxiana, a 17th-century book collection and reading room that is widely considered the first public library in Mexico.  Talavera pottery is one of Puebla\\'s proudest exports. The mud is baked, glazed, and hand-painted, most traditionally in blue and white patterns. It\\'s so strongly associated with Puebla that even the local Starbucks has Talavera-style decor.  Many stores in town sell a few items, but your best bet is to head to Uriarte , the shop that is home base to the country\\'s largest Talavara producer -- you\\'ll have a lot of options, from tableware and vases to individual tiles and custom requests.  Church of Santo Domingo, Avenida 5 de Mayo, Centro Histórico, 72000 Puebla  Templo de San Francisco, Avenida 14 Oriente 805, Barrio del Alto, 72290 Puebla, +52 222 235 1659  Puebla Cathedral, Calle 16 de Septiembre, Centro, 72000 Puebla, +52 222 232 3803  International Museum of the Baroque , Atlixcáyotl 2501, Reserva Territorial Atlixcáyotl, Corredor Comercial Desarrollo Atlixcayotl, Puebla, +52 222 326 7130  Biblioteca Palafoxiana , Calle 5 Oriente 5, Centro, 72000 Puebla, +52 222 2323483 x118  Uriarte , Avenida 4 Poniente 911, 72000 Puebla 52 (222) 232 1598  What to eat  Many restaurants in Puebla claim to have the world\\'s best mole, so you\\'ll just have to try them all. Getty Images  Some of Mexico\\'s most beloved foods have their origins in Puebla, most notably mole poblano. The spicy chocolate sauce was reportedly invented here by a woman who was trying to clean out everything in her pantry.  Nearly every restaurant in town has their own mole poblano, so you\\'ll have to sample a few different ones -- for research, of course. One solid option is El Mural de los Poblanos , which is known for its modern takes on Puebla classics -- besides the mole, try tacos arabes (meat and cheese wrapped in pita bread instead of corn tortillas, inspired by Lebanese immigration to the area) and salad with nopales, a local cactus (it\\'s on the Mexican flag).  And if your sweet tooth still isn\\'t satisfied, head to Calle 6 Oriente, also known as Calle de Los Dulces -- Candy Street. This street is lined with small, locally owned candy stores that sell some of Puebla\\'s most beloved sweets, including camotes (cigar-shaped rolls of colorful coconut), candied citrus rinds and the small round tortitas de Santa Clara. Most of these will be hard to find elsewhere in Mexico, so stock up -- in particular, La Gran Fama will wrap your souvenirs up in white paper boxes tied with ribbon, making them perfect for gifts back home.  Related content Visiting Mexico City? Insiders share tips  For an upscale dinner, head to the Casa Reyna restaurant inside the boutique hotel of the same name. If you can, request a table in the middle of the restaurant underneath the open roof. The menu is a mix of American favorites and Mexican standards, so take an opportunity to try a local specialty like tuna with sauce of jamaica (hibiscus) flowers, chalupas (another dish Puebla lays claim to creating) or guava-and-cheese souffle.  If you\\'re in town during the fall, Pueblan specialty chiles en nogada (peppers stuffed with ground meat, fruit and nuts all covered in a milky sauce) is a traditional thing to eat around Independence Day on September 16.  El Mural de los Poblanos , Calle 16 de Septiembre 506, Centro, 72000 Puebla, +52 222 242 0503  Dulceria La Gran Fama , Avenida 6 Oriente 208 Centro 72000 Puebla +52 222 242 3316  Casa Reyna , Privada 2 Oriente 1007, Centro, 72000 Puebla, +52 222 232 0032  Time for a siesta  The Rosewood Puebla opened its doors in spring 2017. Courtesy Rosewood  Puebla is having a bona fide hotel boom. The latest notable arrival in town is the Rosewood Puebla, an outpost of the posh hotel chain with thoughtful touches like Talavera tilework and hand-hammered silver that manages to still feel like a comfy guest house and not a museum. The brand also has outposts in Playa del Carmen and San Miguel de Allende, making it super-tempting to extend your Mexico travels.  Opening in October 2017 is the Hotel Cartesiano , a 78-room boutique property that\\'s part of the Leading Hotels of the World family. It\\'s inside two historic buildings -- one was originally a home, the other a tile factory that still has many original pieces incorporated throughout the design. Because of the unique spaces next door to each other, each room is slightly different in shape and size, but they\\'re unified by an elegant, neutral design palette.  For a classic Puebla experience, it\\'s hard to go wrong with the Hotel La Purificadora , which was the city\\'s first major design hotel and is part of the upscale Grupo Habita portfolio. Its central location on the beautiful Parque San Francisco (hang out there during the day, but avoid at night when it turns into teenage makeout central) makes it convenient to nearly everything in town, while its trendy bar and restaurant are the places to be seen on a weekend night.  Rosewood Puebla , Calle 10 Norte 1402, Barrio del Alto, 72000 Puebla, +52 222 122 2300  Hotel Cartesiano , Calle 3 Oriente. 410, Centro, 72000 Puebla  Hotel La Purificadora , Callejon de la 10 Norte 802, Paseo San Francisco, Barrio El Alto, 72000 Puebla, +52 800 309 1920  Keep on going  Cholula is a perfect day trip from Puebla. Pixabay  Just a few miles from Puebla is the town of Cholula, which is known for having the largest pyramid in Latin America -- yes, bigger than Giza and Chichen Itza, but with significantly fewer people. Much of the Pirámide Tepanapa is obscured beneath a hill, with the vivid yellow Iglesia de Nuestra Señora de los Remedios (Church of Our Lady of Remedies), a popular pilgrimage site for people seeking cures for diseases or chronic ailments, at its peak. The church is beautiful, but you\\'ll want to make sure you turn your camera outward for panoramic shots of the countryside.  There is now a nice \\\\\" tourist train \\\\\" that runs between Puebla and Cholula, dropping you off just at the base of the pyramid. However, the train still has limited hours, so you\\'ll need to plan ahead. Most days, there are three departures from Puebla in the morning and three returns, each about 40 minutes long, from Cholula in the late afternoon and evening.  If you prefer more flexibility, you may be better off catching a local bus (there are direct buses from Puebla\\'s Plaza Pedrera throughout the day) or taking an Uber one or both ways.  Beyond the pyramid, there are quite a few fun things to see and do in Cholula. If Talavera is on your wish list, head to the Santa Caterina factory and shop, one of the official government license holders to sell the products. Their range is huge, from dishes to candleholders to jewelry and even decorative eggs a la Faberge.  When lunchtime rolls around, don\\'t park in a restaurant. Instead, walk through the meandering Mercado Municipal Cosme del Razo, a multi-street series of stalls where you can sample a local Cholula craft beer, custom-order tacos to be cooked in front of you, buy a traditional embroidered dress or shirt, and pick up handmade wooden toys and crafts as souvenirs -- all in a single short stroll. Good news for a hot day: the market is mostly covered, so you\\'ll be able to avoid a sunburn.  Tourist Train Station : Calle 11 Norte 11, El Tamborcito, Puebla  Pirámide Tepanapa: Calle 8 Poniente 2, San Miguel, Centro, 72760 San Andrés Cholula, +52 228 194 5667  Talavera Santa Caterina : Prolongación 14 Oriente 1402 San Andrés, Cholula, +52 222 247 66 14\",\"label\":0,\"distance\":0.9866335391998291},{\"text\":\"Democrats want to spend a whopping $2 billion on zika virus prevention. Republicans are demanding more controls so Rubio is calling them stingy with federal dollars. Is this guy really a Republican? Just two months after running as one of the conservative candidates in the GOP presidential race, Sen. Marco Rubio is now embracing Democrats  calls to open the federal checkbook and dole out billions of dollars in money to combat the Zika virus   and tacking it onto the debt.Mr. Rubio, whose home state of Florida is at risk of a serious outbreak, is co-sponsoring legislation to fully fund President Obama s nearly $2 billion emergency spending request, and blasted his fellow Republicans for being too stingy by demanding more proof and more controls.And Mr. Rubio, who is finishing out his first term then ditching the Senate at the end of this year, said if the new spending can be offset, that s fine. But he s also fine with tacking it onto the debt and leaving it for others to pay for.  In times of public health emergencies, just like natural disasters, we shouldn t delay acting while we figure out and try to agree on what we re going to cut from other parts of the budget,  he said in a floor speech last week.Mr. Rubio gives Democrats political cover as Congress prepares to fight this week over the mosquito-borne Zika virus, which health experts say hasn t had a breakout in the U.S. yet, but fear one is looming as the summer heats up.The House GOP released its own plan Monday that would allocate $622 million toward Zika, taking the money from existing Ebola money and elsewhere.Read more: WT\",\"label\":1,\"distance\":1.0058404207229614},{\"text\":\"The shooter at the Congressional baseball practice has been identified. His name is James Hodgkinson The 66-year old white male from Illinois is a Bernie Sanders supporter. His Facebook and Twitter accounts are full of anti-Trump/pro-Bernie Sanders posts and pictures:UPDATE: PRESIDENT TRUMP just announced that Hodgkinson has died from his injuries. His Facebook page and Twitter have been inundated with angry conservatives who are so sick of the vile and hateful rhetoric from the left. He s a huge leftist who clearly hastes President Trump calling him a  traitor  on Facebook:This man clearly represents Trump Derangement Syndrome The left is still so angry that Trump was elected. It s sick and twisted!From the shooter s Facebook page:We just reported last weekend on protests across the country that got violent and even saw Antifa attacking a police horse with a weapon:A  female  Antifa member was arrested after using a flag pole w/ a silver nail at the end to stab a police horse in the neck during a riot. pic.twitter.com/yBMThRyUdn  /pol/ News Forever (@polNewsForever) June 12, 2017 The violence on social media and on the streets must stop. Conservatives have been attacked starting with the Trump campaign rallies and are still being attacked. Supporters of our president are even afraid to wear hats or t-shirts with his slogans. Anyone who wears a Trump item could be a target of violence.Leaders of the Democrat party need to stop with the hateful rhetoric NOW! Tom Perez WE RE TALKING TO YOU!\",\"label\":1,\"distance\":1.0058404207229614},{\"text\":\"The bashing of Donald Trump is getting so old and tiresome. People with common sense know the truth and know what the left is trying to do. It s the same old playbook of demonizing what you don t like repeatedly. The problem is that Americans are finally wising up to this Alinsky strategy. You d think the liberals are all coordinating their talking points .hummm  Billy Crystal bashed Trump during his eulogy of Ali in a line similar to Clinton s speech on Tuesday: life is best when you build bridges between people, not walls. Do you think for one minute that Trump would have gotten where he is if he d not reached out to people and built bridges literally and figuratively? The reason Trump wants to build a literal wall with Mexico is that,  without borders, we don t have a country . We can certainly reach out to others but Trump knows open borders DO NOT WORK! Just take a look at Europe and the EU! What a mess! Trump has said he wants LEGAL IMMIGRATION and doesn t want ILLEGAL IMMIGRATION! He s protecting the people of America and that s putting America first!The problem with Billy Crystal s swipe at Trump is that he isn t practicing what he preaches. Anyone who knows Los Angeles knows that the homes have gates and walls. Well, Billy Crystal has walls and a fence surrounding his home people in glass houses!It was easy to get photos above of the fence and wall around Billy Crystal s home but we can t just walk onto his property uninvited. Isn t that the same as people walking over our border illegally?Comedian Billy Crystal gave an emotional tribute during Muhammad Ali s funeral on Friday, but may have sneaked in a low-key dig at Republican presidential nominee Donald Trump. Crystal, a friend of The Champ s for more than 40 years, said at the end of his eulogy for the boxer in the KFC Yum! Center in Louisville, Kentucky that Ali  taught us that life is best when you build bridges between people, not walls.  That line Crystal said sounds similar to what Hillary Clinton said during her victory speech on Tuesday.  We believe that cooperation is better than conflict, unity is better than division, empowerment is better than resentment, and bridges are better than walls,  the Democratic presidential candidate front-runner said. Read more: Daily Mail\",\"label\":1,\"distance\":1.0311551094055176}]}'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "requests.post(\n",
    "     \"http://localhost:3000/predict\",\n",
    "     headers={\"content-type\": \"application/json\"},\n",
    "     data='{\"text\":\"I love it\"}'\n",
    ").text"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
