{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(185460, 7000)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle5 as pickle\n",
    "\n",
    "with open(f'../../pickles/swarog_data/swarog_tfidf.pickle', 'rb') as handle:\n",
    "        tfidfvec = pickle.load(handle)\n",
    "tfidfvec.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['covid_fake_news', 'grafn', 'isot', 'mmcovid_en', 'pubhealth', 'qprop']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn = sqlite3.connect('../../pickles/swarog_data/swarog.sqlite')\n",
    "c = conn.cursor()\n",
    "c.execute(\"\"\"\n",
    "select dataset from raw group by dataset\n",
    "\"\"\")\n",
    "names = [n[0] for n in c.fetchall()]\n",
    "\n",
    "conn.close()\n",
    "names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, f1_score, precision_score, recall_score, roc_auc_score\n",
    "from imblearn.metrics import geometric_mean_score\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "def experiment(foldids, X, y, cls = LogisticRegression(max_iter=10000), fit=True):\n",
    "\n",
    "    scores = {\n",
    "        'Accuracy': {'func': accuracy_score},\n",
    "        'Balanced Accuracy': {'func': balanced_accuracy_score},\n",
    "        'F1': {'func': f1_score},\n",
    "        'Precision': {'func': precision_score},\n",
    "        'Recall': {'func': recall_score},\n",
    "        'G-mean': {'func': geometric_mean_score}\n",
    "    }\n",
    "\n",
    "    for score_name, score_dict in scores.items():\n",
    "        scores[score_name][\"list\"] = []\n",
    "        scores[score_name][\"lab\"] = []\n",
    "\n",
    "    for fold,j in enumerate(foldids):\n",
    "        train = foldids[fold][1]\n",
    "        test = foldids[fold][2]\n",
    "        xin, yin = X[train], np.array(y[train])\n",
    "        \n",
    "        pca = PCA(n_components=512)\n",
    "        pca.fit(xin)\n",
    "        \n",
    "        \n",
    "        if fit == True:\n",
    "            cls.fit(pca.transform(xin), yin)\n",
    "        y_pred = cls.predict(pca.transform(X[test]))\n",
    "        for score_name, score_dict in scores.items():\n",
    "            if score_name in [\"F1\",\"Precision\",\"Recall\"]:\n",
    "                scorvaln = score_dict['func'](y[test], y_pred, average=None)\n",
    "                score_dict['lab'].append(scorvaln)\n",
    "                scorval = score_dict['func'](y[test], y_pred, average=\"weighted\")\n",
    "                score_dict['list'].append(scorval)\n",
    "                #print(score_name, scorval, scorvaln)  \n",
    "            else:\n",
    "                scorval=score_dict['func'](y[test], y_pred)\n",
    "                score_dict['list'].append(scorval)\n",
    "                #print(score_name, scorval)\n",
    "        #print(\" \")\n",
    "\n",
    "    #clear_output()\n",
    "    for score_name, score_dict in scores.items():\n",
    "        score_dict['avg'] = np.mean(score_dict['list'])\n",
    "        score_dict['std'] = np.std(score_dict['list'])\n",
    " \n",
    "    # Print stats\n",
    "    numlabels = scores[\"F1\"][\"lab\"][0].shape[0]\n",
    "    scores[\"F1\"][\"lab\"][0].shape[0] \n",
    "    head = \"| %-20s | %-10s |\" +  numlabels * \" %-10s |\" \n",
    "    headv = [\"Score\", \"Average\"]\n",
    "    headv.extend([\"Kat_\"+str(i+1) for i in range(numlabels)])\n",
    "    row=head % tuple(headv)\n",
    "    print(\"+\"*len(row))\n",
    "    print(row)\n",
    "    print(\"+\"*len(row))\n",
    "    for score_name, score_dict in sorted(scores.items()) :\n",
    "        headv = [score_name, np.mean(score_dict['list'])*100, np.std(score_dict['list'])*100]\n",
    "        for i in range(numlabels):\n",
    "            if score_name in [\"F1\",\"Precision\",\"Recall\"]:\n",
    "                head = \"| %-20s | %4.1f ± %3.1f |\" + numlabels* \" %4.1f ± %3.1f |\"\n",
    "                vals = [v[i] for v in scores[score_name][\"lab\"]]\n",
    "                headv.append(np.mean(vals)*100)\n",
    "                headv.append(np.std(vals)*100)\n",
    "            else:\n",
    "                head = \"| %-20s | %4.1f ± %3.1f |\" + numlabels * \" %-10s |\" \n",
    "                headv.append(\"-\")\n",
    "        print(head % tuple(headv))\n",
    "    print(\"+\"*len(row))\n",
    "    return cls, scores, pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indata['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "covid_fake_news\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "| Score                | Average    | Kat_1      | Kat_2      |\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "| Accuracy             | 96.0 ± 0.1 | -          | -          |\n",
      "| Balanced Accuracy    | 60.9 ± 0.7 | -          | -          |\n",
      "| F1                   | 94.7 ± 0.1 | 35.7 ± 1.9 | 97.9 ± 0.0 |\n",
      "| G-mean               | 46.7 ± 1.5 | -          | -          |\n",
      "| Precision            | 96.1 ± 0.1 | 99.0 ± 1.6 | 95.9 ± 0.1 |\n",
      "| Recall               | 96.0 ± 0.1 | 21.8 ± 1.4 | 100.0 ± 0.0 |\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "grafn\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "| Score                | Average    | Kat_1      | Kat_2      |\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "| Accuracy             | 92.9 ± 0.2 | -          | -          |\n",
      "| Balanced Accuracy    | 85.3 ± 0.3 | -          | -          |\n",
      "| F1                   | 92.6 ± 0.2 | 95.7 ± 0.1 | 80.6 ± 0.5 |\n",
      "| G-mean               | 84.3 ± 0.4 | -          | -          |\n",
      "| Precision            | 92.8 ± 0.2 | 93.3 ± 0.1 | 91.0 ± 0.3 |\n",
      "| Recall               | 92.9 ± 0.2 | 98.2 ± 0.0 | 72.4 ± 0.6 |\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "isot\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "| Score                | Average    | Kat_1      | Kat_2      |\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "| Accuracy             | 99.6 ± 0.1 | -          | -          |\n",
      "| Balanced Accuracy    | 99.6 ± 0.1 | -          | -          |\n",
      "| F1                   | 99.6 ± 0.1 | 99.6 ± 0.1 | 99.6 ± 0.1 |\n",
      "| G-mean               | 99.6 ± 0.1 | -          | -          |\n",
      "| Precision            | 99.6 ± 0.1 | 99.5 ± 0.1 | 99.6 ± 0.0 |\n",
      "| Recall               | 99.6 ± 0.1 | 99.6 ± 0.0 | 99.6 ± 0.1 |\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "mmcovid_en\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "| Score                | Average    | Kat_1      | Kat_2      |\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "| Accuracy             | 91.8 ± 0.4 | -          | -          |\n",
      "| Balanced Accuracy    | 86.4 ± 1.0 | -          | -          |\n",
      "| F1                   | 91.5 ± 0.5 | 94.6 ± 0.2 | 83.2 ± 1.1 |\n",
      "| G-mean               | 85.5 ± 1.2 | -          | -          |\n",
      "| Precision            | 92.0 ± 0.3 | 91.0 ± 0.7 | 94.7 ± 1.3 |\n",
      "| Recall               | 91.8 ± 0.4 | 98.4 ± 0.4 | 74.3 ± 2.3 |\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "pubhealth\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "| Score                | Average    | Kat_1      | Kat_2      |\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "| Accuracy             | 81.3 ± 0.4 | -          | -          |\n",
      "| Balanced Accuracy    | 79.2 ± 0.5 | -          | -          |\n",
      "| F1                   | 81.2 ± 0.4 | 73.9 ± 0.7 | 85.5 ± 0.3 |\n",
      "| G-mean               | 78.7 ± 0.6 | -          | -          |\n",
      "| Precision            | 81.2 ± 0.4 | 77.5 ± 1.1 | 83.3 ± 0.6 |\n",
      "| Recall               | 81.3 ± 0.4 | 70.6 ± 1.6 | 87.7 ± 1.0 |\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "qprop\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "| Score                | Average    | Kat_1      | Kat_2      |\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "| Accuracy             | 94.2 ± 0.0 | -          | -          |\n",
      "| Balanced Accuracy    | 77.2 ± 0.2 | -          | -          |\n",
      "| F1                   | 93.6 ± 0.0 | 96.8 ± 0.0 | 68.1 ± 0.3 |\n",
      "| G-mean               | 74.1 ± 0.3 | -          | -          |\n",
      "| Precision            | 94.0 ± 0.0 | 94.6 ± 0.0 | 88.6 ± 0.4 |\n",
      "| Recall               | 94.2 ± 0.0 | 99.1 ± 0.0 | 55.4 ± 0.4 |\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "rskf = RepeatedStratifiedKFold(n_splits=2, n_repeats=5, random_state=1410)\n",
    "conn = sqlite3.connect('../../pickles/swarog_data/swarog.sqlite')\n",
    "\n",
    "for name in names:\n",
    "    print(name)\n",
    "    indata = pd.read_sql_query(\"\"\"\n",
    "            select tfidf.rowid as _index, raw.dataset, body, tfidf.gid as gid, raw.label as label \n",
    "            from raw join tfidf on (tfidf.gid = raw.ROWID) where raw.dataset ='%s'\n",
    "            \"\"\" % name, conn)\n",
    "\n",
    "    X = []\n",
    "    y = indata['label'].values\n",
    "    \n",
    "    for _id in indata['_index'].values:\n",
    "        X.append(tfidfvec[_id-1].toarray()[0])\n",
    "        \n",
    "    X = np.array(X)  \n",
    "    \n",
    "    foldids = []\n",
    "    for fold_idx, (train, test) in enumerate(rskf.split(X, y)):\n",
    "        foldids.append((fold_idx,train,test))\n",
    "\n",
    "    cls, scores, pca = experiment(foldids, X, y, LogisticRegression(max_iter=10000))\n",
    "    #print(scores)\n",
    "\n",
    "conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
