{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SQL definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "conn = sqlite3.connect('swarog.sqlite')\n",
    "c = conn.cursor()\n",
    "c.execute('''CREATE TABLE raw\n",
    "             (dataset TEXT, id INT, body TEXT, label INT)''')\n",
    "conn.commit()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "conn = sqlite3.connect('swarog.sqlite')\n",
    "c = conn.cursor()\n",
    "c.execute('''CREATE TABLE bert\n",
    "             (dataset TEXT, id INT, vec TEXT)''')\n",
    "conn.commit()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "conn = sqlite3.connect('swarog.sqlite')\n",
    "c = conn.cursor()\n",
    "c.execute('''CREATE TABLE bertnp\n",
    "             (dataset TEXT, id INT, vec BLOB)''')\n",
    "conn.commit()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "compressor = 'zlib'\n",
    "\n",
    "def adapt_array(arr):\n",
    "    \"\"\"\n",
    "    http://stackoverflow.com/a/31312102/190597 (SoulNibbler)\n",
    "    \"\"\"\n",
    "    # zlib uses similar disk size that Matlab v5 .mat files\n",
    "    # bz2 compress 4 times zlib, but storing process is 20 times slower.\n",
    "    out = io.BytesIO()\n",
    "    np.save(out, arr)\n",
    "    out.seek(0)\n",
    "    return sqlite3.Binary(codecs.encode(out.read(),compressor))  # zlib, bz2\n",
    "\n",
    "def convert_array(text):\n",
    "    out = io.BytesIO(text)\n",
    "    out.seek(0)\n",
    "    out = io.BytesIO(codecs.decode(out.read(),compressor))\n",
    "    return np.load(out)\n",
    "\n",
    "import sqlite3\n",
    "\n",
    "# sqlite3.register_adapter(np.ndarray, adapt_array)\n",
    "# sqlite3.register_converter(\"array\", convert_array)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect('swarog.sqlite')\n",
    "c = conn.cursor()\n",
    "c.execute('''CREATE TABLE bertnp\n",
    "             (dataset TEXT, id INT, vec array)''')\n",
    "conn.commit()\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import raw text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 8972/8972 [00:22<00:00, 400.03it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 7332/7332 [00:19<00:00, 379.15it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 10075/10075 [00:27<00:00, 364.48it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 51270/51270 [02:50<00:00, 299.88it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 44898/44898 [02:41<00:00, 277.39it/s]\n",
      "/tmp/ipykernel_4157/3735554623.py:39: DtypeWarning: Columns (3,5,6,9,10,11,12,13,14,16,22) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv(\"../raw/grafn.csv\",sep=\",\")\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 63930/63930 [03:17<00:00, 323.35it/s]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "conn = sqlite3.connect('swarog.sqlite')\n",
    "c = conn.cursor()\n",
    "\n",
    "data = pd.read_csv(\"../raw/covid_fake_news.csv\",sep=\"\\t\")\n",
    "for index, row in tqdm(data.iterrows(), total=data.shape[0]):\n",
    "    values_to_insert = [('covid_fake_news', index, row['text'], row['label'])]\n",
    "    c.executemany(\"\"\"INSERT INTO raw(dataset, id, body, label) VALUES (?,?,?,?)\"\"\", values_to_insert)\n",
    "    conn.commit()\n",
    "    \n",
    "    \n",
    "data = pd.read_csv(\"../raw/mmcovid_en.csv\",sep=\",\")\n",
    "for index, row in tqdm(data.iterrows(), total=data.shape[0]):\n",
    "    values_to_insert = [('mmcovid_en', index, row['text'], row['label'])]\n",
    "    c.executemany(\"\"\"INSERT INTO raw(dataset, id, body, label) VALUES (?,?,?,?)\"\"\", values_to_insert)\n",
    "    conn.commit()\n",
    "\n",
    "data = pd.read_csv(\"../raw/pubhealth.csv\",sep=\",\")\n",
    "for index, row in tqdm(data.iterrows(), total=data.shape[0]):\n",
    "    values_to_insert = [('pubhealth', index, row['text'], row['label'])]\n",
    "    c.executemany(\"\"\"INSERT INTO raw(dataset, id, body, label) VALUES (?,?,?,?)\"\"\", values_to_insert)\n",
    "    conn.commit()\n",
    "\n",
    "data = pd.read_csv(\"../raw/qprop.csv\",sep=\"\\t\")\n",
    "for index, row in tqdm(data.iterrows(), total=data.shape[0]):\n",
    "    values_to_insert = [('qprop', index, row['text'], row['label'])]\n",
    "    c.executemany(\"\"\"INSERT INTO raw(dataset, id, body, label) VALUES (?,?,?,?)\"\"\", values_to_insert)\n",
    "    conn.commit()\n",
    "    \n",
    "data = pd.read_csv(\"../raw/isot.csv\",sep=\",\")\n",
    "for index, row in tqdm(data.iterrows(), total=data.shape[0]):\n",
    "    values_to_insert = [('isot', index, row['text'], row['label'])]\n",
    "    c.executemany(\"\"\"INSERT INTO raw(dataset, id, body, label) VALUES (?,?,?,?)\"\"\", values_to_insert)\n",
    "    conn.commit()\n",
    "    \n",
    "    \n",
    "data = pd.read_csv(\"../raw/grafn.csv\",sep=\",\")\n",
    "for index, row in tqdm(data.iterrows(), total=data.shape[0]):\n",
    "    values_to_insert = [('grafn', index, row['text'], row['label'])]\n",
    "    c.executemany(\"\"\"INSERT INTO raw(dataset, id, body, label) VALUES (?,?,?,?)\"\"\", values_to_insert)\n",
    "    conn.commit()\n",
    "    \n",
    "        \n",
    "\n",
    "    \n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import bert CLS vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 8972/8972 [00:34<00:00, 259.38it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 7332/7332 [00:18<00:00, 392.50it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 10075/10075 [00:36<00:00, 275.73it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 51270/51270 [02:57<00:00, 288.65it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 44898/44898 [02:15<00:00, 330.69it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 63930/63930 [03:29<00:00, 304.71it/s]\n"
     ]
    }
   ],
   "source": [
    "import pickle \n",
    "import json\n",
    "import codecs\n",
    "\n",
    "conn = sqlite3.connect('swarog.sqlite')\n",
    "c = conn.cursor()\n",
    "\n",
    "\n",
    "with open('../covid_fake_news_BERTEmbeddings.pickle', 'rb') as handle:\n",
    "    dst = pickle.load(handle)\n",
    "    for index, row in tqdm(enumerate(dst),total=len(dst)):\n",
    "        values_to_insert = [('covid_fake_news', index, adapt_array(row))]\n",
    "        c.executemany(\"\"\"INSERT INTO bertnp(dataset, id, vec) VALUES (?,?,?)\"\"\", values_to_insert)\n",
    "        conn.commit()\n",
    "        \n",
    "        \n",
    "with open('../mmcovid_en_BERTEmbeddings.pickle', 'rb') as handle:\n",
    "    dst = pickle.load(handle)\n",
    "    for index, row in tqdm(enumerate(dst),total=len(dst)):\n",
    "        values_to_insert = [('mmcovid_en', index, adapt_array(row))]\n",
    "        c.executemany(\"\"\"INSERT INTO bertnp(dataset, id, vec) VALUES (?,?,?)\"\"\", values_to_insert)\n",
    "        conn.commit()\n",
    "        \n",
    "with open('../pubhealth_BERTEmbeddings.pickle', 'rb') as handle:\n",
    "    dst = pickle.load(handle)\n",
    "    for index, row in tqdm(enumerate(dst),total=len(dst)):\n",
    "        values_to_insert = [('pubhealth', index, adapt_array(row))]\n",
    "        c.executemany(\"\"\"INSERT INTO bertnp(dataset, id, vec) VALUES (?,?,?)\"\"\", values_to_insert)\n",
    "        conn.commit()\n",
    "        \n",
    "with open('../qprop_BERTEmbeddings.pickle', 'rb') as handle:\n",
    "    dst = pickle.load(handle)\n",
    "    for index, row in tqdm(enumerate(dst),total=len(dst)):\n",
    "        values_to_insert = [('qprop', index, adapt_array(row))]\n",
    "        c.executemany(\"\"\"INSERT INTO bertnp(dataset, id, vec) VALUES (?,?,?)\"\"\", values_to_insert)\n",
    "        conn.commit()\n",
    "\n",
    "with open('../isot_BERTEmbeddings.pickle', 'rb') as handle:\n",
    "    dst = pickle.load(handle)\n",
    "    for index, row in tqdm(enumerate(dst),total=len(dst)):\n",
    "        values_to_insert = [('isot', index, adapt_array(row))]\n",
    "        c.executemany(\"\"\"INSERT INTO bertnp(dataset, id, vec) VALUES (?,?,?)\"\"\", values_to_insert)\n",
    "        conn.commit()\n",
    "                \n",
    "with open('../grafn_BERTEmbeddings.pickle', 'rb') as handle:\n",
    "    dst = pickle.load(handle)\n",
    "    for index, row in tqdm(enumerate(dst),total=len(dst)):\n",
    "        values_to_insert = [('grafn', index, adapt_array(row))]\n",
    "        c.executemany(\"\"\"INSERT INTO bertnp(dataset, id, vec) VALUES (?,?,?)\"\"\", values_to_insert)\n",
    "        conn.commit()\n",
    "        \n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Un-pickle bert `CLS` tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6542/996138349.py:57: DtypeWarning: Columns (3,5,6,9,10,11,12,13,14,16,22) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv(\"../raw/grafn.csv\",sep=\",\")\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "DATA = {\n",
    "    \"X\" : [],\n",
    "    \"category\" : [],\n",
    "    \"y\" : []\n",
    "}\n",
    "\n",
    "X=DATA[\"X\"]\n",
    "category=DATA[\"category\"]\n",
    "y=DATA[\"y\"]\n",
    "\n",
    "\n",
    "with open('../covid_fake_news_BERTEmbeddings.pickle', 'rb') as handle:\n",
    "    dst = pickle.load(handle)\n",
    "    X.extend(dst)\n",
    "    category.extend(np.repeat(0,len(dst)))\n",
    "    data = pd.read_csv(\"../raw/covid_fake_news.csv\",sep=\"\\t\")\n",
    "    y.extend(data[\"label\"].values)\n",
    "    \n",
    "with open('../mmcovid_en_BERTEmbeddings.pickle', 'rb') as handle:\n",
    "    dst = pickle.load(handle)\n",
    "    X.extend(dst)\n",
    "    category.extend(np.repeat(1,len(dst)))\n",
    "    data = pd.read_csv(\"../raw/mmcovid_en.csv\",sep=\",\")\n",
    "    y.extend(data[\"label\"].values)\n",
    "    \n",
    "\n",
    "with open('../pubhealth_BERTEmbeddings.pickle', 'rb') as handle:\n",
    "    dst = pickle.load(handle)\n",
    "    X.extend(dst)\n",
    "    category.extend(np.repeat(2,len(dst)))\n",
    "    data = pd.read_csv(\"../raw/pubhealth.csv\",sep=\",\")\n",
    "    y.extend(data[\"label\"].values)\n",
    "\n",
    "    \n",
    "with open('../qprop_BERTEmbeddings.pickle', 'rb') as handle:\n",
    "    dst = pickle.load(handle)\n",
    "    X.extend(dst)\n",
    "    category.extend(np.repeat(3,len(dst)))\n",
    "    data = pd.read_csv(\"../raw/qprop.csv\",sep=\"\\t\")\n",
    "    y.extend(data[\"label\"].values)\n",
    "    \n",
    "with open('../isot_BERTEmbeddings.pickle', 'rb') as handle:\n",
    "    dst = pickle.load(handle)\n",
    "    X.extend(dst)\n",
    "    category.extend(np.repeat(4,len(dst)))\n",
    "    data = pd.read_csv(\"../raw/isot.csv\",sep=\",\")\n",
    "    y.extend(data[\"label\"].values)\n",
    "    \n",
    "with open('../grafn_BERTEmbeddings.pickle', 'rb') as handle:\n",
    "    dst = pickle.load(handle)\n",
    "    X.extend(dst)\n",
    "    category.extend(np.repeat(5,len(dst)))\n",
    "    data = pd.read_csv(\"../raw/grafn.csv\",sep=\",\")\n",
    "    y.extend(data[\"label\"].values)\n",
    "    \n",
    "    \n",
    "DATA[\"X\"]=np.array(X)\n",
    "DATA[\"category\"]=np.array(category)\n",
    "DATA[\"y\"]=np.array(y)\n",
    "DATA[\"folds\"] = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5x2 CV experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, f1_score, precision_score, recall_score, roc_auc_score\n",
    "from imblearn.metrics import geometric_mean_score\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def experiment(foldids, X, y, cls = LogisticRegression(max_iter=10000), fit=True):\n",
    "\n",
    "    scores = {\n",
    "        'Accuracy': {'func': accuracy_score},\n",
    "        'Balanced Accuracy': {'func': balanced_accuracy_score},\n",
    "        'F1': {'func': f1_score},\n",
    "        'Precision': {'func': precision_score},\n",
    "        'Recall': {'func': recall_score},\n",
    "        'G-mean': {'func': geometric_mean_score}\n",
    "    }\n",
    "\n",
    "    for score_name, score_dict in scores.items():\n",
    "        scores[score_name][\"list\"] = []\n",
    "        scores[score_name][\"lab\"] = []\n",
    "\n",
    "    for fold,j in enumerate(foldids):\n",
    "        train = foldids[fold][1]\n",
    "        test = foldids[fold][2]\n",
    "        xin, yin = X[train], np.array(y[train])\n",
    "        \n",
    "        pca = PCA(n_components=512)\n",
    "        pca.fit(xin)\n",
    "        \n",
    "        \n",
    "        if fit == True:\n",
    "            cls.fit(pca.transform(xin), yin)\n",
    "        y_pred = cls.predict(pca.transform(X[test]))\n",
    "        for score_name, score_dict in scores.items():\n",
    "            if score_name in [\"F1\",\"Precision\",\"Recall\"]:\n",
    "                scorvaln = score_dict['func'](y[test], y_pred, average=None)\n",
    "                score_dict['lab'].append(scorvaln)\n",
    "                scorval = score_dict['func'](y[test], y_pred, average=\"weighted\")\n",
    "                score_dict['list'].append(scorval)\n",
    "                #print(score_name, scorval, scorvaln)  \n",
    "            else:\n",
    "                scorval=score_dict['func'](y[test], y_pred)\n",
    "                score_dict['list'].append(scorval)\n",
    "                #print(score_name, scorval)\n",
    "        #print(\" \")\n",
    "\n",
    "    #clear_output()\n",
    "    for score_name, score_dict in scores.items():\n",
    "        score_dict['avg'] = np.mean(score_dict['list'])\n",
    "        score_dict['std'] = np.std(score_dict['list'])\n",
    " \n",
    "    # Print stats\n",
    "    numlabels = scores[\"F1\"][\"lab\"][0].shape[0]\n",
    "    scores[\"F1\"][\"lab\"][0].shape[0] \n",
    "    head = \"| %-20s | %-10s |\" +  numlabels * \" %-10s |\" \n",
    "    headv = [\"Score\", \"Average\"]\n",
    "    headv.extend([\"Kat_\"+str(i+1) for i in range(numlabels)])\n",
    "    row=head % tuple(headv)\n",
    "    print(\"+\"*len(row))\n",
    "    print(row)\n",
    "    print(\"+\"*len(row))\n",
    "    for score_name, score_dict in sorted(scores.items()) :\n",
    "        headv = [score_name, np.mean(score_dict['list'])*100, np.std(score_dict['list'])*100]\n",
    "        for i in range(numlabels):\n",
    "            if score_name in [\"F1\",\"Precision\",\"Recall\"]:\n",
    "                head = \"| %-20s | %4.1f ± %3.1f |\" + numlabels* \" %4.1f ± %3.1f |\"\n",
    "                vals = [v[i] for v in scores[score_name][\"lab\"]]\n",
    "                headv.append(np.mean(vals)*100)\n",
    "                headv.append(np.std(vals)*100)\n",
    "            else:\n",
    "                head = \"| %-20s | %4.1f ± %3.1f |\" + numlabels * \" %-10s |\" \n",
    "                headv.append(\"-\")\n",
    "        print(head % tuple(headv))\n",
    "    print(\"+\"*len(row))\n",
    "    return cls, scores, pca"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recording test/train folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TASK 0\n",
      "TASK 1\n",
      "TASK 2\n",
      "TASK 3\n",
      "TASK 4\n",
      "TASK 5\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "DATA[\"folds\"] = []\n",
    "rskf = RepeatedStratifiedKFold(n_splits=2, n_repeats=5, random_state=1410)\n",
    "\n",
    "\n",
    "for t in range(np.max(DATA[\"category\"]+1)):\n",
    "    print(\"TASK\",t)\n",
    "    X = DATA[\"X\"][DATA[\"category\"] == t]\n",
    "    y = DATA[\"y\"][DATA[\"category\"] == t]\n",
    "\n",
    "    foldids = []\n",
    "    for fold_idx, (train, test) in enumerate(rskf.split(X, y)):\n",
    "        foldids.append((fold_idx,train,test))\n",
    "\n",
    "    #print(\"shapes X\",X.shape,\"y\", y.shape)\n",
    "    DATA[\"folds\"].append(foldids)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border: 5px dashed red\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single Task Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TASK 0\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "| Score                | Average    | Kat_1      | Kat_2      |\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "| Accuracy             | 97.2 ± 0.1 | -          | -          |\n",
      "| Balanced Accuracy    | 79.3 ± 1.3 | -          | -          |\n",
      "| F1                   | 97.0 ± 0.1 | 68.7 ± 1.6 | 98.5 ± 0.1 |\n",
      "| G-mean               | 76.8 ± 1.7 | -          | -          |\n",
      "| Precision            | 97.0 ± 0.2 | 81.8 ± 3.5 | 97.8 ± 0.1 |\n",
      "| Recall               | 97.2 ± 0.1 | 59.4 ± 2.7 | 99.3 ± 0.2 |\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "TASK 1\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "| Score                | Average    | Kat_1      | Kat_2      |\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "| Accuracy             | 92.6 ± 0.2 | -          | -          |\n",
      "| Balanced Accuracy    | 88.2 ± 0.7 | -          | -          |\n",
      "| F1                   | 92.4 ± 0.3 | 95.1 ± 0.1 | 85.5 ± 0.7 |\n",
      "| G-mean               | 87.7 ± 0.8 | -          | -          |\n",
      "| Precision            | 92.7 ± 0.2 | 92.3 ± 0.6 | 93.9 ± 1.1 |\n",
      "| Recall               | 92.6 ± 0.2 | 98.0 ± 0.4 | 78.5 ± 1.8 |\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "TASK 2\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "| Score                | Average    | Kat_1      | Kat_2      |\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "| Accuracy             | 81.7 ± 0.4 | -          | -          |\n",
      "| Balanced Accuracy    | 80.4 ± 0.5 | -          | -          |\n",
      "| F1                   | 81.7 ± 0.4 | 75.5 ± 0.6 | 85.4 ± 0.3 |\n",
      "| G-mean               | 80.2 ± 0.5 | -          | -          |\n",
      "| Precision            | 81.7 ± 0.4 | 75.8 ± 0.6 | 85.2 ± 0.5 |\n",
      "| Recall               | 81.7 ± 0.4 | 75.2 ± 1.1 | 85.6 ± 0.6 |\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "TASK 3\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "| Score                | Average    | Kat_1      | Kat_2      |\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "| Accuracy             | 94.0 ± 0.1 | -          | -          |\n",
      "| Balanced Accuracy    | 80.5 ± 0.4 | -          | -          |\n",
      "| F1                   | 93.7 ± 0.1 | 96.7 ± 0.1 | 70.3 ± 0.6 |\n",
      "| G-mean               | 78.5 ± 0.5 | -          | -          |\n",
      "| Precision            | 93.7 ± 0.1 | 95.5 ± 0.1 | 79.5 ± 0.8 |\n",
      "| Recall               | 94.0 ± 0.1 | 98.0 ± 0.1 | 63.0 ± 0.9 |\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "TASK 4\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "| Score                | Average    | Kat_1      | Kat_2      |\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "| Accuracy             | 99.7 ± 0.0 | -          | -          |\n",
      "| Balanced Accuracy    | 99.7 ± 0.0 | -          | -          |\n",
      "| F1                   | 99.7 ± 0.0 | 99.7 ± 0.0 | 99.7 ± 0.0 |\n",
      "| G-mean               | 99.7 ± 0.0 | -          | -          |\n",
      "| Precision            | 99.7 ± 0.0 | 99.6 ± 0.1 | 99.7 ± 0.0 |\n",
      "| Recall               | 99.7 ± 0.0 | 99.7 ± 0.0 | 99.6 ± 0.1 |\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "TASK 5\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "| Score                | Average    | Kat_1      | Kat_2      |\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "| Accuracy             | 91.5 ± 0.1 | -          | -          |\n",
      "| Balanced Accuracy    | 85.0 ± 0.2 | -          | -          |\n",
      "| F1                   | 91.3 ± 0.1 | 94.7 ± 0.1 | 78.0 ± 0.2 |\n",
      "| G-mean               | 84.3 ± 0.2 | -          | -          |\n",
      "| Precision            | 91.3 ± 0.1 | 93.6 ± 0.1 | 82.4 ± 0.3 |\n",
      "| Recall               | 91.5 ± 0.1 | 96.0 ± 0.1 | 74.1 ± 0.3 |\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "DATA[\"folds\"] = []\n",
    "rskf = RepeatedStratifiedKFold(n_splits=2, n_repeats=5, random_state=1410)\n",
    "\n",
    "stl=[]\n",
    "\n",
    "for t in range(np.max(DATA[\"category\"]+1)):\n",
    "    print(\"TASK\",t)\n",
    "    X = DATA[\"X\"][DATA[\"category\"] == t]\n",
    "    y = DATA[\"y\"][DATA[\"category\"] == t]\n",
    "\n",
    "    foldids = []\n",
    "    for fold_idx, (train, test) in enumerate(rskf.split(X, y)):\n",
    "        foldids.append((fold_idx,train,test))\n",
    "\n",
    "    #print(\"shapes X\",X.shape,\"y\", y.shape)\n",
    "    DATA[\"folds\"].append(foldids)\n",
    "    model1, scores1, pca = experiment(foldids, X, y, \n",
    "                                 LogisticRegression(max_iter=10000))\n",
    "    stl.append((model1,pca,scores1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border: 5px dashed red\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Domain Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shapes X (186477, 768) y (186477,)\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "| Score                | Average    | Kat_1      | Kat_2      | Kat_3      | Kat_4      | Kat_5      | Kat_6      |\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "| Accuracy             | 79.6 ± 0.1 | -          | -          | -          | -          | -          | -          |\n",
      "| Balanced Accuracy    | 85.7 ± 0.1 | -          | -          | -          | -          | -          | -          |\n",
      "| F1                   | 79.6 ± 0.1 | 96.7 ± 0.2 | 82.8 ± 0.4 | 72.8 ± 0.5 | 72.8 ± 0.2 | 87.2 ± 0.1 | 77.9 ± 0.1 |\n",
      "| G-mean               | 85.1 ± 0.1 | -          | -          | -          | -          | -          | -          |\n",
      "| Precision            | 80.2 ± 0.1 | 95.2 ± 0.3 | 75.4 ± 0.6 | 61.5 ± 0.7 | 73.1 ± 0.2 | 85.0 ± 0.2 | 83.8 ± 0.3 |\n",
      "| Recall               | 79.6 ± 0.1 | 98.2 ± 0.2 | 91.9 ± 0.5 | 89.3 ± 0.4 | 72.4 ± 0.4 | 89.5 ± 0.2 | 72.9 ± 0.3 |\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n"
     ]
    }
   ],
   "source": [
    "X = DATA[\"X\"]\n",
    "y = DATA[\"y\"]\n",
    "category = DATA[\"category\"]\n",
    "\n",
    "rskf = RepeatedStratifiedKFold(n_splits=2, n_repeats=5, random_state=1410)\n",
    "foldids = []\n",
    "for fold_idx, (train, test) in enumerate(rskf.split(X, y)):\n",
    "    foldids.append((fold_idx,train,test))\n",
    "    \n",
    "print(\"shapes X\",X.shape,\"y\", category.shape)\n",
    "\n",
    "domain_model, domain_scores, domain_pca = experiment(foldids, X, \n",
    "                                         category, LogisticRegression(max_iter=10000, class_weight='balanced'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border: 5px dashed red\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0\n",
      "fold 1\n",
      "fold 2\n",
      "fold 3\n",
      "fold 4\n",
      "fold 5\n",
      "fold 6\n",
      "fold 7\n",
      "fold 8\n",
      "fold 9\n"
     ]
    }
   ],
   "source": [
    "T = np.max(DATA[\"category\"])+1\n",
    "d = 128\n",
    "\n",
    "_bacs = [[] for b in range(T)]\n",
    "\n",
    "\n",
    "for _foldid in range(10):\n",
    "    print(\"fold\",_foldid)\n",
    "\n",
    "    ##### Test\n",
    "    for task in range(T):\n",
    "\n",
    "        X = DATA[\"X\"][DATA[\"category\"] == task]\n",
    "        y = DATA[\"y\"][DATA[\"category\"] == task]\n",
    "        foldids = DATA[\"folds\"][task]\n",
    "\n",
    "        train = foldids[_foldid][1]\n",
    "        test = foldids[_foldid][2]   \n",
    "\n",
    "        X_test=X[test]\n",
    "        X=domain_pca.transform(X_test)\n",
    "        domain_pred = domain_model.predict(X)\n",
    "        ypred = []\n",
    "        for i,dpred in enumerate(domain_pred):\n",
    "            model, model_pca, _ = stl[dpred] \n",
    "            xpca = model_pca.transform(X_test[i:i+1])\n",
    "            ypred.append(model.predict(xpca))\n",
    "    \n",
    "        bac = balanced_accuracy_score(y[test], ypred)\n",
    "        #print(task,bac)\n",
    "        _bacs[task].append(bac)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82.8 ± 1.25 &\n",
      "86.4 ± 0.85 &\n",
      "77.9 ± 0.85 &\n",
      "77.1 ± 0.27 &\n",
      "95.0 ± 0.06 &\n",
      "80.0 ± 0.38 &\n",
      "---\n",
      "83.2102039567237 6.158582778059437\n"
     ]
    }
   ],
   "source": [
    "for t in range(T):\n",
    "    print(\"%3.1f ± %3.2f &\" % (np.mean(_bacs[t])*100, 100*np.std(_bacs[t])) )\n",
    "\n",
    "print(\"---\")\n",
    "print(np.mean(np.array(_bacs).flatten())*100, np.std(np.array(_bacs).flatten())*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global model with category pred."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, f1_score, precision_score, recall_score, roc_auc_score\n",
    "from imblearn.metrics import geometric_mean_score\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def cls_max_predict(X_test):\n",
    "    ypred = np.array([stl[t][0].predict(stl[t][1].transform(X_test)) for t in range(6)])\n",
    "    return np.mean(ypred, axis=0) > 0.5\n",
    "\n",
    "def cls_weighted_predict(X_test):\n",
    "    ypred = np.array([stl[t][0].predict(stl[t][1].transform(X_test)) for t in range(6)])\n",
    "    return np.average(ypred, weights=[78,83,74,73,90,73], axis=0) > 0.4\n",
    "\n",
    "def cls_max_predict_raw(X_test):\n",
    "    ypred = np.array([stl[t][0].predict(stl[t][1].transform(X_test)) for t in range(6)])\n",
    "    return ypred\n",
    "\n",
    "def cls_predict(X_test):\n",
    "    Xd=domain_pca.transform(X_test)\n",
    "    domain_pred = domain_model.predict(Xd)\n",
    "    ypred = []\n",
    "    for i,dpred in enumerate(domain_pred):\n",
    "        model, model_pca, _ = stl[dpred] \n",
    "        xpca = model_pca.transform(X_test[i:i+1])\n",
    "        ypred.append(model.predict(xpca)[0])\n",
    "    return ypred\n",
    "        \n",
    "def experiment2(foldids, X, y, cback):\n",
    "\n",
    "    scores = {\n",
    "        'Accuracy': {'func': accuracy_score},\n",
    "        'Balanced Accuracy': {'func': balanced_accuracy_score},\n",
    "        'F1': {'func': f1_score},\n",
    "        'Precision': {'func': precision_score},\n",
    "        'Recall': {'func': recall_score},\n",
    "        'G-mean': {'func': geometric_mean_score}\n",
    "    }\n",
    "\n",
    "    for score_name, score_dict in scores.items():\n",
    "        scores[score_name][\"list\"] = []\n",
    "        scores[score_name][\"lab\"] = []\n",
    "\n",
    "    for fold,j in enumerate(foldids):\n",
    "        train = foldids[fold][1]\n",
    "        test = foldids[fold][2]\n",
    "        xin, yin = X[train], np.array(y[train])\n",
    "        \n",
    "        y_pred = cback(X[test])\n",
    "        \n",
    "        for score_name, score_dict in scores.items():\n",
    "            if score_name in [\"F1\",\"Precision\",\"Recall\"]:\n",
    "                scorvaln = score_dict['func'](y[test], y_pred, average=None)\n",
    "                score_dict['lab'].append(scorvaln)\n",
    "                scorval = score_dict['func'](y[test], y_pred, average=\"weighted\")\n",
    "                score_dict['list'].append(scorval)\n",
    "                print(score_name, scorval, scorvaln)  \n",
    "            else:\n",
    "                scorval=score_dict['func'](y[test], y_pred)\n",
    "                score_dict['list'].append(scorval)\n",
    "                print(score_name, scorval)\n",
    "        print(\" \")\n",
    "\n",
    "    #clear_output()\n",
    "    for score_name, score_dict in scores.items():\n",
    "        score_dict['avg'] = np.mean(score_dict['list'])\n",
    "        score_dict['std'] = np.std(score_dict['list'])\n",
    " \n",
    "    # Print stats\n",
    "    numlabels = scores[\"F1\"][\"lab\"][0].shape[0]\n",
    "    scores[\"F1\"][\"lab\"][0].shape[0] \n",
    "    head = \"| %-20s | %-10s |\" +  numlabels * \" %-10s |\" \n",
    "    headv = [\"Score\", \"Average\"]\n",
    "    headv.extend([\"Kat_\"+str(i+1) for i in range(numlabels)])\n",
    "    row=head % tuple(headv)\n",
    "    print(\"+\"*len(row))\n",
    "    print(row)\n",
    "    print(\"+\"*len(row))\n",
    "    for score_name, score_dict in sorted(scores.items()) :\n",
    "        headv = [score_name, np.mean(score_dict['list'])*100, np.std(score_dict['list'])*100]\n",
    "        for i in range(numlabels):\n",
    "            if score_name in [\"F1\",\"Precision\",\"Recall\"]:\n",
    "                head = \"| %-20s | %4.1f ± %3.1f |\" + numlabels* \" %4.1f ± %3.1f |\"\n",
    "                vals = [v[i] for v in scores[score_name][\"lab\"]]\n",
    "                headv.append(np.mean(vals)*100)\n",
    "                headv.append(np.std(vals)*100)\n",
    "            else:\n",
    "                head = \"| %-20s | %4.1f ± %3.1f |\" + numlabels * \" %-10s |\" \n",
    "                headv.append(\"-\")\n",
    "        print(head % tuple(headv))\n",
    "    print(\"+\"*len(row))\n",
    "    return scores, pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 169.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shapes X (186477, 768) y (186477,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.8906895183346025\n",
      "Balanced Accuracy 0.8738772228942854\n",
      "F1 0.890706375178059 [0.9199887  0.82753486]\n",
      "Precision 0.8907234951046911 [0.92023432 0.82705902]\n",
      "Recall 0.8906895183346025 [0.9197432  0.82801124]\n",
      "G-mean 0.8726727407962598\n",
      " \n",
      "Accuracy 0.8902378858405371\n",
      "Balanced Accuracy 0.8740442812747655\n",
      "F1 0.8903299506300135 [0.919563  0.8272626]\n",
      "Precision 0.8904298659660493 [0.92090929 0.82467358]\n",
      "Recall 0.8902378858405371 [0.91822063 0.82986793]\n",
      "G-mean 0.8729271766294437\n",
      " \n",
      "Accuracy 0.8901210866697412\n",
      "Balanced Accuracy 0.8736792558319861\n",
      "F1 0.8901881059739745 [0.9195088 0.8269338]\n",
      "Precision 0.8902592631467223 [0.92048511 0.82505225]\n",
      "Recall 0.8901210866697412 [0.91853456 0.82882395]\n",
      "G-mean 0.8725270445120594\n",
      " \n",
      "Accuracy 0.8908063236019649\n",
      "Balanced Accuracy 0.8742422345763926\n",
      "F1 0.8908483410282234 [0.92004304 0.82786372]\n",
      "Precision 0.8908920018230735 [0.92065762 0.82667567]\n",
      "Recall 0.8908063236019649 [0.91942927 0.8290552 ]\n",
      "G-mean 0.8730736603814897\n",
      " \n",
      "Accuracy 0.8904535655680563\n",
      "Balanced Accuracy 0.8735410651778874\n",
      "F1 0.8904635080996898 [0.9198248  0.82712163]\n",
      "Precision 0.8904735416496804 [0.91996922 0.82684173]\n",
      "Recall 0.8904535655680563 [0.91968042 0.82740171]\n",
      "G-mean 0.8723217025699785\n",
      " \n",
      "Accuracy 0.8904845663785153\n",
      "Balanced Accuracy 0.8743973812452943\n",
      "F1 0.8905837749318338 [0.91973431 0.82769444]\n",
      "Precision 0.8906921527351259 [0.92118979 0.82489657]\n",
      "Recall 0.8904845663785153 [0.91828342 0.83051134]\n",
      "G-mean 0.8732953658976153\n",
      " \n",
      "Accuracy 0.890206887675758\n",
      "Balanced Accuracy 0.8735876304050934\n",
      "F1 0.890253094942496 [0.91959819 0.82694616]\n",
      "Precision 0.8903012673833978 [0.92027038 0.82564812]\n",
      "Recall 0.890206887675758 [0.91892698 0.82824828]\n",
      "G-mean 0.8724102770111375\n",
      " \n",
      "Accuracy 0.8907312469164933\n",
      "Balanced Accuracy 0.874350801684055\n",
      "F1 0.8907944592678206 [0.91996103 0.82787051]\n",
      "Precision 0.890861395461057 [0.92088707 0.82608402]\n",
      "Recall 0.8907312469164933 [0.91903686 0.82966475]\n",
      "G-mean 0.8732081544432301\n",
      " \n",
      "Accuracy 0.8914295520114973\n",
      "Balanced Accuracy 0.874654915501095\n",
      "F1 0.8914379288329449 [0.92054098 0.82865316]\n",
      "Precision 0.89144637151626 [0.92066383 0.82841478]\n",
      "Recall 0.8914295520114973 [0.92041816 0.82889167]\n",
      "G-mean 0.8734568946779143\n",
      " \n",
      "Accuracy 0.8895085694673845\n",
      "Balanced Accuracy 0.8732835056941879\n",
      "F1 0.8896101443677675 [0.91901707 0.82616766]\n",
      "Precision 0.8897211498155903 [0.9204932  0.82333356]\n",
      "Recall 0.8895085694673845 [0.91754568 0.82902133]\n",
      "G-mean 0.872161075430089\n",
      " \n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "| Score                | Average    | Kat_1      | Kat_2      |\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "| Accuracy             | 89.0 ± 0.0 | -          | -          |\n",
      "| Balanced Accuracy    | 87.4 ± 0.0 | -          | -          |\n",
      "| F1                   | 89.1 ± 0.0 | 92.0 ± 0.0 | 82.7 ± 0.1 |\n",
      "| G-mean               | 87.3 ± 0.0 | -          | -          |\n",
      "| Precision            | 89.1 ± 0.0 | 92.1 ± 0.0 | 82.6 ± 0.1 |\n",
      "| Recall               | 89.0 ± 0.0 | 91.9 ± 0.1 | 82.9 ± 0.1 |\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n"
     ]
    }
   ],
   "source": [
    "X = DATA[\"X\"]\n",
    "y = DATA[\"y\"]\n",
    "\n",
    "\n",
    "rskf = RepeatedStratifiedKFold(n_splits=2, n_repeats=5, random_state=1410)\n",
    "foldids = []\n",
    "for fold_idx, (train, test) in tqdm(enumerate(rskf.split(X, y)), total=rskf.get_n_splits()):\n",
    "    foldids.append((fold_idx,train,test))\n",
    "    \n",
    "print(\"shapes X\",X.shape,\"y\", y.shape)\n",
    "\n",
    "gscr, gpca = experiment2(foldids, X, y, cls_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "pipe_domain = Pipeline([('pca', domain_pca), ('head', domain_model)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pickle models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# SAVE\n",
    "with open('domain_cls.pickle', 'wb') as handle:\n",
    "    pickle.dump(pipe_domain, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_model_pipe = []\n",
    "for i,elem in enumerate(stl):\n",
    "    with open(f'model_{i}.pickle', 'wb') as handle:\n",
    "        p = Pipeline([('pca', elem[1]), ('head', elem[0])])\n",
    "        domain_model_pipe.append(p)\n",
    "        pickle.dump(p, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Un-pickle models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# load\n",
    "with open('domain_cls.pickle', 'rb') as handle:\n",
    "    pipe_domain = pickle.load(handle)\n",
    "    \n",
    "domain_model_pipe = []\n",
    "for i in range(6):\n",
    "    with open(f'model_{i}.pickle', 'rb') as handle:\n",
    "        p=pickle.load(handle)\n",
    "        domain_model_pipe.append(p)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([1, 1], [1, 1])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls_predict(X[0:2]), y[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved: Model(tag=\"big_puppy:wo3hgzkt6wg6itgm\")\n"
     ]
    }
   ],
   "source": [
    "import bentoml\n",
    "\n",
    "from sklearn import svm\n",
    "\n",
    "saved_model = bentoml.sklearn.save_model(\"big_puppy\", bp)\n",
    "print(f\"Model saved: {saved_model}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BENTO models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Model saved: Model(tag=\"domain_cls:6vgf5nkwiombitgm\")\n"
     ]
    }
   ],
   "source": [
    "import bentoml\n",
    "\n",
    "from sklearn import svm\n",
    "\n",
    "saved_model = bentoml.sklearn.save_model(\"domain_cls\", pipe_domain, signatures={\n",
    "        \"predict\": {\"batchable\": True, \"batch_dim\": 0},\n",
    "        \"predict_proba\": {\"batchable\": True, \"batch_dim\": 0},\n",
    "    })\n",
    "print(f\"Model saved: {saved_model}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved: Model(tag=\"model_0:7gq6owcwio3oqtgm\")\n",
      "Model saved: Model(tag=\"model_1:7hx67tswiojdktgm\")\n",
      "Model saved: Model(tag=\"model_2:7jkorskwiot2atgm\")\n",
      "Model saved: Model(tag=\"model_3:7kda6x2wioeaytgm\")\n",
      "Model saved: Model(tag=\"model_4:7li2yy2wiowiatgm\")\n",
      "Model saved: Model(tag=\"model_5:7ony5tcwiooustgm\")\n"
     ]
    }
   ],
   "source": [
    "for i in range(6):\n",
    "    saved_model = bentoml.sklearn.save_model(f\"model_{i}\", domain_model_pipe[i], signatures={\n",
    "        \"predict\": {\"batchable\": True, \"batch_dim\": 0},\n",
    "        \"predict_proba\": {\"batchable\": True, \"batch_dim\": 0},\n",
    "    })\n",
    "    print(f\"Model saved: {saved_model}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"result\":1,\"result_proba\":[0.12162441839088234,0.8783755816091177],\"domain\":5,\"domain_proba\":[3.727105162009764e-05,0.2524389920779804,0.00014313585175861234,0.011453801048172181,0.35051739023097733,0.3854094097394914]}'"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "requests.post(\n",
    "     \"http://0.0.0.0:3000/predict\",\n",
    "     headers={\"content-type\": \"application/json\"},\n",
    "     data='{\"text\":\"I love it\"}'\n",
    ").text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import bentoml\n",
    "from bentoml.io import NumpyNdarray\n",
    "from bentoml.io import JSON\n",
    "\n",
    "import transformers\n",
    "transformers.logging.set_verbosity_error()\n",
    "from torch.utils.data import DataLoader \n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModel\n",
    "from transformers import TFDistilBertModel, DistilBertTokenizerFast\n",
    "import torch\n",
    "from scipy.sparse import csr_matrix\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(\"using device:\", device)\n",
    "\n",
    "if \"disilbert_model\" not in locals():\n",
    "    disilbert_tokenizer =  AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "    disilbert_model = AutoModel.from_pretrained(\"distilbert-base-uncased\")\n",
    "    handle = disilbert_model.to(device)\n",
    "    \n",
    "    \n",
    "class BERTEmbeddings:\n",
    "    def __init__(self):\n",
    "        self.tokenizer =  disilbert_tokenizer\n",
    "        self.model = disilbert_tokenizer\n",
    "        self.max_length = 256\n",
    "        self.model_name = disilbert_model\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        pass\n",
    "    \n",
    "    def encode(self, txt):\n",
    "        return self.tokenizer(txt, max_length=self.max_length, \n",
    "                              truncation=True, padding=True, return_tensors=\"pt\")\n",
    "\n",
    "    def transform(self, X=None):\n",
    "        dataloader = DataLoader(X, batch_size=4, shuffle=False)\n",
    "        allembeds = []\n",
    "        for batch in tqdm(dataloader):\n",
    "            batchenc = disilbert_tokenizer(batch, max_length=256, truncation=True, padding=True, return_tensors=\"pt\")\n",
    "            input_ids = batchenc['input_ids'].to(device)\n",
    "            attention_mask = batchenc['attention_mask'].to(device)\n",
    "            batchout = disilbert_model(input_ids, attention_mask=attention_mask, output_hidden_states=True)\n",
    "            embeds = [vec[0].cpu().detach().numpy() for vec in batchout[1][-1]]\n",
    "            allembeds.extend(embeds)\n",
    "        return np.array(allembeds)\n",
    "\n",
    "bertemb = BERTEmbeddings()\n",
    "domain_cls = bentoml.sklearn.get(\"domain_cls:latest\")\n",
    "\n",
    "runners=[domain_cls.to_runner()]\n",
    "\n",
    "for i in range(6):\n",
    "    saved_model = bentoml.sklearn.get(f\"model_{i}\")\n",
    "    runners.append(saved_model.to_runner())\n",
    "\n",
    "\n",
    "model = bentoml.Service(\"swarog\", runners=runners)\n",
    "\n",
    "\n",
    "def predict(input_series: np.ndarray) -> np.ndarray:\n",
    "    vec = bertemb.transform([input_series['text']])\n",
    "    category = runners[0].predict.run(vec)[0]\n",
    "    category_proba = runners[0].predict_proba.run(vec)[0]\n",
    "    result = runners[1+category].predict.run(vec)[0]\n",
    "    return {'result': result, \n",
    "            'domain': category, \n",
    "            'domain_proba' : category_proba\n",
    "           }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_cls=bentoml.sklearn.load_model(\"domain_cls:latest\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 40.59it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([3.63167350e-01, 3.90821272e-02, 1.28244952e-04, 1.09349698e-02,\n",
       "       5.52167516e-02, 5.31470556e-01])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec = bertemb.transform([\"Cats and dogs are politically neutral\"])\n",
    "proba = domain_cls.predict_proba(vec)\n",
    "proba[0]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
